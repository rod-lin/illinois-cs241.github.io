[
  {
    "url_slug": "chatroom",
    "url": " /chatroom",
    "learning_objectives": [],
    "wikibook": [],
   "title": "Chatroom",
   "content": "Learning Objectives  Networking Components  Building working server code  Building working client code  Network error handling  Read/Write error handlingGoalThe goal of this lab is to help you understand networking components. You will accomplish this by writing a real chatroom program. You are going to write a client which can send/receive data to/from server, a server which can receive data from multiple clients and broadcast these messages to each of the clients, and read/write functions than handle the failures of read and write.  The files you must modify are  client.c  server.c  utils.cThe files client.c and server.c provide an outline of what you are expected to do via references to questions in questions.txt. For example, if you see /QUESTION 1/ then question 1 in questions.txt should help you understand what to do when filling that part of the code.So be sure to answer the questions in questions.txt to begin with as these will help you get started!ClientThe file chat_window.c is the control center for setting up the ncurses windows (that’s a thing).  You do not need to worry about this, but feel free to look at it if you are interested.The client executable will accept up to four arguments:./client &lt;host&gt; &lt;port&gt; &lt;username&gt; [filename]  host     - The address the client should connect to.  port     - The port number to connect to the host on.  username - The name you want to be displayed in the chatroom.  filename - Optional argument - will disable ncurses and write bytes received from the server to the output file.The client performs two main functions: (1) writes user input to the server and (2) writes bytes from server to user.  We have handled the overall logic of reading from user, writing to server, reading from server, and writing to user.  Your job is to set up the client and connect it to the server.Implement run_client() to use a TCP IPv4 connection and connect to the host at the given port.  A signal interrupt will be sent to the client as a flag to tell your client to exit. To be precise, when your client program receives a SIGINT it should free memory, close sockets, and gracefully exit the program.Notice the write_to_server() and read_from_server() functions use write_all_to_socket() and read_all_from_socket().  You will have to implement these functions to handle the failures of read/write calls, but more on that later.The figure below gives you an idea about how the client side architecture looks like: So to sum up, your job in the client program is:  Implement run_client() and the rest of close_client()  Set up the network connection (TCP + IPv4).  Launch threads to read from the server.  Launch threads to write to server.  Free memory you allocate.Note: You do not need to modify any of the code in client.c except for the function run_client() and close_program() in order to get the client successfully working.  However, you may modify any of the other code if you want, but be careful.Server./server &lt;port&gt;  port - The port number to accept connections on.Similar to client.c, a lot of the functionality in server.c has been implemented for you.  Your job is to set up the server to use TCP IPv4 with reusable ports and gracefully close the server when SIGINT is received. The figure below illustrates how a message propagates through the system: To sum up, you have to:  Implement run_server() and close_server() (the signal hanlder for SIGINT)  Set up connections (TCP &amp; IPv4).  (There is a giant while-loop - you need to do something in it)Here is the overall client-server architecture: Read/Write FailuresRead and Write calls (general read/write - this extends to recv, send, etc.) can fail to send/receive all bytes or get interrupted by signals.  We have defined failure as:  If read/write should read/write x bytes, then read/write failed if read/write returns y where 0 &lt; y &lt; x OR y = -1.  If read/write returns -1 AND errno == EINTR then read/write was interrupted by a signal and should try again.In utils.c/h we have declared the functions read_all_from_socket and write_all_to_socket.  You need to implement these functions to read/write from/to a socket and handle the failures of read/write (defined above).  You should look at utils.h for detailed info on what your functions should do.Messages in our server/client will be exchanged in the following format:&lt;message_size&gt;&lt;message&gt;informally: 0x0000000C\"hello world\\n\"where the first 4 bytes of the message indicate the size of the message in bytes.We use network-to-host byte-order (ntohs) and host-to-network byte-order (htons) for this.We’ve given you get_message_size(), you must implement write_message_size().  As we will be testing your server and client separately, and because our server and client expect this setup, be sure this works; it is like our “protocol”.Please see how get_message_size() it is done in utils.cIn user_hooks.c we have given an example of how to emulate a read failure (feel free to modify this file by adding a write failure call).  You can include user_hooks.h in your utils/server/client code to test your error handling.BE SURE NOT TO LEAVE ANYTHING RELATING TO user_hooks IN YOUR FILES.  THEY ARE THERE FOR TESTING, THE AG WILL NOT COMPILE THEMError CheckingNetworks Break!Many things can go wrong when working with networks. Be sure to do plenty of error checking! If anything fails, print the error message and exit(1). For each networking function call (except one of them) that you will be using, use perror(NULL). For the one that you cannot use perror, use the man pages to learn how to print the error. You must figure out which function does not set errno upon failure and thus you cannot use perror.TestingYou should implement tests for testing functionality of client and server side code separately. That way you don’t worry about client-server interactions. You can then consider cases where a message is written to one client, is sent to the server and is then broadcasted to all the other clients running. To test such a code path, you start a test that writes to one of the clients c and then verifies whether all the clients have received the message that was provided as input to c.Note, you are writing a server that could potentially run for a long time. This is exactly a scenario where memory leaks can be very costly and cause your server to crash. So ensure there are no memory leaks in your implementation.Otherwise, we will leave it open ended to let you come up with other interesting test cases.We provided you with a Makefile.You can run the client and server as follows:./client &lt;address&gt; &lt;port&gt; &lt;username&gt; [filename]./server &lt;port&gt;Test your server and client with a friend! On your VMs you can connect to each others’ machines. Just ask them what their machine number is! ./server 12345Waiting for connection...Connection made: client_fd=4^CEnding Server ./client fa18-cs241-XYZ.cs.illinois.edu 12345 stevesteve: hello there!alec: sending bytes^CClosing ClientNotice the XYZ, that is the machine number you will use to connect to the server (the person hosting’s machine)In the above “terminals”, there are things like “Waiting for connection…” and “Ending Server”: do not worry about having to do this. It is simply flavor text printed to the window. Feel free to do that; we will only test the bytes that are sent and received.Because it’s particularly important for this lab, we want to reiterate that you should not have any memory leaks :)Grading  Client must function as specified  Server must function as specified  Implementation of read_all_from_socket and write_all_from_socket to handle failures  Errors must be handled as specified  No memory leaksOnce again, you do not need to modify any of the provided code in order to complete the lab, but you can if you want (however, be very careful; we are not responsible for your changes )Interesting ThingsWe are using pthread_cancel, pthread_detach,  pthread_cleanup, and ncurses.  It is not necessary to know about these (actually cancel might have been on one of your quizzes), so don’t let them distract/confuse you.  However, if you are interested, definitely read up on them.In the Makefile, we have -I./includes.  This lets you do #include \"something.h\" instead of #include \"./includes/something.h\"Also #pragma once in the .h filesUsernamesHere is the link to the username form for the quiz. Fill it out sometime during your lab. Thanks!"
  }
    ,
    
  {
    "url_slug": "critical-concurrency",
    "url": " /critical_concurrency",
    "learning_objectives": ["Synchronization Primitives","Common Patterns in Multi-Threaded Programs","Thread-Safe Datastructures and Their Design"],
    "wikibook": ["Synchronization, Part 1: Mutex Locks","Synchronization, Part 2: Counting Semaphores","Synchronization, Part 3: Working with Mutexes And Semaphores","Synchronization, Part 4: The Critical Section Problem","Synchronization, Part 5: Condition Variables","Synchronization, Part 6: Implementing a barrier","Deadlock, Part 1: Resource Allocation Graph","Deadlock, Part 2: Deadlock Conditions"],
   "title": "Critical Concurrency",
   "content": "Lab AttendanceFor this week’s lab attendance please fill out the following form: https://docs.google.com/forms/d/e/1FAIpQLSd29dlmCoZ0SPEULCVv_nuIfZojUfoY5Zy493DkAFkmPOU1Fw/viewformOverviewThere are four main components to this lab, three of which are graded. These are Rendezvous (not graded), Semamore, Barrier, and Thread-safe Queue. Each of these represent very common synchronization problem (or slight twists on them) that will do you well to become familiar with.Good luck!Rendezvous (UNGRADED)This is a problem for you to think about. We have provided a worked solution to this problem but PLEASE try to solve this problem before looking at the solution!Problem description:Given two threads, a and b, and the fact that both have to run two tasks (a1, a2, b1, b2), how do you get both a1 and b1 to run before either a2 and b2? In rendezvous.c, you need to modify the two functions (modifyB_printA &amp; modifyA_printB) using semaphores so that both quotes A and B are modified before being printed.semamore.cNOTE: A semamore is NOT a real thing! It is simply a made up clever name! This means you can’t use them in future assignments (unless you re-implement it).A normal semaphore blocks when the value within the semaphore reaches 0. A semamore blocks when it reaches 0, but also blocks when it reaches some maximum value. You can think of a semamore as a top-bounded semaphore. In semamore.c, you are given four functions to work on, semm_init, semm_wait, semm_post, semm_destroy. semm_post is the important difference. When semm_post reaches max_val (as defined in the semamore struct in semamore.h), it blocks.There are four functions in total you will be writing:  void semm_init(Semamore *s, int value, int max_val);  void semm_wait(Semamore *s);  void semm_post(Semamore *s);  void semm_destroy(Semamore *s);barrier.cIn rendezvous you saw an example of an one-time-use barrier.  Now, you get to build code to support a reusable barrier.  At the cost of being redundant, a reusable barrier is one that can get used more than once.  Say you have threads executing code in a for loop and you want them to stay in sync.  That is, each thread should be on the i’th iteration of the loop when every other thread is on the i’th iteration.  With a reusable barrier, you can stop threads from going to the i+1’th iteration until all of them have finished the i’th.Note that most barrier implementations (including the pthread library barrier) are “resuable”, but never say so.  This is because it simply does not make sense to have a “not-reusable” barrier.  Thus, we are only iterating to you that the barrier your build should be reusable so that you understand what  it means.You can find more info in the WIKIYour goal is to implement the functions  int barrier_destroy(barrier_t *barrier);  int barrier_init(barrier_t *barrier, unsigned num_threads);  int barrier_wait(barrier_t *barrier);so that a barrier_t using these functions is a working reusable barrier.queue.cNOTE: Do not use semaphores or your semamore here.Your task is to build a thread safe queue, that also may or may not be bounded, by implementing the functions in queue.c. The maxSize of the queue can be set to either a positive number or a non-positive number. If positive, your queue will block if the user tries to push when the queue is full. If not positive, your queue should never block upon a push (the queue does not have a max size). If your queue is empty then you should block on a pull. You should make use of the node struct to store and retrieve information. In the end, your queue implementation should be able to handle concurrent calls from multiple threads. queue_create and queue_destroy will not be called by multiple threads.The queue is completely independent of the data that the user feeds it. The queue should make use of the constructors and destructors provided by the user to handle data.Your goal is to implement the functions  queue* queue_create (ssize_t max_size, copy_constructor_type copy_constructor, destructor_type destructor);  void queue_destroy (queue* this);  void queue_push (queue* this, void* element);  void* queue_pull (queue* this);TestingTesting is ungraded, but highly recommendedSince the implementation of your semamore is quite close to an actual semaphore, please test this on your own in a variety of ways. Be careful of race conditions! They can be hard to find!  We’ve given you a semamore_tests.c file to write tests in.For barrier_test.c we have provided you with a simple test case.  Feel free to expand on it, as it is not exhaustive/perfect.  Learning how to use the barrier is just as important as writing it, since you will be using barriers on the Password Cracker MP :)For queue_test.c we would like you to write tests yourself.  Learning to write tests for multi-threaded code is very important.  You will also be using this queue in the Password Cracker MP :)  (we will give you a working version; you will not be penalized on the MP for not successfully completing the lab)Helpful Hints and Notes  Make sure you thoroughly test your code! Race conditions can be hard to spot!  Attempting to visualize your code or diagram it in certain cases can sometimes be a huge aid and is highly recommended!** In any of semamore.c, barrier.c, or queue.c you may not use semaphores or pthread_barriers **ANYTHING not specified in these docs is considered undefined behavior and we will not test itFor example, calling queue_push(NULL, NULL) can do whatever you want it to. We will not test it."
  }
    ,
    
  {
    "url_slug": "deadlocked-diners",
    "url": " /deadlocked_diners",
    "learning_objectives": ["Synchronization","Deadlock / Livelock / Starvation","Coffman Conditions","Dining Philosophers","Messing with Interns"],
    "wikibook": ["Deadlock, Part 1: Resource Allocation Graph","Deadlock, Part 2: Deadlock Conditions","Deadlock, Part 3: Dining Philosophers"],
   "title": "Deadlocked Diners",
   "content": "BackstoryYou are creating a start up that allows companies to rent code monkeys interns for a project.They are billed by the number of days it takes to complete the project.The reason why companies want to rent interns is because they realized they do not need dedicated interns,since they do not always have projects at hand (sometimes they are contemplating about life).Basically a company in 1 of 3 states: “trying to rent interns”, “working with interns” or “having a board meeting”.They came to the conclusion that a possible way of handling this dilemma is to simply overwork the interns by having them work for 2 companies,just not at the same time.This is where you come along….The scenario is as follows.Each of the companies practices pair programming,so you will need to find a way to schedule the interns so that we can continue to bill each company as often as possible.This means that work on a project can only be completed when the company has TWO interns assigned to it.There are n companies and k interns in this scenario.For some odd reason the ith company likes to work with intern i%k and (i+1)%k…A company might decide to give the interns a break from the project,in which case they are free to be assigned to another company that wants them and won’t be reassigned until said company gives them a break.Your mentor has written a simulation of this scenario with a synchronization strategy, but it does not work.The mentor left a note that reads:  Dear intern, I have written a simulation of the ‘intern for rent’ program,but sometimes a company grabs one intern,then waits for the second intern,which wont be released until the first intern is given a break…Your Job  Read Resource Allocation Graphs and Deadlock Conditions to have all the knowledge you will need for this assignment.  Read simulator.c, bad_company.c, and company.h until you have a good sense of what the code is doing (nothing will make sense until you do).  Overwrite good_company.c with your correct solution (hint: look in company.h for useful functions).TestingWe provided you with a Makefile.Typingmakewill create the good_company and bad_company executable.For both the good_company and bad_company executable you can execute them with 2 required arguments and 3rd optional argument as follows:./bad_company 5 6 100000will run the bad solution with 5 companies and 6 interns and with a delta of 100000.Delta is approximately how long an operation takes in microseconds (read the source code for more details).If you see something like this:Company 0 used our services for 2083 billable days.Company 1 used our services for 2164 billable days.Company 2 used our services for 2456 billable days.Company 3 used our services for 2826 billable days.Company 4 used our services for 3733 billable days.Total Billable days : 13262then the simulation terminated successfully.This does not mean your solution is correct.There may still be race conditions, so it it up to you to test your code thoroughly with all sorts of parameters.If the simulator stops without billing the companies just hit CTRL+Z.GradingYour grade depends on having a good working solution.A good solution must have the following:  No Deadlock  No Livelock  Performant          Performance will be judged against the reference solution (good_company_reference) and measured by total billable days.      You must be within 90% of the reference solution to receive full points.        Fair (all companies should get a roughly equal number of billable days)          You must be within 90% of than the reference solution to receive full points.      Fairness is determined by min_billable_days/max_billable_days where higher is better.        Must adhere to the rules of the scenario  Run with a single intern should not cause deadlock AND not burn cpu cycles  A valid solution should not know about the number of interns or or number of companies"
  }
    ,
    
  {
    "url_slug": "extreme-edge-cases",
    "url": " /extreme_edge_cases",
    "learning_objectives": ["Test Driven Development","Thinking of Edge Cases","String Manipulation","C Programming"],
    "wikibook": ["C Programming, Part 1: Introduction","C Programming, Part 2: Text Input And Output","C Programming, Part 3: Common Gotchas"],
   "title": "Extreme Edge Cases",
   "content": "BackstoryWhat makes code good? Is it camelCased strings? Good comments? Descriptive variable names, perhaps?One thing we know is that good code is generally modular - it consists of discrete “units” of functionality that are only responsible for very specific and certain behavior. In our case, working with C, these “units” are functions.For example, the C string function strlen is solely responsible for determining the length of a string; it doesn’t do any I/O or networking, or anything else. A function that knows all and tries to do all would be bad design, and testing whether that kind of function adheres to expectations would be nontrivial.A programmer might ask, “do my units of work behave the way I expect?” or “if my function expects a string, how does it behave when given NULL?”. These are crucial questions, since ensuring that units of code work exactly the way one would expect makes it easy to build reliable and robust software. An unreliable unit in a large system can affect the entire system significantly. Imagine if strcpy, for example, did not behave properly on all inputs; all of the higher-level units that use strcpy, and all of the units that interact with those units, would in-turn have unpredictable behavior, and so the unreliability would propagate through the whole system.Enter unit testing.Unit TestingUnit testing is a ubiquitous and crucial software development method used heavily in industry. According to artofunittesting.com, “a unit test is an automated piece of code that invokes a unit of work in the system and then checks a single assumption about the behavior of that unit of work”. This sounds like testing - leave it to the QAs, right? Actually, developers, much to their chagrin, are expected to write their own unit tests.In order to write effective unit tests, all possible cases of input to a unit (mainly functions, in C), including edge cases, should be tested. Good unit tests test (extreme) edge cases, making sure that the discrete unit of functionality performs as specified with unexpected inputs.In this MP, your goal is to create and test the behavior of an arbitrary string manipulation function to determine if it is reliable, predictable, and correct. While writing your functions, try to write modular code, as this will make your life easier when you test it. You’ll learn how to write effective test cases - an incredibly helpful skill for the rest of the course. Finally, you’ll be able to take these skills to Facenovel for your next internship and impress your coworkers.Camel CaserWe have chosenchar **camel_caser(const char* input)as your arbitrary string manipulation function.Your manager at Facenovel, to celebrate Hump Day, has asked all of the interns to implement a brand new camelCaser to convert sentences into camelCase. To give you a chance to earn your return offer, he also assigned you to write test cases for all the other interns’ implementations of camelCaser, with the implementations hidden from you.Let’s say I want to get a sequence of sentences in camelCase. This is the string passed into your method:\"The Heisenbug is an incredible creature. Facenovel servers get their power from its indeterminism. Code smell can be ignored with INCREDIBLE use of air freshener. God objects are the new religion.\"Your method should return the following:[\"theHeisenbugIsAnIncredibleCreature\",\"facenovelServersGetTheirPowerFromItsIndeterminism\",\"codeSmellCanBeIgnoredWithIncredibleUseOfAirFreshener\",\"godObjectsAreTheNewReligion\",NULL]The brackets denote that the above is an array of those strings.Here is a formal description of how your camelCaser should behave:  You can’t camelCase a NULL pointer, so if input is a NULL pointer, return a NULL pointer.  If input is NOT NULL, then it is a NULL-terminated array of characters (a standard C string).  A input sentence, input_s, is defined as any MAXIMAL substring of the input string that ends with a punctuation mark. This means that all strings in the camel cased output should not contain punctutation marks.          This means that “Hello.World.” gets split into 2 sentences “Hello” and “World” and NOT “Hello.World”.        Let the camelCasing of input_s be called output_s  output_s is the the concatenation of all words w in input_s after w has been camelcased          The punctuation from input_s is not added to output_s.        Words are:          delimited by the MAXIMAL amount of whitespace.                  This means that “hello world” is split into “hello” and world” and NOT “hello “, “ “, “ world” or any other combination of whitespaces                    considered uppercased if all of its letters are uppercased.      considered lowercased if all of its letters are lowercased.        a word w is camelCased if and only if:          it is the first word and it is lowercased      it is any word after the first word and its first letter is uppercased        Punctuation marks, whitespace, and letters are defined by ispunct(), isspace(), and isalpha() respectively.          These are parts of the C standard, so you can man ispunct for more information.      If input_s has ANY non-{punctuation, letter, whitespace} characters, they go straight into output_s without any modifications. ALL ASCII characters are valid input. Your camelCaser does not need to handle all of Unicode.        camel_caser returns an array of output_s for every input_s in the input string,  terminated by a NULL pointer.Hint: ctype.h has a lot of useful functions for this.Your implementation goes in camelCaser.c, and you may not leak any memory.We have also included a reference implementation. It is there to help you answer questions like, “What should be the result of inputting &lt;blah&gt; into camel_caser()?”  You can start the program with ./camelCaser-reference and the program will take your input and return it camelCased when you press Enter. You should not add quotes around the strings you test (unless you want to try camelCasing actual quotation marks).DestroyYou must also implement destroy(char **result), a function that takes in the output of your camel_caser and frees up any memory used by it. We will be calling this in our test cases and checking for memory leaks in your implementation, so remember to test this!Camel Caser Result In MemorycamelCaser takes in a C string, which represents an arbitrary number of sentences, and returns a pointer to a NULL-terminated array of C strings where each sentence has been camelCased. It is up to you how the resulting structure is allocated, but it must be completely deallocated by your destroy function.For those who like pictures, here is what the return value of camelCaser looks like in memory:In the above picture, you can see that we have a char double pointer called ‘array’. In this scenario, the char double pointer points to the beginning of a NULL-terminated array of character pointers. Each of the character pointers in the array points to the beginning of a NULL-terminated char array that can be anywhere in memory.These arrays are NULL-terminated because your user will need to know when these arrays end so they do not start reading garbage values. This means that array[0] will return a character pointer. Dereferencing that character pointer gets you an actual character. For demonstration purposes, here is how to grab the character “s” in “as”:// Take array and move it over by 3 times the size of a char pointer.char **ptr = array + 3;// Deference ptr to get back a character pointer pointing to the beginning of \"as\".char *as = *ptr;// Take that pointer and move it over by 1 times the size of a char.char *ptr2 = as + 1;// Now dereference that to get an actual char.char s = *ptr2;Escape SequencesIf you want to see how the reference implementation handles ASCII characters that cannot be typed directly, you can use escape sequences. You are likely already familiar with the \\n escape sequence for representing newlines in printf, but there are many others available.For example, you can see that newlines are treated as whitespace:&gt; hello\\nworld.{  \"helloWorld\",  NULL}Be warned: in the reference, if you type \\n, the reference sees it as two bytes (\\ and n), and will replace it with the ASCII line feed character (ASCII value 0x0A) before checking what type of character it is (punctuation, whitespace, alphanumeric, etc).You should not do this in your implementation.The reference does this so that you can test different escape sequences and how they should behave.If you want to test escape characters in your camel caser, you can simply do camel_case(\"foo\\tbar\") in your test function(s). The C compiler will correctly compile the \\t into the ASCII tab character rather than a \\ followed by a t. To your camel caser, the \\t will appear as one character, and will be correctly identified as whitespace by isspace('\\t').In conclusion: you should not parse escape sequences yourself by putting together \\ and t; they will appear as one character to your camel caser.Writing Unit TestsYour goal is to show that the other interns’ implementations of camelCaser - which, of course, you can’t see directly - fail on some extreme test cases, and, in the meantime, demonstrate to the head honcho at Facenovel exactly how robust your own function is.Facenovel promises to pass in C-strings. Likewise, you promise to return a dynamically allocated NULL-terminated array of strings that can be deallocated with your destroy function.What kinds of edge cases might come up?Run make camelCaser to test. You will have to fill in tests in camelCaser_tests.c.Because Facenovel values their testing server time, you may not try more than 16 different inputs, and each input must be less than 256 characters (only characters). This does NOT mean your implementation can assume input of 256 characters or less.Also, it is not in the spirit of unit testing to diff your implementation with the one you are testing. Therefore, you may NOT call your own camel_caser function when implementing your test cases.Other helpful resources: Test-Driven DevelopmentGradingGrading is split up into two parts.Your ImplementationThe first portion of the test cases test your implementation of camel_caser. We pass in some input, and check that your output matches the expectations laid out in this document. Essentially, your code is put up against our unit tests, which means you can write as-good (or even better) unit tests to ensure that your camel_caser passes ours.Your Unit TestsThe second portion of the test cases test your unit tests. We have a handful of camel_caser implementations, some that work, and some that don’t. To test your unit tests, we feed each of our camel_caser implementations through your test_camelCaser function (found in camelCaser_tests.c) and see if it correctly identifies its validity.For each of the camel_caser implementations that you correctly identify - marking a good one as good, or a bad one as bad - you get a point. To prevent guessing, randomization, or marking them all the same, any incorrect identification loses you a point. However, after each autograde run, we will tell you how many good ones you correctly identified and how many bad ones you identified, so you know which unit tests may need improvement.If your unit test segfaults or otherwise crashes, our test will interpret that as evaluating that implementation as a bad one.You cannot assume anything about the input, other than the input string being NULL-terminated, just like all good strings in C.ExampleLet’s say there are five good implementations and five bad implementations. If you correctly say all five good are good, then you’d get +5 points. If you correctly identify three of the bad ones as bad, then you would get +3 for those and -2 for incorrectly labeling the others. In this case, you’d get a 6/10.Good luck!"
  }
    ,
    
  {
    "url_slug": "finding-filesystems",
    "url": " /finding_filesystems",
    "learning_objectives": ["Learn how inodes are represented in the kernel","How to write callbacks for filesystem operations","Traverse singly indirect blocks","Modifing permissions on files"],
    "wikibook": ["File System, Part 1: Introduction","File System, Part 2: Files are inodes (everything else is just data...)","File System, Part 3: Permissions","File System, Part 4: Working with directories"],
   "title": "Finding Filesystems",
   "content": "QuizzIzFor this week’s lab attendance grade, please fill out the google form at this link: https://docs.google.com/forms/d/e/1FAIpQLSc9tDTBZ62p2zcZq6AaYKrq4q1A6zYzWCFzdnJGHYwwvxtWDw/viewformOverviewYour friendly neighborhood 241 course staff asked themselves, “What’s the best way to learn filesystems?” Write one!In this lab, you will be implementing several callbacks to file system operations, namely, chmod, chown, read, and write. To do this you will be exploring how metadata is stored in the inode and how data is stored in the data blocks.minixfsext2 is good filesystem, but to keep things simple, we will be using a modified version of its predecessor (the MINIX filesystem) in this lab.Superblocktypedef struct {\tuint64_t size;\tuint64_t inode_count;\tuint64_t dblock_count;\tchar data_map[0];} superblock;The superblock stores information like the size of the filesystem, the number of inodes and data blocks, and whether those data blocks are being used. Remember from class that inodes become free when their hard link count reaches zero, but data blocks need some kind of bitmap or sentinel to indicate if they are being used. data_map is a variable-sized array that holds this information. You don’t need to worry about these abstractions, they are taken care of for you.Inodestypedef struct {  uid_t uid;   gid_t gid;   uint16_t mode;   uint32_t nlink;   struct timespec atim;  struct timespec mtim;  struct timespec ctim;  uint64_t size;   data_block_number direct[NUM_DIRECT_INODES];  data_block_number indirect;} inode;This is the famous inode struct that you have been learning about! Here are a breakdown of the variables:  uid is the user ID of the inode owner.  gid is the ID of the inode group (does not have to include the owner).  mode is a bitmask. The bottom 9 bits are read-write-execute for owner-group-others. Bits 11-10 are the type of the file. (mode &gt;&gt; 9) corresponds to a particular type. We have given you two functions, is_file and is_directory, that tell you whether or not the inode represents a directory or file. There are no other types in our filesystem.  nlink is the hard link count which is the number of directories that the file is linked to from (directories can’t be hard linked).  atim is access time, which is the time of last access or the last time a file was read(2).  mtim is the last modification time, or in other words, the last time the file was changed with write(2).  ctim is the last change time, or in other words, the last time the file’s metadata was changed.  size is the size of the file in bytes  direct is an array where the direct[i] is the ith data block’s offset from the data_root.  indirect is the offset number (data_block_number) of a data block, which contains NUM_INDIRECT_INODES number of data_block_number’s.Data blockstypedef struct {\tchar data[16 * KILOBYTE];} data_block;Data blocks are currently defined to be 16 kilobytes. Nothing fancy here.file_system structtypedef struct {\tsuperblock* meta;\tinode* inode_root;\tdata_block* data_root;} file_system;The file_system struct keeps track of the metadata, the root inode (where fs-&gt;inode_root[0] is the root \"/\" inode), and the root of the data_blocks.  The meta pointer points to the start of the file system, which includes the superblock and the data_map.  The inode_root points to the start of the inodes as in the picture, right after the data_map.  The data_root points to the start of the data_blocks as in the picture, right after the inodes.The inodes and data blocks are laid sequentially out so you can treat them like an array. Think about how you could get a pointer to the nth data_block.fakefs interfaceTo make this lab possible, we’ve developed our own userspace filesystem interface which we’re calling fakefs. Normally, filesystem are a piece of code which you load into your kernel and must provide a few things. It needs a constructor, destructor, callbacks for all system calls involving files and file descriptors within your filesystem. However, writing kernel code is a bit more cumbersome than writing normal code (since you need additional security checks among other things), and can even lead to instability in your operating system. To avoid this, there are various ways to implment a filesystem in userspace. The most common (and preffered) method is to use a library called FUSE (Filesystems in USErspace). However, FUSE alllows you to implement your file operations in userspace, but still interacts with th ekernel to provide it’s functionality. While this allows you to mount  the filesystem and use it like any other filesystem, there a few reasons why we chose not to use it for this lab. A major reason is that if a FUSE callback crashes while it is mounted, it renders the mounted partition unsuable and in some cases, you won’t be able to even unmount the parition without rebooting the machine. To prevent this, and make this lab not annoying and tedious, we’ve made ourn own way of implementing filesystems in userspace by hooking filesystem operations.If you take a look at fakefs.c you’ll see that we’ve overridden most of glibc’s filesystem operations. Note that this only hooks functions from code or programs that were either written in C or in something that compiles to C. Running a program written in assembly will not be affected by these hooks.Note that not all programs will work with fakefs. At the least, we guarantee that ls, cat, mkdir, unlink and cp work. vim and neovim seem to work although you might run into some weird bugs using these programs within fakefs.Helper Functions/MacrosThere are some functions that you are going to need to know in order to finish this lab.get_inodeThis function takes a string name like /path/to/file and returns the inode corresponding to the file at end of that path. get_inode returns NULL when the intended file does not exist or the file is invalid.is_file / is_directoryCall is_file or is_directory on an inode to tell whether it is a directory or a file. You don’t need to consider other inode types.NUM_DIRECT_INODESNUM_DIRECT_INODES is the number of direct data_block nodes in a single inode. The indirect array has only this many entries (for the sake of simplicity).UNASSIGNED_NODEYou may not need to use this macro, but if you choose to, then any data_block or inode that is not currently being used will have this number.Directory StructureOur directory data_blocks looks like the following:|--248 Byte Name String--||-8 Byte Inode Number-||--248 Byte Name String--||-8 Byte Inode Number-|...The filesystem guarantees that size of a directory is a multiple of 256. You need to loop through all of the directory entries and get the name of the entry, and print it out to standard out. You are going to need to call two different print functions based on whether the inode that you are pointing to is a directory or a file, which means you have to get the inode number and check that inode.Use make_dirent_from_string: it accepts a char* ptr to the start of a dirent block like this.|--248 Byte Name String--||-8 Byte Inode Number-|^ -- Points hereSo what do I need to do?You will need to implement the following 4 functions  int minixfs_chmod(file_system *fs, char *path, int new_permissions)  int minixfs_chown(file_system *fs, char *path, uid_t owner, gid_t group)  ssize_t minixfs_read(file_system *fs, const char *path, void *buf, size_t req, off_t *off)  ssize_t minixfs_write(file_system *fs, const char *path, const void *buf, size_t count, off_t *off)You can find more information about these functions in minixfs.h. Remember to set errno on errors in your code!Note that for all functions where you need to update times, you should use clock_gettime(CLOCK_REALTIME, variable_to_update);.TestingTesting is ungraded, but highly recommendedYou can grab the test filesystem using make testfs. Do not commit this file. If you overwrite it and want the original version just rm test.fs and do make testfs againYou will probably want to reset your test.fs file frequently while testing your write functionality.Note: There’s a small chance that make testfs can fail - in this case rm test.fs and make testfs again.make will generate the minixfs_test executable that you can use for testing. We strongly reccomend writing your own testcases in minixfs_test.c and not just on the output of commands like ls and cat (which we describe how to test with below). This is because subtle bugs in your code can make the output look right, but have random unprintable characters as well.The goodies directory is also included and can also be used to check against the /goodies directory in test.fs.For example, the output of:./fakefs test.fs cat test.fs/goodies/hello.txt should be the same as cat ./goodies/hello.txtHere are some sample (and not comprehensive) testcases!$ ./fakefs test.fs cat /goodies/hello.txtHello World!$You can even cat directories!$ ./fakefs test.fs cat /you00000001got00000002ls!00000003congrats00000004 [...]$So that’s what really is going on under the hood?Want something fun?$ ./fakefs test.fs cat test.fs/goodies/dog.png &gt; dog.png$ xdg-open dog.pngYou can store anything on filesystems. See what we hid around the testfs filesystem for you…You can also test by generating your own filesystems. Simply run ./fakefs mkfs filename to generate a filesystem with the filename filename. If you’ve implemented the write functionality, you can use commands like ./fakefs cp file1 filename/ to copy files over. programs like mkdir should work as well.Other Edge Cases  You do need to update atim and the ctim!  You don’t need to worry about data corruption or checksums or anything fancy, the filesystem will be valid. (Unless your write has bugs in it)  Make sure all the files you cat out in /goodies look correct when you xdg-open them. Make sure you can get the PNGs and the PDFs to print out correctly.  Make sure your output is the same size as the files inside the filesystem. You can check this by running stat on the files inside the filesystem(./fakefs test.fs stat test.fs/FILE_PATH), and wc -c on the on output of running cat on the file (./fakefs test.fs cat test.fs/FILE_PATH | wc -c) to check that the number of bytes is the same.Helpful Hints and Notes  Handle the edge conditions. You can assume that size will be valid. What is the code supposed to do when you get to a singly indirect block?  Draw pictures! Understand what each of the things in the structs mean.  Review your pointer arithmetic.  Only changeminixfs.c.Graded Files  minixfs.cAnything not specified in these docs is considered undefined behavior, and we will not test it."
  }
    ,
    
  {
    "url_slug": "ideal-indirection",
    "url": " /ideal_indirection",
    "learning_objectives": ["Virtual Memory","The virtual address translation process","Memory Management Unit (MMU)","Page Tables","Translation Lookaside Buffer (TLB)"],
    "wikibook": ["Virtual Memory, Part 1: Introduction to Virtual Memory"],
   "title": "Ideal Indirection",
   "content": "Quizziz/AttendanceFor this week’s quizziz username mapping/feedback form see this link https://docs.google.com/forms/d/e/1FAIpQLSdmmKmx6XHaUtXgLVGtQzOFdIS1zuuInFjbOWqOwkk_Xcy_HA/viewform.OverviewIn this assignment, you will be working on managing a mapping of 32-bit virtual address space  to a 32-bit physical address space with 4 KB (kilobyte) pages.Each component of virtual memory has been split up into several files to help you build a mental model of virtual memory.Reading through these files can start to help you understand the roles of the different hardware and software involved in managing virtual memory.You will only have to write two functions in mmu.c, but it requires a good understanding of the wikibook and decent knowledge of the rest of the provided code.The rest of this documentation will serve to help you understand the purpose of each file and give you a high level understanding of virtual memory.The implementation details of each function are documented in the header and source files.It is your responsibility to read every line of code before starting this assignment, since you will not be able to do anything meaningful otherwise.Page Tables (page_table.c and page_table.h)Each process has two levels of paging:The top level page table is known as a “page directory” and has entries (page directory entries) that hold the base address of page tables (beginning of a page table).Each of these page tables hold entries (page table entries) that hold the base address of an actual frame in physical memory, which you will be reading from and writing to.There are other metadata bits in both the page directory and page table entries that is explained in detail in page_table.h.The actual layout is taken directly from a real 32 bit processor and operating system, which you can read more about in the “IA-32 Intel® Architecture Software Developer’s Manual”.For illustrative purposes a Page Table Entry looks like the following:Each entry is represented as a struct with bit fields whose syntax you can learn about in a tutorial.The bit fields basically allows us to squeeze multiple flags into a single 32 bit integer.This means that each entry has not only the physical address to the lower level paging structure, but also metadata bits/flags which are documented in the header file.However for the purpose of this lab you are only responsible for knowing how the following fields works:  Page base address, bits 12 through 32  Present (P) flag, bit 0  Read/write (R/W) flag, bit 1  User/supervisor (U/S) flag, bit 2  Accessed (A) flag, bit 5  Dirty (D) flag, bit 6More detailed information about the function of each permission bit is described page_table.h. Here are some helpfulguidelines for correctly setting the bits:  Once a page_directory_entry is created, it will remain in physical memory and will not be swapped to disk.  Each segmentation has a permissions field, and there is a permissions struct in segments.h. If permissions &amp; WRITE is not 0, then it has write permission. Same is true for READ and EXEC.  page_directory_entry’s should always have read and write permission  For the purposes of this lab, all page_table_entrys and page_directory_entrys will have the user_supervisor flagset to 1  You only need to keep track of Accessed and Dirty flags for each page_table_entry, based on any reading or writing thathas occurred to the base_addr stored by the page_table_entry.Translation Lookaside Buffer (tlb.c and tlb.h)The Translation Lookaside Buffer will cache the base virtual address to the corresponding page table entry pointer.The implementation and header is provided to you.Make note of the use of double pointers.The reason why our TLB caches page table entry pointers instead of physical addresses of frames is because you will need to set metadata bits when translating addresses.Segments (segments.c and segments.h)A process’s virtual address space is divided into several segments. You are familiar with many of these:  Stack  Heap  BSS  Data  CodeFor this lab, a processes’ address space is split into memory segments like so:Photo Cred: http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/Notice how some of the memory segments like the stack and mmap have an arrow pointing down.This indicates that these regions “grow down” by decreasing their end boundry’s virtual address as you add elements to them.This is so that the stack and heap can share the same address space, but grow in different directions.It is now easy to see that if you put too many elements onto the stack it will eventually run into heap memory leading to the classic Stack Overflow.The reasons why this external structure is needed for this lab is to answer the question: “How do you know when an address is invalid?”.You can not rely on the present bit of a page table entry, since that page may be valid, but just happens to be paged to disk.The solution is to check to see if an address is in any memory segment with bool address_in_segmentations(vm_segmentations *segmentations, uint32_t address);.If the address is not in any of the process’s segments, then you get the dreaded segmentation fault (segfault).Kernel (kernel.c and kernel.h)For this assignment all the memory allocations will be abstracted by kernel.c.This file will maintain a global array of pages that you will use to model all of physical memory.That is to say that all virtual addresses get translated to an address in:char physical_memory[PHYSICAL_MEMORY_SIZE] __attribute__((aligned(PAGE_SIZE)));The caveat to this lab is that it is all done in user space.That means you are technically mapping one virtual address to another virtual address that represents a physical address.However, all the concepts involved remain the same in a real operating system’s memory management software.We use a global char array for our physical memory as it so happens that global variables such as these are storedin some of the lowest addresses in memory. Because of this, the array, despite existing in a 64 bit environment, onlyneeds the 32 lower bits of a 64 bit address to address it. This is great because it allows us to use 32 addresses torefer to a physical memory location, despite being on a 64 bit system. The downside is that we will need to convertany 32 bit references to the data into a 64 bit pointer before we actually try to access the physical memory at thataddress.In this lab, we will be dealing with addr32 type variables to keep track of both virtual and “physical” addresses.The type addr32 is just an alias for uint32_t, which is just a type that can store a 32 bit value. However,since our actual VMs are 64 bit, we will need to convert this addr32 into a system pointer if we ever want to interactwith real physical memory directly (ie, by dereferencing a pointer). We have provided a few helper functions to help with this translation:void *get_system_pointer_from_pte(page_table_entry *entry);void *get_system_pointer_from_pde(page_directory_entry *entry);void *get_system_pointer_from_address(addr32 address);The function get_system_pointer_from_address will take an addr32 address and return a system pointer that you canuse to interact with the data at that address. Similarly, the functions get_system_pointer_from_pte andget_system_pointer_from_pde can be used to get a pointer for accessing the memory at the base_addr of thepage_table_entry or page_directory_entry (respectively). A good example of using these functions can be found in mmu.c’s mmu_add_process function.A word of caution: shifting signed numbers can produce unexpected behavior, as it will always extend thesign, meaning if the most significant bit is 1, the “leftmost” bits after shifting right will all be 1s instead of 0s. Do yourself a favor, work with unsigned values.Memory Management Unit (mmu.c)For this assignment you are mainly responsible for handling reads to and writes from virtual addresses.The functions you are to complete are:void mmu_read_from_virtual_address(mmu *this, uintptr_t virtual_address, size_t pid, void *buffer, size_t num_bytes);void mmu_write_to_virtual_address(mmu *this, uintptr_t virtual_address, size_t pid, const void *buffer, size_t num_bytes);This means you have to translate from a virtual to a physical address:From the wikibook: “For most memory accesses of most programs, there is a significant chance that the TLB has cached the results… the TLB [may] not have the result cached and the MMU must use the much slower page table to determine the physical frame.”Thus for any virtual address, you should check whether the result has been already cached in the TLB (see tlb.h). Otherwise you must search the page tables.For this lab we have 2 levels of indirection (see page_table.h).The following illustration demonstrates how to translate from a virtual address to a physical address:That this image is saying is that you are to take the top 10 bits of the provided virtual address to index an entry in the page directory of the process.That entry should contain the base address of a page table.You are to then take the next 10 bits to index an entry the page table you got in the previous step, which should point to a frame in physical memory.Finally you are to use the last 12 bits to offset to a particular byte in the 4kb frame.TestingMake sure you throughly test your code as usual. We have provided some tests cases, but we encourage you to write your own as well. Use the provided test cases as a reference to learn to create tests with good coverage."
  }
    ,
    
  {
    "url_slug": "know-your-tools",
    "url": " /know_your_tools",
    "learning_objectives": ["Getting familiar with the tools needed for CS 241."],
    "wikibook": ["HW0","System Programming Jokes"],
   "title": "Know Your Tools",
   "content": "HW0You have already been assigned a HW0 for the class. Here is the HW0 submission link – beware the link does not save so be ready to submit when going through. We’ll spend the first part of class going over the various questions from HW0. Your grade for this lab is partly HW0 and partly the assignment below.DevelopmentRead the Development Guide!Git(Read the first section of the development site!) You will be using git to submit all your assignments in this course. First go to the repository creator. DO NOT DO THE README TUTORIALOnce you are in your VM, you’ll need to set up some global defaultsgit config --global user.name \"FIRST_NAME LAST_NAME\"git config --global user.email NETID@example.comMake sure to replace FIRST_NAME and LAST_NAME and NETID with your information. Then checkout your repository as followsgit clone https://github-dev.cs.illinois.edu/cs241-fa18/NETID.gitwhich will check out your entire git repo into a folder called ‘NETID’ into your current directory. Now change your directory into that folder:cd NETIDYou’ve probably noticed the repository is empty! In order to grab the latest version of our assignment, complete the following steps.git remote add release https://github-dev.cs.illinois.edu/cs241-fa18/_release.gitgit pull release mastergit push origin masterGraded FilesOne section we will have on the top of every assignment is a section called graded_files these are the files that we use to grade the assignment. git does not allow us to set the rest of the files to readonly to prevent changing them (header files, Makefile). You have to be careful to avoid changing these files. We are working on a system that prevents you from accidentally committing the changes, but there is no easy way to set permissions on your local copy.BackgroundYou are working for ShadyCorp Inc. Your boss commissioned your coworker to write a program. The program reads a file, overwrites it multiple times so that it is harder to recover on the hard disk, then encrypts the file, then writes it once to an output file.The head of ShadyCorp is lazy, so they want more features. They want the first five lines of the file and the last five lines of the file to be copied to the beginning. They also want the file to be wrapped to be more easily read on mobile devices. Lines should be at most 80 characters (not including the newline). If a line is longer than 80 characters, then it should be split into two or more lines, where all the but the last line has 80 characters (not including the newline). Your co-worker sighs and comes up with the following game plan.  Read the entire file from disk  Wrap the lines to 80 characters max  Do the rewrite and make sure the file is mangled  Find the first five and the last five lines and copy them in the front of the string  Write it to an output file  In the case where all is successful, print out the process address space. (You need to implement this)Usage:$ ./secure_move -hUsage:\t./secure_move: &lt;path&gt; &lt;destination&gt;./secure_move takes a file located at &lt;path&gt;, copies the file into memorythen wraps the file to 80 characters maximum andoverwrites the file 3 times to prevent recovery.Then it writes to the file at &lt;desination&gt; the following\t- The first five lines (after wrapping)\t- A newline\t- The last five lines (after wrapping)\t- A newline\t- The whole fileYour boss at ShadyCorp is very paranoid. To test that his program, he wrote a test suite himself. Your co-worker went home sick that day. Now, he hasn’t been heard from in two weeks; you don’t ask any questions. The boss sent you an email to fix the code that your co-worker gave you. Since you are the Boss’ cousin, he gives you the test cases that you failed and promises to run the test cases every day (your mom is very convincing).But, he imposed a penalty. You are currently passing some test cases, but you won’t get any points for those because your co-worker wrote that code. You are failing four test cases. If you get those test cases to pass, you get full points for this lab and keep your job at ShadyCorp. If you mess any test cases that you were passing before, you will lose one point. The boss assures that the code is well sectioned, so you won’t have to even look at the files that aren’t related to the test case.The output of the file should be:&lt;first 5 lines&gt;&lt;newline&gt;&lt;last 5 lines&gt;&lt;newline&gt;&lt;the whole file&gt;&lt;newline&gt;Where &lt;newline&gt; = '\\n'.A line is defined as zero or more characters terminated by a newline character.Problem 1: No Such FileIf the file does not exist, the program currently doesn’t work. Instead of crashing, exit with a status NO_FILE_RETURN_CODE found in secure_move.cProblem 2: Address SpaceDue to the new meltdown and spectre vulnerabilities, your bosses are worried to no end about shadier corporations trying to get your data. There are some software patches available to detect against variations of meltdown, the ones against the variation of spectre are few and far between. The security gurus have found was of detecting spectre attacks and can now track attacks against processes. They are able to get the address and all other parameters of the affected area, but they need to know what region of memory was read. For instance, if a c library function was read, then no big deal. But if one of the file* structs was read, ShadyCorp’s shady dealings could be uncovered. As such, they want you to print out the following in descending order.  The address of main  The address of strdup  A string literal (e.g char *ptr = \"abs\")  A malloc’d array  Address of argcHint: Do you need to check the order every time? What do you know about process address spaces?EntrypointThe driver program is in secure_move.c. There, we do some basic input validation, open a file, shred it, and print the output that your boss wants. I wonder where it could be going wrong…Debugging GuideRead this to get started with debugging!Manual TestingIn the end, your boss was nice enough to give you some test cases. In files/, there are a few files that your boss will use to test the program with. One is files/blank.txt, which you can use to test blank input. Another is files/final.txt, which is full of secret business-y type stuff. In order to run a test case, try the following commands:$ make reset # Make sure to do this before test cases$ make$ ./secure_move files/final.txt files/final_out.txt$ diff files/final_out.txt files/final_sol.txt$ # If diff has nothing to complain about you are good!$ # You may want to make sure files/final.txt is overwritten though...CS 241 MakefileAll the assignments in this class will use a similar makefile.Note: This is not a class about makefile programming, so you will not need to know the advanced parts of makefiles (pattern matching, expansion phases, etc). Still, it is important that you know a little bit about how they work for a future assignment.Here is what a typical makefile will look like:# directory to store object filesOBJS_DIR = .objs# define the EXESEXE_SHELL=shellEXES_STUDENT=$(EXE_SHELL)OBJS_SHELL=$(EXE_SHELL).o format.o# set up compilerCC = clangINCLUDES=-I./includes/WARNINGS = -Wall -Wextra -Werror -Wno-error=unused-parameterCFLAGS_DEBUG   = -O0 $(INCLUDES) $(WARNINGS) -g -std=c99 -c -MMD -MP -D_GNU_SOURCE -DDEBUGCFLAGS_RELEASE = -O2 $(INCLUDES) $(WARNINGS) -g -std=c99 -c -MMD -MP -D_GNU_SOURCE# set up linkerLD = clangLDFLAGS = -Llibs/ -lprovided.PHONY: allall: release# build types# run clean before building debug so that all of the release executables# disappear.PHONY: release.PHONY: debugrelease: $(EXES_STUDENT)debug: clean $(EXES_STUDENT:%=%-debug)# include dependencies-include $(OBJS_DIR)/*.d$(OBJS_DIR):@mkdir -p $(OBJS_DIR)# patterns to create objects# keep the debug and release postfix for object files so that we can always# separate them correctly$(OBJS_DIR)/%-debug.o: %.c | $(OBJS_DIR)$(CC) $(CFLAGS_DEBUG) $&lt; -o $@$(OBJS_DIR)/%-release.o: %.c | $(OBJS_DIR)$(CC) $(CFLAGS_RELEASE) $&lt; -o $@# exes$(EXE_SHELL)-debug: $(OBJS_SHELL:%.o=$(OBJS_DIR)/%-debug.o)$(LD) $^ $(LDFLAGS) -o $@$(EXE_SHELL): $(OBJS_SHELL:%.o=$(OBJS_DIR)/%-release.o)$(LD) $^ $(LDFLAGS) -o $@.PHONY: cleanclean:rm -rf .objs $(EXES_STUDENT) $(EXES_STUDENT:%=%-debug)This looks scary, but if you Google some makefile basics and carefully read the comments it should start to make sense. These are the things you will need to know, at the minimum:  Compile the assignment:make  Clean up the assignment directory:make clean  Compile a debug-able version of your code that you can use gdb on:make debug  Compile a release version of your assignment that you test with:make releaseThe Outline  Log into your VM  Clone or Update your git repository on your VM  Fix the code using test cases you develop          Look through the code in the files!      Use printf’s!      Use valgrind!      Use GDB!      Run on the given files and see if the output is what you expect.      Problem 1: See why the file is not shreded      Problem 2: See why the program crashes on non-existant-file      Problem 3: Are there any memory errors or leaks (check valgrind?)      Problem 4: What does the address space look like?        git commit -a -m \"My Submission\" (commit your work to git).Lab AttendancePart of your grade in this class relies on you attending labs. Towards the end of every lab, we will ask you to swipe out (swipe your i-card). You may only leave early if you show that you have finished the lab to your lab attendant or if the lab attendant calls time. If you are more than ten minutes late to class, then your lab attendant reserves the right to not swipe you out for the day. You may never swipe yourself out without your lab attendant’s consent. Any violation will result in a zero in lab attendance for the semester.Due to seating limitations, you are required to go to the lab section you signed up for. If you wish to go to any other lab section, you may get permission from the TA of another section to go to their section, provided that either:  You will be working on your laptop in the room  There is seating available where registered students get priority.You must email the TA of that lab section beforehand.You can still get credit for attending a different section due to special or occasional circumstances by making arrangements with the graduate assistant (GA) at cs241admin@illinois.edu. However, you must change your registered lab if you start regularly going to a different lab. Please contact Holly Bagwell in the academic office (SC 1210) to change your section without having to drop your enrollment.We will never grant exemptions for lab attendance. If you have an interview, then you are just going to have to use your lab attendance drop. You also can not make up lab attendance. Be warned that forgetting to swipe out is not a valid excuse—your lab attendant is not allowed to vouch for your attendance."
  }
    ,
    
  {
    "url_slug": "mad-mad-access-pattern",
    "url": " /mad_mad_access_pattern",
    "learning_objectives": ["Working with files","mmap()","fseek() and fread()"],
    "wikibook": ["Files, Part 1: Working with files","File System, Part 6: Memory mapped files and Shared memory"],
   "title": "Mad Mad Access Pattern",
   "content": "Mapping InventoryYou’ve landed an internship at Zing!, a search enginestart-up.  Your first project is to develop a keyword advertisementinventory tool.Advertisers can “buy” keywords such that their ad is shown whenevera user does a search that contains one of their keywords. For example,if a user searches for “stapler”, they will see ads for an office supplycompany who bought that keyword.Before buying a keyword, advertisers want to know, “How much will thiscost me?”  To compute that, they’ll need to know how often the keywordis searched for, and how valuable the word is.  For example “how” isa very common word but has little value. “Donate” is less common buthighly valuable, because a user searching for “donate” is probably willingto do so.The intern before you scanned through a large volume of search logsto determine the frequency and value of each word.  Your job is toperform efficient searches on the data file she created. This file isexpected to grow to be very large, larger than will fit in memory, soyou will need to access it without reading it all into memory.Data File StructureThe file is structured like a binary search tree, where each tree nodeis an instance of this structure:typedef struct {uint32_t left_child;  // offset of node containing left childuint32_t right_child; // offset of node containing right child// Offsets are relative to the beginning of the file.// An offset of zero means the child does not exist.uint32_t count;  // number of times the word occurs in the data setfloat price;     // price of the wordchar word[0];    // contents of the word, null-terminated} BinaryTreeNode;The first 4 bytes of the input file are the letters “BTRE”. Anyfile which does not start with these 4 bytes is an invalid data file.The root node is stored at offset 4 in the file. Each uint32_t andfloat is stored in little-endian format (the same as the processorsyour VMs use, so no conversion will be necessary). “word” is an arrayof ASCII characters at the end of each structure, and it is anull-terminated string.  There is no limit on the length of a word inthe file or the length of the words your program will look up.Remember the properties of a binary search tree: if a node has a leftchild, that child’s value is less than the node. If it has a right child,that child’s value is greater than the node.Comparison among nodes in this assignment is defined by their word’s  int strcmp(const char *s1, const char *s2). In other words:BinaryTreeNode *node = ...a node from the file...if (node-&gt;left_child) {  BinaryTreeNode *left = ...load node at node-&gt;left_child...  assert(strcmp(left-&gt;word, node-&gt;word) &lt; 0);}if (node-&gt;right_child) {  BinaryTreeNode *right = ...load node at node-&gt;right_child...  assert(strcmp(right-&gt;word, node-&gt;word) &gt; 0);}Note that none of the binary search trees we give you will have duplicate keys.FilesYou’ll be given:  tree.h - contains the struct definition above and a detailed description   of the data in sample.data  Makefile - the makefile you should use to build lookup1 and lookup2  sample.data - a small file containing the words “sample”,   “word”, “list”, “for”, “this”, and “program”  utils.h - Printing functions for you to use  input_file - Sample input to create_file executable.  create_file - Creates binary tree structured data file corresponding to input_file. This will be used for your test cases.  print_file - Prints out human readable form of binary tree structured file from above.Make two versions of your program. Both should produce thesame results, but using different file access methods.Version 1: fseek / freadWhen reading a node from the file, use fseek() to jump to thecorrect position and read the node with fread() and/or fgetc().You may not use mmap() for this part.Put the code for this in lookup1.c.Version 2: mmapUse mmap() to map the entire file into memory withoutreading any part of the file directly. When reading a node from the memory mapped file, usepointer arithmetic to jump to the correct position and read the nodeusing regular pointer dereferencing.mmap IntroductionPut the code for this in lookup2.c.Notice that you can use only mmap() to map the WHOLE file for this version. Do not use other functions to read files.Sample usagelookup1 &lt;data_file&gt; &lt;keyword&gt; [&lt;keyword&gt; ...]lookup2 &lt;data_file&gt; &lt;keyword&gt; [&lt;keyword&gt; ...]% ./lookup1 sample.data list sample werdlist: 12 at $0.04sample: 25 at $10.60werd not found% ./lookup2 sample.data list sample werdlist: 12 at $0.04sample: 25 at $10.60werd not foundTesting notes  You are given reference files! Compare your outputs with ./lookup1-reference and ./lookup2-reference :)  Write your test cases to include comparison of performance between the two versions (lookup1 and lookup2). Think about which one is faster and why.  In order to generate different binary tree structured data files based on input required for each test case, use the create_data executable.See input_file for sample input to this executable.  The print_file executable will provide a human readable form of a binary tree structured data file generated from create_data.Error cases:  If run with less than 2 arguments, your program should print an errormessage describing the arguments it expects and exit with error code 1.  If the data file cannot be read or the first 4 bytes are not“BTRE”, print a helpful error message and exit with error code 2.For each word that is found, print its count and its price, where theprice is always printed with exactly two digits to the right of the decimalpoint."
  }
    ,
    
  {
    "url_slug": "malloc",
    "url": " /malloc",
    "learning_objectives": ["Memory Allocation and Management","Performance Optimization","Developing in a Restricted Environment"],
    "wikibook": ["Memory, Part 1: Heap Memory Introduction","Memory, Part 2: Implementing a Memory Allocator"],
   "title": "Malloc",
   "content": "IntroductionIn the past, you have been using malloc to allocate memory on the heap. In this MP, you will be implementing your own version of malloc. By the end of this MP, you will theoretically be able to use your own malloc to run any program you wish.OverviewYou should write your implementations of calloc, malloc, realloc, and free in alloc.c. alloc.c will be the only file we test.Don’t modify mcontest.c, contest.h, or contest-alloc.so. Those files create the environment that replaces the standard glibc malloc with your malloc. These files will be used for testing.Your malloc must allocate heap memory using sbrk. You may not use files, pipes, system shared memory, mmap, a chunk of pre-defined stack memory, other external memory libraries found on the Internet, or any of the various other external sources of memory that exist on modern operating systems.A Bad ExampleMemory allocation seems like a mystery, but in actuality, we are making a wrapper around the system call sbrk. Here’s a really simple implementation of malloc:void *malloc(size_t size) {    return sbrk(size);}As you can see, when we request size bytes of memory, we call sbrk(size) to increase the heap by size bytes. Then, we return a pointer to this memory, and we’re done. Simple!Here is our implementation of free:void free(void *ptr) {}This is a “correct” way to implement free. However, the obvious drawback with our implementation is that we can’t reuse memory after we are done with it. Also, we have not checked for errors when we call sbrk, and we have not implemented realloc or calloc.Despite all of this, this is still a “working” implementation of malloc. So, the job of malloc is not really to allocate memory, but to keep track of the memory we’ve allocated so that we can reuse it. You will use methods that you’ve learned in class and practiced in the Mini Valgrind lab to do this.Testing Your CodeIn order to run your solution on the testers, run ./mcontest with the tester you want. You must do this, or your code will be run with the glibc implementation!Example:./mcontest testers_exe/tester-1Memory failed to allocate![mcontest]: STATUS: FAILED=(256)[mcontest]: MAX: 0[mcontest]: AVG: 0.000000[mcontest]: TIME: 0.000000We’ve also distributed a bash script run_all_mcontest.sh to run all testers. We design the script so that you caneasily test your malloc implementation. Here is how you use the script:./run_all_mcontest.shIt will automatically make clean and make again, and then run each test case in the testers folder. If you want to skipsome test cases, you can do:./run_all_mcontest.sh -s 1 2 3where 1, 2, and 3 are the tests you want to skip. You can skip as many as you like.Here is what some of our error codes mean:11: (SIGSEGV) Segmentation fault15: (SIGTERM) Timed out65, 66: Dynamic linking error67: Failed to collect memory info68: Exceeded memory limit91: Data allocated outside of heap92: Data allocated exceeds heap limitGood PracticesSince you can implement your malloc in whatever way you want, you may end up with a huge chunk of messy code that’s hard to debug. Here are some suggestions for organizing and maintaining your code better:  Build simple functions before you add advanced features. In other words, make sure your program does what you want it to do before moving on to optimize it.  Separate the functionality of your program into smaller chunks of independent code. For example, if you find that you’re frequently splitting a block of memory into two blocks, you probably want to write a split function instead of copy-pasting the splitting code every time you need to split.  Keep your code readable. This can be naming your variables appropriately or commenting your code well. This will really help you understand what your code is doing when you look back at them three days later!Debugging./mcontest runs an optimized version of your code, so you won’t be able to debug with gdb. To solve this, we have provided another version called ./mreplace which uses a version of your malloc compiled without optimization, so you can debug with gdb. Here’s an example, running tester 2 with gdb:gdb --args ./mreplace testers_exe/tester-2Since ./mreplace calls fork, you need to change the follow-fork-mode in gdb to be able to set a breakpoint in your alloc.c:(gdb) set follow-fork-mode child(gdb) break alloc.c:322No source file named alloc.c.Make breakpoint pending on future shared library load? (y or [n]) yBreakpoint 1 (alloc.c:322) pending.(gdb) runNote: if you terminate your running program and run it again, i.e. if you do this:(gdb) runThread 2.1 \"tester-2\" hit Breakpoint 1, malloc (size=1) at alloc.c:323323    return ptr;(gdb) killKill the program being debugged? (y or n) y[mcontest]: STAUS: FAILED. SIGNAL=(9)[mcontest]: MAX: 0[mcontest]: AVG: 0.000000[mcontest]: TIME: 0.012000(gdb) runStarting program: malloc/testers_exe/tester-2 Memory was allocated, used, and freed!it will no longer use your own implementation, and therefore will not stop at the breakpoints you set, and will use the glibc implementations of malloc/calloc/etc. This is because of the way gdb handles dynamically loaded libraries.Real ProgramsBoth mcontest and mreplace can be used to launch “real” programs (not just the testers). For example:# ignore the warning about an invalid terminal, if you get it./mreplace /usr/bin/less alloc.cor./mcontest /bin/lsThere are some programs that might not work correctly under your malloc, for a variety of reasons. You might be able to avoid this problem if you make all yourglobal variables static. If you encounter a program for which this fix doesn’t work, post on Piazza!GradingHere is the grading breakdown:  Correctness (75%)          Part 1 (25%): tests 1-6 complete successfully - due 02/26 11:59pm      Part 2 (50%): tests 1-12 complete successfully - due 03/05 11:59pm        Performance (25%): Points only awarded if all part 2 testers completesuccessfully - due with part2There are 12 testcases in total. For part 1, you will be graded using tests 1through 6. For part 2, you will be graded using tests 1 to 12 (tests 1 through 6get graded twice). Tester 13 is not graded.There are also performance points, which you are only eligible for if you passall the testcases. Your malloc will be compared against the glibc version ofmalloc, and given a base performance score as a percentage (accounting forruntime, maximum memory usage, and average memory usage). The base score iscalculated using the formula from the contest section below; higher percentagesare better. Performance points are then awarded in buckets:  Better than or equal to 85% of glibc: Full 25% awarded.  75-85% (include 75%, exclude 85%): 20% awarded.  60-75%: 15% awarded.  40-60%: 10% awarded.  40% and worse: 0% awarded.So, let’s work out some scenarios:  Scenario 1: A student gets tests 1 through 6 working for part1 and misses 2tests on part2. Then they get all of the correctness points for part1, 10/12of the correctness points for part2 and none of the performance points. Thusthis student will receive a (6 / 6) * 25 + (10 / 12) * 50 + 0 = 66.67%.  Scenario 2: A student gets none of the tests working for part1 and getseverything working for part2 and beats glibc. Then they get none of thecorrectness points for part1, 12/12 of the correctness points for part2, andthe performance points. This student will receive a(0 / 6) * 25 + (12 / 12) * 50 + 25 = 75.00%.  Scenario 3: A student gets tests 1 through 6 working for part1, then they getall the tests except test 4 working for part2. Then they get all of thecorrectness points for part1, 11/12 of the correctness points for part2, butthey will not receive any of the performance points. This student willreceive a (6 / 6) * 25 + (11 / 12) * 50 + 0 = 70.83%.      Scenario 4: A student gets tests 1 through 6 working for part1, then they getall of the tests working for part2, but they can only get to 65% ofglibc. In this case, they get all of the correctness points for part 1, allof the correctness points for part 2, but only 15% performance points. So,they get (6 / 6) * 25 + (12 / 12) * 50 + 15 = 90.00%    We modify the allocation numbers slightly when we actually grade.ContestView the malloc contest here!The malloc contest pits your memory allocator implementation against your fellow students. There are a few things to know:  The test cases used for grading will be randomized with a different seed every day.  There may be additional, more advanced tests added which won’t count for anything but the contest.  The memory limit is 2.500GB.  To submit your program to the contest, you simply commit to Subversion. Your most recent SVN submission will be fetched somewhat frequently.  We will assign a score to each of the three categories (max heap, average heap, and total time) based on how well your program performs memory management relative to a standard solution.  You can pick a nickname in nickname.txt. You will show up as this name on the contest webpage.  On the webpage, each test will either be green, which signifies that you passed the test, or red, which signifies that you failed the test.Scores and rankingYour score will be computed by the following formula:Where:   is the number of tests   in the subscript means reference implementation, and  means student’s implementation   is the time reference implementation spends on test    is the time student spends on test    is the average memory used by reference implementation on test    is the average memory used by student implementation on test    is the max memory used by the reference implementation on test    is the max memory used by the student implementation on test Higher scores are better.Note: We reserve the right to slightly modify constants inside the formula to ensure fair grading and prevent gaming the system. However, the basic idea will not be changing, and whatever we use will be the same for everyone.Example 1.If a student implementation  performs like the reference implementation, which means it spends the same time and memory as the reference, then ’s score will be:Example 2.If a student implementation  performs the same as the reference implementation on memory usage, but is twice as slow (meaning ), then ’s score will be:Example 3.If a student implementation  performs three times better than the reference implementation, which means , , and , then ’s score will be:WARNING: As the deadline approaches, the contest page will refresh more slowly. There are 400 students, 12 test cases, and up to a minute or so. It will only retest a student’s code if it has been updated, but many more students will be updating their code causing longer waits. Start early, and don’t become reliant on the contest page by testing locally!"
  }
    ,
    
  {
    "url_slug": "mapping-memory",
    "url": " /mapping_memory",
    "learning_objectives": ["Memory Mapped Files","File Streams","Virtual Memory"],
    "wikibook": ["File System, Part 6: Memory mapped files and Shared memory"],
   "title": "Mapping Memory",
   "content": "Required ReadingRead this in the wikibook before starting the lab.  Introduction to Virtual MemoryOverviewIn this lab you will be implementing mmap! Note that what you will implement in this lab has a slightly different interface than the system call mmap. The basic concepts however, are the same. This lab will build off of the mmu you implemented back in Ideal Indirection. We have provided all of the mmu functionality. Before starting you should go through all the provided files and make sure that you understand what functions are available to you.You do not need to worry about two processes reading from the same mmap file.You will only have to write code in mmap.c. The functions you need to implement are detailed below.Good luck!mmap_createCreates a new mmap object. This involves setting all fields of the mmap struct defined in mmap.h and reproduced below.typedef struct {    mmu *mmu;    FILE *stream;    size_t length;    uintptr_t start_address;} mmap;You will need to create a new mmu struct (check mmu.h for functions that do this!) and make sure you add the process with pid DEFAULT_PID defined in mmap.h. You will also need to create a segment corresponding to the segment type MMAP. It is your job to find out how many pages are needed for this segment.mmap_readRead from the mmap’d file into a buffer provided by the user. You will need to use the mmu to perform translations from virtual memory into physical addresses.mmap_writeSame as mmap_read, but with writes instead of reads.munmapCleanup and destroy the mmap object. Remember that you need to copy dirty pages back to the file on disk. Be sure to close the file stream and free all memory allocated here.Testing  Make sure you throughly test your code as usual. We have provided some tests cases, but we encourage you to write your own as well. Use the provided test cases as a reference to learn to create tests with good coverage."
  }
    ,
    
  {
    "url_slug": "mapreduce",
    "url": " /mapreduce",
    "learning_objectives": ["Interprocess Communication (IPC)","Pipes","Files and File Descriptors","MapReduce","Jeff Dean"],
    "wikibook": ["Pipes, Part 1: Introduction to pipes","Pipes, Part 2: Pipe programming secrets"],
   "title": "Mapreduce",
   "content": "MapReduceIn 2004, Google released a general framework for processing large data sets on clusters of computers.We recommend you read this link on Wikipedia for a general understanding of MapReduce.Also, this paper written by Jeffrey Dean and Sanjay Ghemawat gives more detailed information about MapReduce.However, we will explain everything you need to know below.To demonstrate what MapReduce can do, we’ll start with a small dataset–three lines of text:Hellothereclass!The goal of this MapReduce program will be to count the number of occurrences of each letter in the input.MapReduce is designed to make it easy to process large data sets, spreading the work across many machines. We’ll start by splitting our (not so large) data set into one chunk per line.                   Chunk #1      Chunk #2      Chunk #3                  Input      “Hello”      “there”      “class!”      Map. Once the data is split into chunks, map() is used to convert the input into (key, value) pairs.In this example, our map() function will create a (key, value) pair for each letter in the input, where the key is the letter and the value is 1.                   Chunk #1      Chunk #2      Chunk #3                  Input      “Hello”      “there”      “class!”              Output      (h, 1)      (t, 1)      (c, 1)                     (e, 1)      (h, 1)      (l, 1)                     (l, 1)      (e, 1)      (a, 1)                     (l, 1)      (r, 1)      (s, 1)                     (o, 1)      (e, 1)      (s, 1)      Reduce. Now that the data is organized into (key, value) pairs, the reduce() function is used to combine all the values for each key.In this example, it will “reduce” multiple values by adding up the counts for each letter.Note that only values for the same key are reduced.Each key is reduced independently, which makes it easy to process keys in parallel.                   Chunk #1      Chunk #2      Chunk #3                  Input      (h, 1)      (t, 1)      (c, 1)                     (e, 1)      (h, 1)      (l, 1)                     (l, 1)      (e, 1)      (a, 1)                     (l, 1)      (r, 1)      (s, 1)                     (o, 1)      (e, 1)      (s, 1)              Output      (a, 1)                                   (c, 1)                                   (e, 3)                                   (h, 2)                                   (l, 3)                                   (o, 1)                                   (r, 1)                                   (s, 2)                                   (t, 1)                    MapReduce is useful because many different algorithms can be implemented by plugging in different functions for map() and reduce().If you want to implement a new algorithm you just need to implement those two functions.The MapReduce framework will take care of all the other aspects of running a large job: splitting the data and CPU time across any number of machines, recovering from machine failures, tracking job progress, etc.The MPFor this MP, you have been tasked with building a simplified version of the MapReduce framework.It will run multiple processes on one machine as independent processing units and use IPC mechanisms to communicate between them.map() and reduce() will be programs that read from standard input and write to standard output.The input data for each mapper program will be lines of text.Key/value pairs will be represented as a line of text with “: “ between the key and the value:key1: value1key two: values and keys may contain spaceskey_3: but they cannot have colons or newlinesMany mappers, one reducerYou’ll spread the work across multiple instances of the mapper executable.[...input_file...]|       |       |MAP1  MAP2  MAP3    \\  |  /     REDUCE       |  output_fileThe input file will need to be split into chunks, with one chunk for each mapper process.To split the input file, we’ve supplied the tool splitter.Please run it without arguments for a brief explanation of how it works.You’ll start up one instance of splitter for each mapper, using a pipe to send stdout of splitter to stdin of the mapper program.  splitter inputfile 3 0  |  |     splitter inputfile 3 1  |     |  |     |    splitter inputfile 3 2  |     |    |MAP1  MAP2  MAP3   \\  |  /    REDUCE      | output_fileCommand line:./mapreduce &lt;input_file&gt; &lt;output_file&gt; &lt;mapper_executable&gt; &lt;reducer_executable&gt; &lt;mapper_count&gt;Sample Usage$ ./mapreduce test.in test.out ./my_mapper ./my_reducer 3Your program will:  Split the input file into  parts and pipe the contents into  different mapper processes (use splitter).  Write the output of the reducer process to the output file.Remember to close all the unused file descriptors!This too can be done in the Unix shell:    $ (./splitter inputfile 3 0 | my_mapper ; \\       ./splitter inputfile 3 1 | my_mapper ; \\       ./splitter inputfile 3 2 | my_mapper ; ) | my_reducer &gt; test.outThings we will be testing for:  Inputs of varying size  Different types of mapper and reducer tasks  Both mapper and and reducer generating accurate output to stdout file descriptor independently  Splitter being used correctly to generate equally sized input data for each mapper  All mappers being run in parallel resulting in at least 2x performance speedup for the pi executable  No memory leaks and memory errors when running the applicationThings that will not be tested for:  Illegal inputs for either the mapper or reducer (Input data in a format other than as described above)  Invalid mapper or reducer code (mappers or reducers that do not work)  Key Value pairs that are larger than a pipe buffer of 4096 bytes.Building and RunningBuildingThis MP has a very complicated Makefile, but, it defines all the normal targets.make # builds provided code and student code in release modemake debug # builds provided code and student code in debug mode# there is no tsan target because threading is not needed for this MP.Input DataTo download the example input files (books from Project Gutenberg), use the Makefile:make dataYou should now see data/dracula.txt and data/alice.txt in your MP folderRunning Your CodeWe have provided the following mappers:  mapper_wordcount  mapper_lettercount  mapper_asciicount  mapper_wordlengths  mapper_piThese each be used anywhere we specify my_mapper in these docs.And the following reducers:  reducer_sum  reducer_piThese each be used anywhere we specify my_reducer in these docs.For example, if you wanted to count the occurrences of each word in Alice in Wonderland, you can run and of the following./mr1 data/alice.txt test.out ./mapper_wordcount ./reducer_sum 4Record Setting Pi CodeAs well as the simple mapper/reducer pairs, we also have also included some really cool pi computation code (see this for more info).For instructions on how to use the pi code, see the file pi/README.txt.Note that we do not currently compile this with an NVIDIA compiler, so you willnot be able to use the CUDA version of this code (which we have not tested) unless you fiddle with the Makefile."
  }
    ,
    
  {
    "url_slug": "mini-valgrind",
    "url": " /mini_valgrind",
    "learning_objectives": ["Using metadata for memory bookkeeping","Memory management and linked lists","Learning what Valgrind does","Preparation for the Malloc MP"],
    "wikibook": ["Memory, Part 1: Heap Memory Introduction","Memory, Part 2: Implementing a Memory Allocator","Memory, Part 3: Smashing the Stack Example"],
   "title": "Mini Valgrind",
   "content": "Quiziz/FeedbackTo get attendence credit for this week’s lab session, please fill out the google form at this link and enter your netid and quiziz nickname. We also have some feedback questions about last week’s lab, to help us make CS 241 better!OverviewFor this lab, you will be implementing a small version of Valgrind called mini_valgrind. Valgrind is a great tool for monitoring memory usage, and you have likely used it earlier in this class. Your version will print out a summary of the memory leaks in a particular C program. This lab is meant in part as preparation for your Malloc MP, introducing some topics and techniques which you will find helpful there.Main ConceptsThe main concept of this lab is that we can track each block of memory using some extra space before each allocation (called metadata). We have provided you with a struct meta_data in mini_valgrind.h. The metadata is set up as a linked list of nodes which store information for each allocated block. Each node stores the amount of memory requested, the filename and location of the instruction that made the request, and a pointer to the next allocated block.Here’s an illustration:When the program is about to exit, we can look at this metadata list to see what the user hasn’t freed. These are your memory leaks.If you feel that you need a refresher on linked lists or other prerequisite concepts, feel free to ask a CA or TA one-on-one.mini_valgrind.cWe have set up mini_valgrind to dynamically replace every call to malloc, calloc, realloc, and free in the user’s program with a call to mini_malloc, mini_calloc, mini_realloc, and mini_free, respectively. You will be implementing these four functions in order to track the memory the user allocates.Inside mini_valgrind.c, it is safe to call the real versions of malloc and related functions. You should not be writing your own implementation of malloc using sbrk or related system calls.See the mini_valgrind.h header file for details.Global VariablesIn addition to the four functions above, you’ll need to maintain the following global variables:      head: a pointer to the head of a linked list storing all the metadata corresponding to allocated memory blocks        total_memory_requested: stores the total number of bytes of memory requested by the user throughout the lifetime of the program (excluding metadata)        total_memory_freed: stores the total number of bytes of memory freed by the user throughout the lifetime of the program        invalid_addresses: stores the number of times the user has tried to realloc or free an invalid pointer  Since we keep track of this data, we can show the user how much memory they’ve allocated, just like the real Valgrind. We can also find out how much memory a user might be leaking, by subtracting total_memory_freed from total_memory_requested.If you look in mini_valgrind.h, you’ll notice that these are declared as extern variables. This allows variables to live somewhere else beside the line where you are ‘declaring’ them, pushing the responsibility of providing a real location in memory for these variables elsewhere and letting the linker resolve the variable name to where memory is actually reserved. This link has a nice explanation of how to use this. In order to prevent your code from crashing, you will have to declare these variables as globals in mini_valgrind.c.TestingYou’ll want to test your mini_valgrind thoroughly.We’ve provided you with a test.c file that you can put test cases in. Running make will generate a ./test executable alongside mini_valgrind. You can use it like the regular Valgrind:./mini_valgrind ./testThe output should look familiar!Note that we always build ./test with debugging symbols (gcc -g), so mini_valgrind can find the line numbers corresponding to memory leaks.To debug mini_valgrind itself, you can use gdb like usual. Use make debug to generate a version of mini_valgrind with debugging symbols:gdb --args ./mini_valgrind-debug ./testWarning: printf()Be careful with printf in Mini Valgrind! By default, stdout is buffered, so printf calls malloc internally to create a buffer.If you call printf inside of mini_malloc, it will allocate its buffer using the real malloc (since calls to malloc inside mini_valgrind.c use the real version), but then free it using your mini_free since the cleanup happens outside of mini_valgrind.c. As you can imagine, this results in unexpected behavior.Instead, you can use fprintf(stderr, ...), which is unbuffered, or use write, but the easiest solution may be to turn off buffering for stdout:  setvbuf(stdout, NULL, _IONBF, 0);Warning: extra free() callNote that there will be some extra calls to your mini_free function at the end of the program.This is an unfortunate side effect of how we implement mini_valgrind internally. In mini_hacks.c, we call a cleanup function defined in the C library (__libc_freeres) at the end of the program, which calls free several times to deallocate any internal buffer created by the C library. Here is an example of what the backtrace looks like in gdb:Breakpoint 1, mini_free (payload=0x0) at mini_valgrind.c:142(gdb) bt#0  mini_free (payload=0x0) at mini_valgrind.c:142#1  0x00007ffff7bd3d4a in free (ptr=0x0) at mini_hacks.c:193#2  0x00007ffff797c380 in __GI___libc_freeres () at set-freeres.c:42#3  0x00007ffff7bd44ba in finalize () at mini_hacks.c:334#4  0x00007ffff7bd3fa0 in print_leak_info () at mini_hacks.c:365...This should not affect your implementation of mini_free. However, do be aware of the extra free calls when you’re debugging your program, just so that you’re not confused about where they’re coming from.ExampleHere’s a basic test case to check your progress.Say you had the following in your test.c file:#include &lt;stdlib.h&gt;int main() {    void *p1 = malloc(30);    void *p2 = malloc(40);    void *p3 = malloc(50);    free(p2);    return 0;}mini_valgrind’s output should look like this (of course, your process ID and addresses might be different):==25219== Mini-Valgrind==25219====25219== LEAK REPORT:==25219==    Leak origin: main (test.c:5)==25219==    Leak size: 50 bytes==25219==    Leak memory address: 0x1009790==25219====25219==    Leak origin: main (test.c:3)==25219==    Leak size: 30 bytes==25219==    Leak memory address: 0x10096f0==25219====25219== Program made 0 bad call(s) to free or realloc.==25219====25219== HEAP SUMMARY:==25219==    Total memory requested: 120 bytes==25219==    Total memory freed: 40 bytes==25219==    Total leak: 80 bytesNotice that leaks are reported most-recent-first. This is because we insert new metadata at the head of the linked list.Other ProgramsYou can also run mini_valgrind on other programs, like echo:$ ./mini_valgrind echo 'Hello, world!'==19506== Mini-ValgrindHello, world!==19506====19506== Program made 0 bad call(s) to free or realloc.==19506====19506== HEAP SUMMARY:==19506==    Total memory requested: 1068 bytes==19506==    Total memory freed: 1068 bytes==19506==    No leaks, all memory freed. Congratulations!It should work on most standard utilities, but just be aware that it won’t work on everything. You’ll notice it may generate different output than Valgrind or may even crash when run on complex software like python. This is okay; writing a memory checker is hard! You only need to implement what we’ve described above and in mini_valgrind.h.Optional Fun: Sentinel Value!This part of the assignment in this section is not graded. However, sentinel value is a pretty cool concept and we encourage you to try to implement it.So, suppose that our users of mini_valgrind are terrible at coding. They wrote past the end of their allocation (buffer overflow) and corrupted the memory beyond what’s allocated to them. Can we detect this kind of memory corruption and warn them? The answer is yes, by using sentinel value!Sentinel value is a chunck of pre-defined bits at the end of an allocated memory. In other word, each allocation would look like this:[meta_data][---actual data---][sentinel_value]On every operation, we would check that the sentinel value is still the same as it was pre-defined. If the sentinel value has changed, then we know for certain that the user has corrupted memeory.In your mini_valgrind, you will use the magic number 0xCAFEBABE for sentinel value. (Why x0CAFEBABE?)Implementation:  Add the bits 0xCAFEBABE to the end of every allocation. (Do you need to do it for realloc?)  Check if the sentinel value of a previously allocated buffer has changed in mini_realloc and mini_free.  If so, print out a warning to the user with fprintf(stderr, ...). (Do not print to stdout!)If you want to test out your implementation, you can add the following code to your test.c and see if you get any warning when running ./mini_valgrind ./test:char* ptr = malloc(10);*(ptr + 10) = 'a';free(ptr);Behind the ScenesThis section describes some details of how we’ve implemented mini_valgrind. You are encouraged, but not required, to understand this.We compile your mini_ functions, along with some extra code from mini_hacks.c, into a shared object called mini_valgrind.so.mini_hacks.c has two main jobs:  Create wrappers around malloc and the other functions to make sure they use your replacement functions when the user’s program calls them, while still letting you use the real versions within your code  Print out leak info at program exitThe actual ./mini_valgrind program is implemented in mini_main.c. When you run ./mini_valgrind ./test, we use an environment variable called LD_PRELOAD to run the ./test program using the code in mini_valgrind.so. Essentially, it replaces normal references to the built-in malloc with references to our version.“But,” you may ask, “how do we call the real version of malloc if we’ve replaced it with our own version of it?” The trick is a function called dlsym, which allows us to bypass LD_PRELOAD and ask for a function pointer to the real malloc. This is all handled within mini_hacks.c."
  }
    ,
    
  {
    "url_slug": "mr0",
    "url": " /mr0",
    "learning_objectives": ["Interprocess Communication (IPC)","Pipes","Files and File Descriptors","MapReduce","Jeff Dean"],
    "wikibook": ["Pipes, Part 1: Introduction to pipes","Pipes, Part 2: Pipe programming secrets"],
   "title": "Map Reduce 0 - Lab Edition",
   "content": "MapReduceIn 2004, Google released a general framework for processing large data sets on clusters of computers.We recommend you read this link on Wikipedia for a general understanding of MapReduce.Also, this paper written by Jeffrey Dean and Sanjay Ghemawat gives more detailed information about MapReduce.However, we will explain everything you need to know below.To demonstrate what MapReduce can do, we’ll start with a small dataset–three lines of text:Hellothereclass!The goal of this MapReduce program will be to count the number of occurrences of each letter in the input.MapReduce is designed to make it easy to process large data sets, spreading the work across many machines. We’ll start by splitting our (not so large) data set into one chunk per line.                   Chunk #1      Chunk #2      Chunk #3                  Input      “Hello”      “there”      “class!”      Map. Once the data is split into chunks, map() is used to convert the input into (key, value) pairs.In this example, our map() function will create a (key, value) pair for each letter in the input, where the key is the letter and the value is 1.                   Chunk #1      Chunk #2      Chunk #3                  Input      “Hello”      “there”      “class!”              Output      (h, 1)      (t, 1)      (c, 1)                     (e, 1)      (h, 1)      (l, 1)                     (l, 1)      (e, 1)      (a, 1)                     (l, 1)      (r, 1)      (s, 1)                     (o, 1)      (e, 1)      (s, 1)      Reduce. Now that the data is organized into (key, value) pairs, the reduce() function is used to combine all the values for each key.In this example, it will “reduce” multiple values by adding up the counts for each letter.Note that only values for the same key are reduced.Each key is reduced independently, which makes it easy to process keys in parallel.                   Chunk #1      Chunk #2      Chunk #3                  Input      (h, 1)      (t, 1)      (c, 1)                     (e, 1)      (h, 1)      (l, 1)                     (l, 1)      (e, 1)      (a, 1)                     (l, 1)      (r, 1)      (s, 1)                     (o, 1)      (e, 1)      (s, 1)              Output      (a, 1)                                   (c, 1)                                   (e, 3)                                   (h, 2)                                   (l, 3)                                   (o, 1)                                   (r, 1)                                   (s, 2)                                   (t, 1)                    MapReduce is useful because many different algorithms can be implemented by plugging in different functions for map() and reduce().If you want to implement a new algorithm you just need to implement those two functions.The MapReduce framework will take care of all the other aspects of running a large job: splitting the data and CPU time across any number of machines, recovering from machine failures, tracking job progress, etc.The LabFor this Lab, you have been tasked with building a simplified version of the MapReduce framework.It will run multiple processes on one machine as independent processing units and use IPC mechanisms to communicate between them.map() and reduce() will be programs that read from standard input and write to standard output.The input data for each mapper program will be lines of text.Key/value pairs will be represented as a line of text with “: “ between the key and the value:key1: value1key two: values and keys may contain spaceskey_3: but they cannot have colons or newlinesVersion 0 - one mapper, one reducerFor your initial implementation, start with one mapper process and one reducer.input_file    |   MAP    | REDUCER    |output_fileCommand line:mr0 &lt;input_file&gt; &lt;output_file&gt; &lt;mapper_executable&gt; &lt;reducer_executable&gt;Sample Usage:% ./mr0 test.in test.out my_mapper my_reducermy_mapper exited with status 1my_reducer exited with status 2output pairs in test.out: 9You won’t implement your own map() or reduce() function–your program will take the names of a map program and a reduce program on the command line and run those.Close all unused file descriptors!The mapper and reducer processes won’t exit until they reach the end of their input file.An EOF won’t be triggered on their input file until all processes that have a copy of their input file descriptor close that file descriptor.For example, if the main process doesn’t close its copy of the write end of the pipe that the reducer is reading from, the reducer will never see an EOF and will never exit.In each child process created with fork() you’ll also need to close all unused file descriptors inherited from the parent process.To aid you in this, we’ve provided a set of functions, declared in common.h, that make it easy to keep track of all the additional file descriptors you create, and to close them all.void descriptors_add(int fd);void descriptors_closeall();void descriptors_destroy();You don’t have to use these, but they may make the project easier.You also should consider using the function pipe2() to create your pipes.If you use pipe2(), you can set a flag O_CLOEXEC which will instruct the system to close both ends of the pipe if a call to exec is made.See the man pages for pipe2() and open() for more information.Since most of the child processes in this program have their stdin and stdout redirected, you may wish to create a function for that.“Reference Implementation”You can implement the equivalent of this program in a Unix shell quite easily:% my_mapper &lt; test.in | my_reducer &gt; test.outFiles used for grading:  mr0.cThings we will be testing for:  Inputs of varying size  Different types of mapper and reducer tasks  No memory leaks and memory errors when running applicationThings that will not be tested for:  Illegal inputs for either the mapper or reducer (Input data in a format other than as described above)  Invalid mapper or reducer code (mappers or reducers that do not work)Building and RunningBuildingThis Lab has a very complicated Makefile, but, it defines all the normal targets.make # builds provided code and student code in release modemake debug # builds provided code and student code in debug modeInput DataTo download the example input files (books from Project Gutenberg), use the Makefile:make dataYou should now see data/dracula.txt and data/alice.txt in your Lab folderRunning Your CodeWe have provided the following mappers:  mapper_wordcount  mapper_lettercount  mapper_asciicount  mapper_wordlengthsThese each be used anywhere we specify my_mapper in these docs.And the following reducers:  reducer_sumThese each be used anywhere we specify my_reducer in these docs.For example, if you wanted to count the occurrences of each word in Alice in Wonderland, you can run and of the following./mr0 data/alice.txt test.out ./mapper_wordcount ./reducer_sumNotes  You may find dup and/or dup2 helpful.  You may NOT use system()"
  }
    ,
    
  {
    "url_slug": "networking-mp",
    "url": " /networking_mp",
    "learning_objectives": ["Implementing a simple text based protocol","epoll and non-blocking I/O","Network error handling"],
    "wikibook": ["POSIX, Part 1: Error handling","Networking, Part 1: Introduction","Networking, Part 2: Using getaddrinfo","Networking, Part 3: Building a simple TCP Client","Networking, Part 4: Building a simple TCP Server","Networking, Part 7: Nonblocking I O, select(), and epoll"],
   "title": "Nonstop Networking",
   "content": "Warning!We strongly recommend reading this entire document at least twice to make sure you understand what the exact requirements of the assignment are. This is a three week MP (one fifth of your MP grade!), and it may be long and painstaking. We strongly recommend starting early.Make sure you also read the grading portion, as it is different than the standard multi-week MP grading scheme.Note: do not use threads for this assignment. Any code that uses the pthread library automatically gets a zero.Threads start wearing outOne of the common ways of handling multiple clients at a time is to use threads. Sounds simple enough. A client connects, we spawn a new thread to handle it, and then that thread can clean up after itself once it’s done. What’s the catch?Well, that usually works okay up until a point. After that, your server won’t scale as fast. And in the modern world, you have to do things web scale (TM).Non blocking I/OWell, what can we do about this? Maybe we could keep a thread pool, that is, have a fixed number of threads, and have them service the connections. However, it’s an M:N mapping this time (M connections, N threads). But wait, how do I multiplex all these different connections, and handle all those threads?Non-blocking I/O is your friend here. Remember how regular calls to read(), accept() etc. block until there’s data or a new connection available? (If you don’t, try it out! Trace how your server code blocks in read() until your client sends some data!). Well, non-blocking I/O does exactly what it says, you structure your application in such a way that works with the data that’s already present (in the TCP buffers), not block for data that may or may not arrive! Functions that help you with this are select(), poll(), and epoll().Think of it as an event driven system. At a high level, you maintain a set of file descriptors (could map to files, pipes, network sockets, etc.) that you’re interested in, and call the appropriate wait() function on that set of descriptors. Your program waits until one (or more) of those descriptors have some data available (in a server scenario, when a client has actually sent data). When data is available, it’s like an ‘event’ occurred, so your program exits the wait() call, and can iterate over the descriptors that have data, process each of them, and then go back to wait()-ing for additional data to arrive.Epoll basicsepoll() arose out of the inefficiencies of select() and poll() (O(N) waiting is so 20th century) (Check out the C10k problem for more information). It provides two modes of operation, edge triggered (ET) and level triggered (LT). Think of it as follows, you have a tank (the descriptor) that you want a notification for whenever there’s water (data) in it. Edge triggered mode would wake up your program once and expect you to empty out the entire tank (process all the data). If you only process half of it and call epoll\\_wait() again, your process will block (that’s not good - there is data waiting to be processed and other connections to handle).On the other hand, level triggered will wake up your epoll_wait() call any time there is any data in the descriptor. In this case, if you process half, and then call epoll_wait() again, it’ll immediately return with a notification about that descriptor.So why would we ever want to use edge triggered behavior? Well, consider what happens when there are multiple threads blocking on the same epoll descriptor (yes, we can do that; yes, people do that). Some data arrives on a socket, a thread wakes up and starts processing it. But there’s still data, so another thread might accidentally get woken up and start processing data for the same descriptor. That’s bad, very bad.Edge triggered mode (together with the EPOLLONESHOT flag) guarantees that a single thread will handle all the data that arrived on that given socket, so (although with some additional code complexity) it’s not possible that two threads accidentally ‘steal’ the file descriptor data from each other.The ProblemYou’ll be writing the client and server for a simplified file sharing application. TCP is used for everything here, so reliability is taken care of. The server uses non-blocking I/O (with epoll) to handle concurrent requests. The application supports four basic operations - GET, PUT, LIST and DELETE. Their functions are as follows:GET - Client downloads (GETs) a file from the serverPUT - Client uploads (PUTs) a file to the serverLIST - Client receives a list of files from the serverDELETE - Client deletes a file from the serverFor simplicity, you can assume that there are no conflicting requests (that is, nobody will upload a file while someone else is downloading or deleting it, etc.)The ProtocolThis is a text-based protocol (similar to HTTP and FTP). The client sends plaintext requests along with some binary data (depending on the operation), and then the server responds with plaintext containing either error messages or optional binary data. The binary data in this case is the file being transferred, if it is a GET or PUT request. The maximum header length (header is part before data) for both the request and response is 1024 bytes.  The format for the protocol is as follows:Client requestVERB [filename]\\n[File size][Binary Data]  VERB can be any one of ‘GET’, ‘PUT’, ‘DELETE’ or ‘LIST’ (Case sensitive - VERB must be capitalized).  ‘\\n’ is the newline character (a single byte).  There is a space character in between VERB and [filename].  [filename] is limited to 255 bytes.  File size and binary data are only present for a PUT operation (since the client is trying to upload a file). File size is a size_t which indicates how many bytes are present in the binary data in the request. For example, if file size is 32, then the server should expect 32 bytes of binary data to be in the request from the client. For this binary data, we will be using the Little Endian form of byte ordering (the system used by Intel hardware) while sending size_t over the network. Because of this, you do not need to convert the byte ordering in either the client or server.  On PUT, if local file does not exist, simply exiting is okay.If VERB is “LIST”, then only the newline after will be present (no space, file size, or data).Server responseRESPONSE\\n[Error Message]\\n[File size][Binary Data]RESPONSE can be either OK or ERROR, depending on how the request went (details on error handling are in a later section).Error message and the newline after it are only present if and only if the RESPONSE is ERROR.File size and binary data are only present in GET or LIST responses, and refer to the number of bytes (size_t, same way the client sent size_t in a PUT request) of binary data that follows. If it’s a GET request, the binary data is the data in the file being requested. If it’s a LIST request, the binary data is a series of filenames, separated by newlines, referring to files currently stored on the server. For example, if a server is hosting files ‘you.txt’, ‘gonna.log’, ‘give.avi’, ‘never.mp3’, and ‘up.mov’, the response to a LIST might look like this-OK\\n\\&lt;10 + 10 + 9 + 8 + 6, expressed as a size_t\\&gt;never.mp3\\ngonna.log\\ngive.avi\\nyou.txt\\nup.movThe large size_t referred to comes from the length of the filenames, plus the newlines between filenames (there is no newline after the last file, or before the first one) - the value is broken down into a sum on a per line basis for ease of understanding. In that example, the actual value that would be sent would be 43.Specifics: ExamplesIn all four examples, the first line represents how we call the client in the command line, followed by the client’s request to the server, and finally followed by the server’s response. Notice how we always send all sizeof(size_t) as raw bytes. That is, in each below, [size] is 8 bytes that represent the number of bytes the binary data that follows should be.  You did something similar to this in chatroom.  While you’re looking at these examples, think about what parts of the request and response you want to print (if any), depending on request and response types.  GETHere, the client is GET’ing the file “The.Social.Network.2010.1080p.BluRay.x265.10bit-z97.mp4” and saving it locally as “social_network.mp4”.$ ./client server:port GET The.Social.Network.2010.1080p.BluRay.x265.10bit-z97.mp4 social_network.mp4GET The.Social.Network.2010.1080p.BluRay.x265.10bit-z97.mp4\\nOK\\n[size]...  PUTIn this example, the client is PUT’ing the file “Prison.Break.S05E01.WEB-DL.x264-FUM[ettv].mp4” (local to the client) on the server as “prison_break_s05_e01.mp4”.$ ./client server:port PUT prison_break_s05_e01.mp4 Prison.Break.S05E01.WEB-DL.x264-FUM[ettv].mp4PUT prison_break_s05_e01.mp4\\n[size]some call it prison break others call it privilege escalation ...OK\\n  DELETEIn this case, the client DELETE’s the file “prison_break_s05_e01.mp4” from the server.$ ./client server:port DELETE prison_break_s05_e01.mp4DELETE prison_break_s05_e01.mp4\\nOK\\n  LISTIn LIST requests, the client LIST’s all available files on the server.$ ./client server:port LISTLIST\\nOK\\n[size]logan.mp3\\nlaura.log\\nlive.avi\\nman.txt\\nis.movNotice there is no new line at the end of the list.Specifics: The ClientThe client’s job is simple: execute a single request. The usage is as follows:./client &lt;server IP&gt;:&lt;server port&gt; VERB [remote] [local]Where remote is the filename used in the request and local is the filename that the client uses while uploading/downloading. For example:./client 127.0.0.1:9001 GET remotefile localfileThat would download the file ‘remotefile’ from the server and store it as ‘localfile’.The client runs a single command (GET, PUT, LIST or DELETE) with the chosen arguments, makes sure the file it’s trying to upload (if it is uploading one) actually exists, connects to the server, sends the request (and file data, if needed), and finally prints out any error messages to STDOUT. Once the client has sent all the data to the server, it should perform a ‘half close’ by closing the write half of the socket (hint: shutdown()). This ensures that the server will eventually realize that the client has stopped sending data, and can move forward with processing the request.For LIST, binary data from the server should be printed to STDOUT, each file on a separate line.For GET, binary data should be written to the [local] file specified when the user ran the command.  If not created, create the file.  If it exists, truncate the file.  You should create the file with all permissions set.Your client is allowed to use blocking I/O, since clients don’t really care about scaling. However, there are a few important things to keep in mind:1) Parse the response carefully. When you’re reading, you may accidentally read into the application binary data without realizing it (since you don’t have fixed size fields in the responses).2) write(fd, buffer, n) may not always write n bytes for various reasons. Buffers may become full, signals may arrive, the Skynet revolution might begin. None of which are excuses for not sending the correct amount of data to the server. Good practice is to wrap your read/write calls in a loop that runs until the specified number of bytes are read, the connection is closed, or an error occurs.3) Your client needs to be able to handle large files (more than physical RAM) and should do so efficiently.Error HandlingYour client should handle the following errors and use the appropriate function in format.h:  Received too much or too little data from server.  Invalid response from server (malformed or nonexistent STATUS).  Print any ERROR message from the server.Specifics: The ServerThe real fun lies here. As discussed, you’ll be using epoll to allow non-blocking I/O. As you know, epoll allows you to add various descriptors to the epoll set to be ‘monitored’ for events. After that, when you call epoll_wait(), it will block until there are events on one or more epoll descriptors (either indicating data is available or that data can be written to the socket).Request statesOne way to reason about connections in a nonblocking server is to visualize each one as a traversal of a finite state machine. That is, there is some initial state (probably when the connection was created), and you transition between the different states depending on what action occurred (the type of request, whether there was an error or not, etc.).A suggested flowchart for the server automata:Maintaining persistent connection stateNew connections arrive and old connections close all the time. Your server need to know what the current status of the command it’s serving is. One suggested way is to maintain a mapping from socket handle to connection state (you are provided a dictionary data structure for this purpose). When a connection arrives, this state is allocated on the heap and added to the dictionary. When the server is handling epoll events, it can check the descriptor of the event that occurred, and quickly find out the underlying state of the request. Information that might go into a connection state could be:  What state in the DFA you’re in  The request VERB  Various buffers and offsets  Filenames  Anything else you’d like to put in there, really, this is your design decisionGlobal data structuresYou should maintain the file list (server-side) with a global vector that gets appended to every time a file is added (using push_back()). Entries are removed one file at a time, by using vector_erase() with the appropriate index.You might also want to maintain a map from file descriptor to connection state, as discussed above. Remember to clean up any state when you’re done serving a single connection!Memory limitsSince your server is expected to be able to serve a large number of clients multiple (possibly large) files concurrently, you cannot assume that the files will entirely fit in memory (that is, you cannot read the entire file data into one giant buffer). Instead, you should maintain some (reasonably) fixed size buffers (say, 1024 bytes), and reuse these buffers as you send or receive data over time. You may use different buffers for different kinds of data (for instance, the request header, the file list, the file being sent/received) if you wish. It is also okay to keep different buffers for different connections.File StorageYou should create a temporary directory using the mkdtemp() function (make sure you follow this convention exactly!). Your server will store all uploaded files in this directory. Immediately after creating your directory, you must print it out using print_temp_directory (found in format.h) from the current directory (do not cd into another directory and then call print_temp_directory - if you don’t follow this rule, do not expect to pass any of the autograder tests.When your server exits, it should clean up any files stored in this directory, and then delete the directory itself. unlink() and rmdir() might be helpful here.Note: Be sure to use the directory name that mkdirtmp(char *template) gives you. Additionally, make sure that your template is exactly 6 X’s, as in XXXXXX.Exiting the serverYour server should exit on receiving SIGINT.You might find sigaction and signal masking with threads helpful, if your signal handling and threads aren’t working together quite the way you had hopedNote: Do not store the newlines in your filenames. There will be no whitespace or slashes in filenames at all.Error handlingYour server is expected to be able to handle misbehaving/stark raving mad clients. That means you can never assume the request is formatted the way the protocol says it should be. While handling a request, as you read data from the connected socket into your local buffers, you should parse the command to make sure it is well-formed (the legal verb, the number of arguments is as expected, etc.)Another thing to keep in mind is that if you try writing data to a client that has disconnected for any reason (they close()d the socket, for instance), your server might receive a SIGPIPE - you should setup your program to ignore that signal. This may also result in write() calls returning -1 with errno set to EPIPE. If this happens, your server should also close the connection and clean up any associated state.Your server should handle these errors:  Bad request (malformed or nonexistent verb)  Bad file size (too much or too little data from client)  No such file (GET/DELETE on nonexistent file)Notes:  If a PUT request fails, delete the file.  If a PUT request is called with an existing file. overwrite the file.  You should use the error messaged defined in format.hWriting your server codeKeep things modular! Write functions for everything. This has multiple advantages. First, it lets you debug your code in small, incremental units, rather than writing a huge monolith of code and trying to figure out which part of it is broken through trial and error. Secondly, you’d be surprised how much code you can end up reusing if you design your application appropriately. Third, it’ll be helpful while debugging or discussing your approach with course staff - it’s really hard to tell what your code is supposed to be doing, otherwise.LoggingThis assignment is challenging enough, and debugging it is even more so. We recommend that you constantly log state as your client/server program executes. You might want to log at the beginning/end of function calls, entry and exit of loops etc. and maybe log the values of key variables, pointers, file descriptors etc. to sanity check what’s going on with your code.We provide a simple LOG() macro, if you’re interested in that. Or, you could play around with writing one of your own (ours is just a wrapper around fprintf()).TestingTesting networking programs can always be challenging. There are a few ways we suggest going about this:Client - You could write a toy server in any language of your choice that logs the adheres to the protocol above (even if it doesn’t do multithreading, nonblocking I/O etc.)Server - By the time you start your server, you will (hopefully) have a working client implementation. Use that to test your server! In addition, feel free to setup a server and have each others’ clients try connecting to them (As long as you’re not sharing any code/design decisions) - this is a good way to stress test your own implementation. Another way to simulate multiple clients could be to write a program that fork()s a bunch of times, each child calling exec() on your client executable and sending a request (no fork bombing, please!).Alternatively, if higher level languages are more your thing, you could try writing a script in some other language (say, Python or Ruby). As long as you strictly adhere to the specified protocol, it should work fine (be careful about the width and byte ordering of types in other languages, though!). The catch is, you have to be sure your mock client/server actually works as expected, since you’ll end up debugging programs in different languages at this point, which is never fun. On the bright side, this lets you practice multilingualism.We will also be providing a reference client and server.  These print out helpful logging messages that you do not need to mirror in your code.  These might also not be perfect, so please report things to us (they do pass our tests though).NotesMake sure you use SO_REUSEADDR to ensure bind() doesn’t fail in the event that your server or client crashes. This will enable faster debugging for you (otherwise, you would have to wait for the kernel to reopen the source address and port). We will be making sure that your socket is setup with these options (look into setsockopt) so please make sure you use this flag! If you don’t, you will not pass this assignment.GradingThere are three parts for this assignment:  Part 1: The ClientPart 1 requires full client functionality, and is due Monday, November 27th at 23:59.  Part 2: The Server Part 1Part 2 requires you to begin implementing your server. We will run the full server-client autograder for this week (except for the stress test).Obtaining 50% of the points is a 100% on week 2, 45% yields a 90%, 40% an 80%, and so on. You may choose which parts of the server you wish to implement first.  Part 3: The Server Part 2Part 3 is full server-client functionality. All tests will run, including the stress test. This is due Monday, December 11th, at 23:59.Your final grade for this assignment is computed as total = max(part1, part3) + max(part2, part3) + part3."
  }
    ,
    
  {
    "url_slug": "parallel-make",
    "url": " /parallel_make",
    "learning_objectives": ["Parallel Programming with Dependencies","Using a Threadsafe Data structure","Resource Allocation Graphs (RAG)","Deadlock Detection","Synchronization"],
    "wikibook": ["Synchronization, Part 4: The Critical Section Problem","Synchronization, Part 5: Condition Variables","Deadlock, Part 1: Resource Allocation Graph","Deadlock, Part 2: Deadlock Conditions"],
   "title": "Parallel Make",
   "content": "IntroductionMore and more programs today are being programmed as multithreaded applications.The goal of this MP is to give you more practice writing multithreaded applications and to expose common pitfalls that occur while designing a program to work in a parallel manner.Additionally, you will need to make use of synchronization primitives to protect the memory shared amongst the threads.You are given a task of writing an application which will imitate the common make utility.make is a utility that automatically builds executable programs from source code by reading files called Makefiles which specify how to derive the program.You have encountered Makefiles in CS 241 MPs as well as in your previous undergraduate CS classes and should be familiar with them.We have provided the code to parse a Makefile and list the dependencies and commands specified in the file.Once the file is parsed, you will need to perform the actions specified by the Makefile following the rules specified later in the docs.Using a fixed pool of threads, you will parallelize this execution process such that all commands are executed as soon as their dependencies are satisfied.Before starting you should read the Wikipedia article on Make.You might also want to look here for some notes that explain makefiles really well.(They start with some C++ specific details but you can skip to the ‘Now, makefiles’ section. Also, do note that the makefile for this MP does NOT use makefile macros.)THIS IS A HARD MP. WE RECOMMEND THAT YOU START EARLY.Resource Allocation GraphsA good way to think about this MP at a high level is by using a model covered in lecture, Resource Allocation Graphs. You can think of make rules as nodes in the graph and dependency relations as directed edges that point from rules to dependencies. This visualization comes in handy when we are dealing with programs that may encounter deadlock. Given that a Makefile may contain a circular dependency (what are the required conditions for a program to deadlock?), keep this model at the back of your mind when building your solution.Here is an example Makefile:d: a c\techo Da: b\techo Ab: a\techo Bc:\techo CThe following graph represents the above Makefile. Note that ‘a’ and ‘b’ form a cycle (-&gt; ‘b’ -&gt; ‘a’ -&gt;).Some more resources on RAGs &amp; Deadlock: Wikipedia, Wikibook.Program InputsThe input for this MP will be in the following form:./path/to/parmake [-f path/to/makefile] [-j positive-integer] [targets ...]The input parsing step is already handled for you in parmake_main.c. The Makefile, thread count, and target list will be provided as arguments to the parmake() function, which you will have to implement.Process the MakefileThe first thing you will need to do is to parse the Makefile into a dependency graph.The Makefile will always consist of one or more rules of the form:target [target ...]: [dependency ...]    [command 1]    .    .    [command n]For example:rule1: rule2 rule3    commandtoberun withargs    commandtoberun2 withargsrule2:    othercommandrule3 rule4:    finalcommandYou may want to take a look at the Wikipedia page if you do not know how to read or write a basic Makefile. However, you will not need to parse the Makefile yourself. Instead,you must use the parser_parse_makefile() function to represent the Makefile as a dependency graph.parser_parse_makefile() takes the filename and a NULL-terminated array of strings as inputs.The array of strings specify the targets you are planning to run. Remember, if the array is null or empty, the parser will use the first target found in the Makefile. The parser returns a graph data structure containing all rules and dependencies in the Makefile, including those that do not need to be executed.For example, suppose we have the following Makefile:a: b c    echo Ab: c    echo Bc:    echo Cd:    echo DThe parser will return a graph containing 5 vertices, once each for rule ‘a’, ‘b’, ‘c’, and ‘d’, as well as one sentinel (labeled as an empty string) whose neighbor is rule ‘a’ (i.e. the only goal rule).Those curious of the implementation can view the source in parser.c although this is not necessary.We have provided an implementation of a thread safe queue, a vector, a set, a dictionary, and a graph. This is the same queue from luscious locks and the same vector you’ve used in prior assignments. The set, graph, and dictionary are new data structures from the CS 241 provided library. You can view the header information in includes/.Graph Data StructureSince a Makefile is a representation of a dependency graph, our parser returns a directed graph data structure. You may find the graph API in includes/graph.h. To access Makefile rules from this graph, you would userule_t * rule = (rule_t *)graph_get_vertex_value(dependency_graph, target)where target is a string labelling a rule. To get a list of all targets, usevector *targets = graph_vertices(dependency_graph)To get a list of all the dependencies of a rule with a given target, usevector *dependencies = graph_neighbors(dependency_graph, target)The graph returned from the parmake parser will contain all the vertices and edges depicting rules and dependencies in a Makefile. In addition, it will contain an empty sentinel rule (with key “”) whose neighbors are the goal rules. Do not execute this rule. Instead, you should only work on rules that descend from this rule (i.e. the goal rules and all their descendants). Here, “B descends from A” means that ‘A’ implicitly depends on ‘B’ to run.See rule.h for a description of the rule_t API. And read parser.h for more usage details on the dependency graph.USAGE WARNINGS:      Any vectors returned from graph functions must be destroyed manually to prevent memory leaks. Destroying these vectors will not destroy anything in the actual graph.    Destroying the graph or removing vertices from the graph will completely destroy all associated targets (i.e. rule labels), rules, and edges. So copy anything you need for later use before removal or destruction.      You should not add new vertices to the graph. If you choose to do this using graph_set_vertex(), keep in mind that both the key and value must be strings, since the graph’s value copy constructor transforms strings to new rule_t structs. Read parser.c in order to understand the dependency graph’s memory management scheme.    The graph and vector classes are not thread-safe! You must enforce mutual exclusion if multiple threads are to concurrently modify and access these structures.Graph Searching and Cycle DetectionGNU make handles cyclical dependencies by attempting to delete edges that cause cycles. If you tried to call make d on the example Makefile shown earlier, GNU make would essentially attempt to convert that Makefile to this one:d: a c\techo Da: b\techo Ab:  #a (comment out 'a': no more cycles if you remove this edge!)\techo Bc:\techo CTo highlight the importance of cycle detection in resource allocation schemes, we also require that you explicitly handle cycles. However, your implementation of parmake will ignore all goal rules whose descendants belong to cycles. That is, calling ./parmake d on this makefile would execute nothing, since ‘d’ cannot be satisfied due to the cyclical dependency (-&gt; ‘a’ -&gt; ‘b’ -&gt;). However, calling ./parmake c will still execute echo C, since the (nonexistent) descendants of ‘c’ don’t belong to cycles.Moreover, you must announce any goal rules that are dropped due to existence of cyclical dependencies using the function print_cycle_failure() found in format.h. Read the header file for usage information.Since this MP requires you to implement some graph algorithms, you may want to consult this resource to jog your CS 225 memory.Note: You do NOT have to parallelize cycle detection and essential rule extraction. You only need to parallelize the execution of commands.Satisfy the rulesEach rule depends on a (possibly empty) set of other rules. It is important to note that every dependency will be a rule, even if the dependency isn’t explicitly defined in the Makefile. For example, these two Makefiles are equivalent:# Makefile 1a: b\techo A# Makefile 2a: b    echo Ab:Some rules might also be files on the disk. A rule can be satisfied if and only if all of rules that it depends on have been satisfied and none of them have failed (See what determines a failed rule in Running Commands).Note that you shouldn’t try to satisfy rules that aren’t “good” goal rules and don’t have any “good” goal rules as ancestors. Specifically, you should not try to satisfy a rule if any of the following is true:  the rule is a goal rule, but is involved in a cycle, i.e. there exists a path from the rule to itself in the dependency graph  the rule is a goal rule, but at least one of its descendants, i.e. any rule in the dependency graph reachable from the goal rule, is involved in a cycle  the rule is not a goal rule, and it has no ancestors that are goal rules  the rule is not a goal rule, and all of its goal rule ancestors fall under (1) or (2)Basically, there is no need to satisfy a rule if it isn’t necessary to satisfy the goal rules or if we already know that all the goal rules it might satisfy are doomed to fail due to cycles. Trying to satisfying any of them would be impossible at worst or a waste of time at best.When a rule is ready to be satisfied, we must determine if we actually need to run the rule’s commands. We run its commands if and only if at least one of the following is true:  The name of the rule is not the name of a file on disk.Example:clean :    rm -rf *ormakenewfile:    touch newfile  The rule depends on another rule that is not the name of a file on disk.Example:clean : take_backup    rm -rf *take_backup :    cp -r * ../backup  The rule is the name of a file on disk, and it depends on another file with a NEWER change time than the change time of the file which corresponds to the name of the rule. To determine whether a file is NEWER, you should use stat and difftime to determine if it is newer. The differences in time will have a granularity of 1 second.If neither of these is true, then the rule is already satisfied and does not need its commands executed. Otherwise, the rule is unsatisfied and available to be run.Running the commandsYou can use system() to run the commands associated with each rule. There are a few conditions to think about when running these commands:  The rule’s commands need to be run sequentially in the order they appear in the command vector  If any of a rule’s commands fail while evaluating that rule, then the rule should “fail” and no more of its commands should be run  If a rule fails, its parent rules (rules which have this rule as a dependency) should fail as well. Note that this is not necessarily true for the converse (i.e. if a parent fails, its children may still be satisfied)For your convenience these rules are captured in the following flow chart:Parallelize! (Part 2 Only)parmake must satisfy all of the rules needed to build the specified targets correctly and as quickly as possible. Because we want maximum runtime performance, you need to be running a rule on each worker thread whenever possible. Threads should not stay idle when there are rules that are available for execution. A rule is defined as available when all of its dependencies have been satisfied and it is not already satisfied (see “Satisfy the rules”).There are two important parallelism requirements:  You should NOT run any rule unless its dependencies have been satisfied (all dependent rules have been run and none have failed; see the previous section)  If a thread is available (not doing useful work), and there is at least one rule that is available to be executed, the available thread should work on executing that rule.The exact type of work that your worker threads perform will generally depend on your implementation. But for the purposes of this MP, you must parallelize the actual execution of commands. If any rule is ready to have its commands executed, a worker thread should do so as soon as possible (i.e. within several milliseconds) unless all worker threads are already executing commands.If a rule is available because all its dependencies have been satisfied, and some of your threads are still not executing any rules, then you probably haven’t achieved maximum parallelization.ExampleSuppose we have makefile:a: b c    echo Ab: c    echo Bc:    echo CRunning ./parmake should output:CBAThere are many more examples provided in your MP folder.Notes  Only make changes in parmake.c.  You will receive 0 points if your implementation uses sleep(), usleep(), or any other form of timed waiting (e.g. sem_timedwait()).  For full points, avoid busy-waiting. i.e. threads should not be burning CPU when they aren’t doing useful work.  You must only ever launch T+1 threads, where T is the number of worker threads (+1 comes from the main thread). Do not keep re-spawning new threads for every rule.  We will try to artificially create spurious wakeups, so think about how you would resolve those.  To achieve a perfect score, you should maximize parallelization by ensuring that every given rule that can be run at a given time is being run.  Because rules should be run as soon as they are available, there will sometimes be a well-defined, optimal order of rule execution when multiple threads are used. Think about why that might be the case.Compiling and RunningAs usual, we have provided you with a Makefile which will compile your code in a variety of ways.Unfortunately, you can’t use parmake to compile parmake, because our parser does not support variables and variable expansions.To compile in release mode, run make, for debug mode, use make debug.ThreadSanitizerThe provided Makefile also builds a ThreadSanitizer instrumented version of your code.The tsan executable is parmake-tsan.You can run this (instead of parmake) to use the ThreadSanitizer race condition detection tool with parmake.For a tsan example, see the tsan docsWe will be using ThreadSanitizer to grade your code! If the autograder detects a data race, you won’t automatically get 0 points, but a few points will be deducted.(Almost) a reference implementationYou can use the real GNU make to check your implementation. However, it differs from parmake in certain substantive aspects that may or may not be resolved. Here is a partial list of differences:  make usually prints every command it runs. Run make with the flag -s (for silent) to suppress these.  make deals with cycles differently than parmake, so do not use make as a reference for cycle handling.  make kills the program immediately after a rule fails. Run make with the flag -k (for keep going) to continue satisfying rules that aren’t doomed to fail.  make requires every dependency to either be explicitly declared in the Makefile or present as a file on the disk. To get parmake and make to work the same way, define every rule explicitly.  make spits out error messages when commands fail, even when the flag -k is used. parmake will not do this.Example “good” Makefile:#testfilea: maybefile b c \techo \"a\"b:\tcat / # always fails\techo \"I should not print out.\"c:\techo \"c\"maybefile:Example commands:    $ ./parmake -f testfile -j 2This should generate the same output as:    $ make -s -k -f testfile -j 2except maybe for some printouts that make emits when ‘b’ fails. Remember that you don’t need to implement any GNU Make features that aren’t prescribed in these docs.GradingHere is the grading breakdown:  Part 1 (50%): Create a single-threaded version of parmake (so just make). This version should:          identify cycles in the dependency graph returned by the parser and remove goal rules that depend on them      attempt to run all other goal rules by running all their descendants (i.e. implicit dependencies) and only their descendants      identify whether or not to run a rule as per the flowchart recipe and run it once possible (or reject it if not possible)        Part 2 (50%): Create the full multi-threaded version of parmake (so par). This version should:          perform the same functions as in Part 1      run with 2-4 threads (excluding the main thread) for any given Makefile      concurrently run all rules whose dependencies have been satisfied, subject to the thread limit      avoid deadlock, data races, livelock, and busy-waiting      create performant code that doesn’t incur excessive overhead (e.g &gt; 10 ms per rule)      "
  }
    ,
    
  {
    "url_slug": "password-cracker",
    "url": " /password_cracker",
    "learning_objectives": ["Multithreaded programming and its performance gains","Using a thread-safe datastructure","Using synchronization primitives"],
    "wikibook": ["Pthreads, Part 1: Introduction","Pthreads, Part 2: Usage in Practice","Synchronization, Part 1: Mutex Locks","Synchronization, Part 2: Counting Semaphores","Synchronization, Part 3: Working with Mutexes And Semaphores","Synchronization, Part 4: The Critical Section Problem","Synchronization, Part 5: Condition Variables","Synchronization, Part 6: Implementing a barrier"],
   "title": "Password Cracker",
   "content": "IntroductionIn this MP, you will be creating a program that can recover lost passwords.For security reasons, passwords are usually never stored in plain text.Instead, the hashed versions of passwords are stored.For an example of this, take a look at the /etc/shadow file on any modern Linux machine.When a user tries to log in, the password they enter is hashed and compared with the stored hash.This way, there’s no need to store your actual password.Given the output of a good hash function, it is hard or impossible to reconstruct the input using the hashed value.However, if you are willing to burn some CPU time, it is possible to try every possible password (brute force attack) until you find one that hashes to the target hash.crypt_r()We will be using crypt_r() (a reentrant/thread-safe version of the crypt() function) as our hashing function.crypt_r() takes three arguments: the string to hash, a salt string, a struct crypt_data.Make sure to set the initialized member of your struct crypt_data to zero before using it for the first time.For example:struct crypt_data cdata;cdata.initialized = 0;const char *hashed = crypt_r(\"example1\", \"xx\", &amp;cdata);printf(\"hash of 'example1' = %s\\n\", hashed);hashed = crypt_r(\"example2\", \"xx\", &amp;cdata);printf(\"hash of 'example2' = %s\\n\", hashed);This code outputs the following:hash of 'example1' = xxPXiOTQGgNxchash of 'example2' = xx96r6/l1aOi.The struct crypt_data is necessary for crypt_r().This is because crypt() stores information between invocations, so calling crypt() in multiple threads at the same time will cause this information to be inaccurate.crypt_r() gets around this by storing information in a struct crypt_data instead.You should check the man page for crypt_r. Do you need to free the string it returns?Why is there salt in my hash?The salt argument “flavors” the string so that when you hash the same password with different salts, you’ll get different results. In practice, we might use a random value generated for every user. This prevents an attacker from noticing that two people have the same password just by comparing their hash values.For this assignment, always use \"xx\" for the salt argument.Problem StatementYou will be given a list of hashes that you must recover the passwords for. For each hash, we have two other pieces of information:  The first few letters in their password  The total length of the passwordAll the passwords only contain lowercase letters!For example, we may say that a password begins with \"hello\" and has a total of 8 letters. We know the hashed value associated with this password is \"xxsczBXm6z4zA\", so we simply have to try hashing each possible password (starting with the prefix provided) until we find one that hashes to the desired value.InputYour input will be a file with one line for each password to recover. Each line will contain:  Username (1-8 characters)  Password hash (13 characters)  Known part of password (plus periods representing unknown characters) (1-8 characters, contains 0-8 lowercase letters followed by 0-8 periods)          A period in the password represents an unknown letter.      These three fields are separated by a single space.Don’t worry about duplicate usernames, duplicate password hashes, or duplicate prefixes.Each line is an independent task.All input we provide is guaranteed to be in this format.Example input:donna xxC4UjY9eNri6 hello...eric xxqJ7cKzV3v4E zip.....francie xxGGPN89YLcGY cham....george xxq5aBqiB66j2 xz....helen xxhx0AsVpMTMU sysx....inigo xxHUf9zUctXNA miss....Note: For both version 1 and version 2, the main thread is NOT to be used to crack passwords. ONLY the worker threads should try to crack a password.  For both version 1 and version 2, the main thread is NOT to be used to crack passwords. ONLY the worker threads should try to crack a password.  For both, you will be editing a function called start that should return 0 when exiting under normal circumstances. You can return any non-zero exit status when an error occurs.Version 1: Thread PoolWe will not grade any output which is not the result of a call to a function in format.hIt is always a good idea to write a single threaded version of your code before trying to parallelize!Use multiple threads to speed up the password processing.The main thread will start up a pool of worker threads, then read lines of input from standard input.Each line will be converted to a task which is added to a task queue.The task queue is provided in libprovided.a and queue.h.This is the same thread-safe queue that you’ve implemented in lab!The worker threads will pull one task from the task queue, then process the task.When a worker thread starts processing a task, it will print the username of the task (use format.h).When a worker thread finishes a task, it will print the cracked password (use format.h), along with the index of the thread (starting with index 1) and the amount of CPU time spent working on the password (use getThreadCPUTime()).When the main thread finishes reading in lines from the input, it can’t shut down immediately, since worker threads may still be cracking some passwords.You need to decide how to cleanly shut all the threads down when there are no more passwords to crack.Every thread must join with the main thread!After all the worker threads have exited, the main thread will print (this is provided in cracker1_main.c):  Number of successful and unsuccessful password cracks  Wall clock time since the program was started (via getTime() in utils.h)  CPU time used (a sum of the CPU time used in all threads).  Proportion of CPU time to wall clock time.By default, the provided code creates 4 worker threads.If a command line argument is supplied to the program, it will use that as the number of worker threads rather than the default.Example:$ cat password_file.txtdonna xxC4UjY9eNri6 hello...eric xxqJ7cKzV3v4E zip.....francie xxGGPN89YLcGY cham....george xxq5aBqiB66j2 xz....helen xxhx0AsVpMTMU sysx....inigo xxHUf9zUctXNA miss....$ ./cracker1 [thread_pool_size] &lt;  password_file.txtExample output:Thread 1: Start donnaThread 4: Start francieThread 3: Start georgeThread 1: Password for donna is helloaac (3 hashes in 0.00 seconds)Thread 1: Start helenThread 2: Start ericThread 2: Password for eric is zipaaazz (676 hashes in 0.00 seconds)Thread 2: Start inigoThread 1: Password for helen is sysxpert (266806 hashes in 1.05 seconds)Thread 2: Password for inigo is missudad (353552 hashes in 1.32 seconds)Thread 4: Password for francie not found (456976 hashes in 1.65 seconds)Thread 3: Password for george is xzzzzy (456975 hashes in 1.75 seconds)5 passwords recovered, 1 failed.Total time: 1.74 seconds.Total CPU time: 5.77 seconds.CPU usage: 3.31xThe times and order may vary slightly.Your password cracker should be processing passwords in a streaming manner. This means that once the program is started, if both a password and a worker thread are available, the thread should immediately work on the password.Be sure to consider how your task queue is conducive to this and when you launch your threads to achieve this.Note that the queue does not have a queue_empty() function (as explained in queue.h).So a question you might ask yourself is “How do I know when the queue is empty?”.This is an exercise we have intentionally left for the reader, but one hint we will give is “How does strlen() know when it has reached the end of a C style string?”. How can you reuse the same idea in terms of a queue (what is the analogue of the null byte)?Remember to use appropriate synchronization, and make sure to use crypt_r.If you create a new thread for each task (instead of keeping the threads in the thread pool running), you will lose points! (and your implementation will be very slow)Version 2: Parallelize each taskWe will not grade any output which is not the result of a call to a function in format.hVersion 1 works great when there is a long list of passwords that need cracking in parallel, but it’s no faster than a single threaded version when there’s one really hard password that needs cracking.For version 2, you’ll still have a pool of threads, but rather than assigning one thread to each password task, all the threads will work in parallel on each password task.Example input:maude xxEe0WApyDMcg a......jesse xxsJNywggi0lA za......francie xxGGPN89YLcGY cham....Example output:Start maudeThread 2: Start maude at 77228944 (agnaaaa)Thread 4: Start maude at 231686832 (atnaaaa)Thread 1: Start maude at 0 (aaaaaaa)Thread 3: Start maude at 154457888 (anaaaaa)Thread 1: Stop after 308332 iterations (found)Thread 3: Stop after 327747 iterations (cancelled)Thread 4: Stop after 337977 iterations (cancelled)Thread 2: Stop after 318970 iterations (cancelled)Password for maude is aaarocx (1293026 hashes in 1.72 seconds)Total CPU time: 6.41 seconds.CPU usage: 3.72xStart jesseThread 3: Start jesse at 154457888 (zanaaaaa)Thread 4: Start jesse at 231686832 (zatnaaaa)Thread 1: Start jesse at 0 (zaaaaaaa)Thread 2: Start jesse at 77228944 (zagnaaaa)Thread 2: Stop after 945682 iterations (found)Thread 4: Stop after 968171 iterations (cancelled)Thread 3: Stop after 966968 iterations (cancelled)Thread 1: Stop after 911765 iterations (cancelled)Password for jesse is zagpbuyj (3792586 hashes in 3.24 seconds)Total CPU time: 12.77 seconds.CPU usage: 3.94xStart francieThread 4: Start francie at 342732 (chamtnaa)Thread 3: Start francie at 228488 (chamnaaa)Thread 1: Start francie at 0 (chamaaaa)Thread 2: Start francie at 114244 (chamgnaa)Thread 4: Stop after 114244 iterations (end)Thread 3: Stop after 114244 iterations (end)Thread 2: Stop after 114244 iterations (end)Thread 1: Stop after 114244 iterations (end)Password for francie not found (456976 hashes in 0.40 seconds)Total CPU time: 1.53 seconds.CPU usage: 3.81xDistribute the work by splitting the search space into equal-sized chunks, one for each worker thread.For example, if there are 3 unknown characters, then there are 26^3 = 17576 possible passwords that need to be tested.With 4 worker threads, you would split the work up like this:  Thread 1: 0..4393 (aaa..gmz)  Thread 2: 4394..8787 (gna..mzz)  Thread 3: 8788..13181 (naa..tmz)  Thread 4: 13182..17575 (tna..zzz)When the number of threads doesn’t divide the search space evenly, it’s easy to get off-by-one errors due to integer rounding.The functions getSubrange() and setStringPosition() are provided in utils.h file to assist you with this. We cannot guarantee the correctness of code that does not utilize these functions.With all the threads working on the same task, you may want to restructure your thread synchronization a little.Rather than a queue, you may wish to use a barrier.                Startup     Task 0..............................   Task 1..............................main thread:    read task | idle      | print results, read next | idle      | print results, read nextworker threads: idle      | computing | idle                     | computing | idle                          &amp;uarr;                       barrierLike with version 1, you may not create new threads for each task.The threads you create at the beginning of the program must be the same threads that compute the last task.When the main thread reads a task, it should print \"Start &lt;username&gt;\".When a thread starts processing a task, it should print its index and starting position.As usual, make sure to use format.h.For example:% echo eric xxqJ7cKzV3v4E zip..... | ./cracker2Start ericThread 1: Start eric at 0 (zipaaaaa)Thread 2: Start eric at 2970344 (zipgnaaa)Thread 4: Start eric at 8911032 (ziptnaaa)Thread 3: Start eric at 5940688 (zipnaaaa)When a worker thread finds the correct password, it should tell all the other threads to stop working on the task.You can implement this with a simple flag variable that each thread checks on each iteration.Since all the threads are reading this variable and any thread may write to it, you’ll need to properly synchronize access to it.When the worker threads finish a task, each thread will print the number of passwords it tried and a word describing how its run finished:  (found) - this thread found the password  (cancelled) - stopped early because another thread found the password  (end) - finished with no password found. Note: this can happen if the password was found, but this thread finished its chunk before another thread found the password.After all worker threads finish each task, the main thread will print the password (if found), the total number of hashes, the wall clock and CPU time spent on that task, and the ratio of CPU time to wall clock time.Note that we have not provided any of the timing print statements in cracker2.ConceptLatency &amp; ThroughputBy definition, latency is the delay from input into a system to desired outcome or the execution time of a single task. Throughput is the maximum rate at which something can be processed or the amount of task that could be completed in a period of time.Let’s take pizza delivery for an example,  Do you want your pizza hot? Low latency = pizza arrives quicker!  Or do you want your pizza to be inexpensive? High throughput = lots of pizzas per hourFor the “Version 1: Thread Pool” solution, because the amount of time needed for every task is different, the tasks that need less time won’t be blocked by the tasks that needed longer time. On the other hand, the execution time for each task is longer than having all the threads working on the single task.Consider the following tasks (in order), where a thread can run 100 iterations per second:  task 1: 100 iterations  task 2: 10000 iterations  task 3: 100 iterations  task 4: 100 iterations  task 5: 100 iterationsThroughputSuppose there are 4 threads available and the program runs for 1 second.For version 1: The throughput is 2 since tasks 1, 3, and 4 will have completed, while 2 is still being worked on (and 5 is just being started).For version 2: The throughput is 1 since only the first task will have completed and all of the threads are busy working on task 2.LatencyThe latency is determined by how quickly each password can be cracked.                                    Task1      Task2      Task3      Task4      Task5                  Latency (version 1)           1         100           1          1          1              Latency (version 2)         0.2          20         0.2         0.2         0.2      Version 2 has much lower latency since each password is cracked faster by multiple threads working on the same task.Building and RunningAs usual, we have provided a Makefile which can build a release and a debug version of your code.Running make will compile cracker1 and cracker2 in release mode, as well as a tool called create_examples (more on this in the next section).Running make debug will compile cracker1 and cracker2 in debug mode, and will also compile create_examples.ThreadSanitizerWe have also included the target make tsan, which compiles your code with Thread Sanitizer (run cracker1-tsan and cracker2-tsan)ThreadSantizer is a race condition detection tool. See this page for more information.We will be using ThreadSanitizer to grade your code! If the autograder detects a data race, you won’t automatically get 0 points, but a few points will be deducted.Helpful ExtrasThread status hookWe’ve provided a simple tool to help you when debugging your program. See thread_status.h and thread_status.c. We’ve install threadStatusPrint() as a handler for SIGINT.It will print a brief summary of what each thread is currently doing any time you hit ctrl-c.For example:% ./cracker2 cracker2.in 2 100000 2Start u0000000Start u0000001^C** Thread 0: semaphore wait at cracker2.c:219** Thread 1: processing at cracker2.c:269** Thread 2: processing at cracker2.c:269To use it:  #include \"thread_status.h\"  Call threadStatusSet() to describe what the thread is currently doing. The argument to threadStatusSet() should be a string constant. For example:threadStatusSet(\"initializing\");...while (!done) {  threadStatusSet(\"waiting for task\");  task = queue_pull(task_queue);  threadStatusSet(\"processing\");  ...}When threadStatusPrint() is called, it doesn’t print the exact line number that each thread is at. It just prints the line number of the most recent call to threadStatusSet(). So, for more precise reporting, add more calls to threadStatusSet() to your code.thread_status.h contains macros that will redefine calls to common thread synchronization functions so that when a thread is blocking on one of them, its status will represent that (like the “semaphore wait” on line 219 in the example above).Note: Since Thread Status is hooked to Ctrl-C, you might need to use Ctrl-D (EOF) or Ctrl-\\ (SIGQUIT) to shutdown a running password crackerYou’re not required to use the thread status tool as part of the assignment, we just thought it might make your debugging easier.create_examplesWe’ve also provided a small program to create example input files, to help you with your testing. To build the create_examples program, run make create_examples.To use the program, write its output to a file, then use the file as input to a cracker program.For example:./create_examples 10 100 150 &gt; my_examples.in # write the output to a file./cracker1 &lt; my_examples.inTo see what the cracked passwords should be, use the -soln flag when running create_examples (see the usage documentation given when running the program with no arguments).timing exampleCPU time and so called “wall clock” time are not always the same thing.CPU time is defined as “the amount of time your program spends running on a CPU,” and wall clock time is quite literally, the amount of time that would pass on a wall clock (the kind of clock on a wall) between the time a program starts and a program finishes running.These numbers are often not the same!If your program makes a large number of blocking system calls, it may take 10 seconds to run, but only actually consume 5 seconds of CPU time.In this case, the kernel spent time reading from a file, or writing packets to the network, while your program sat idle.CPU time can also be much larger than wall clock time.If a program runs in multiple threads, it may use 40 seconds of CPU time, but only take 10 seconds of wall clock time (4 threads, each ran for 10 seconds).To demonstrate these differences, we’ve provided a program in tools/timing.c which shows an example of both kinds cases.To compile this program, run make timing, then run ./timing. You should see output like this:sleep(1): 1.00 seconds wall time, 0.00 seconds CPU timesingle threaded cpu work: 0.14 seconds wall time, 0.14 seconds CPU timemulti threaded cpu work: 0.14 seconds wall time, 0.28 seconds CPU time"
  }
    ,
    
  {
    "url_slug": "perilous-pointers",
    "url": " /perilous_pointers",
    "learning_objectives": ["Pointers","Strings","Functions","Function Pointers"],
    "wikibook": ["C Programming, Part 1: Introduction","C Programming, Part 2: Text Input And Output","C Programming, Part 3: Common Gotchas"],
   "title": "Perilous Pointers",
   "content": "IntroductionIn CS 125, CS 225, and other classes, you have used various languages that are considered to be “C-based”, but up to now you may have very limited experience in C programming. This lab will provide a short programming introduction to pointers, strings, and functions in C.This lab will be divided up into two parts. In the first part, you will be debugging broken functions that use pointers incorrectly. In the second part, you will need to write code to call some “creatively defined” functions so that each prints out “Illinois”.For this lab, you should modify only:  part1-functions.c  part2-main.cAll other files will be replaced with new/different files for grading. If you modify any other files for debugging purposes, please ensure you test your program with the original files.Part 1There are erroneous/unimplemented functions in part1-functions.c. Your task is to modify the functions according to the comment above each function so that the output of ./part1 looks exactly as follows:== one() ==20 not passed!100.000000 passed!== two() ==The value of p is: 4== three() ==x and y are equal.x and y are different.== four() ==4 == 4.000000432 == 432.000000== five() ==a is a letter.a is not a letter.== six() ==Hello World!== seven() ==0.000000 0.100000 0.200000 0.300000 0.400000 0.500000 0.600000 0.700000 0.800000 0.900000== eight() ==0 10 40 90 160 250 360 490 640 810== nine() ==orange and blue!ORANGE and blue!Orange and BLUE!orange and blue!== ten() ==The radius of the circle is: 17.500000.The radius of the circle is: 10.000000.== clear_bits() ==17001710200== little finite automatons5467Note that you can just diff with part1-expected-output.Part 2We have given you a file called part2-functions.c, that you may not change. Inside part2-functions.c, you will see twelve different functions, such as first_step():void first_step(int value) {  if (value == 81)    printf(\"1: Illinois\\n\");}To complete Part 2, you must write part2-main.c so that it makes calls to all twelve functions in part2-functions.c, and such that each one prints out its “Illinois” line. When running ./part2, your output should look exactly like this:1: Illinois2: Illinois3: Illinois4: Illinois5: Illinois6: Illinois7: Illinois8: Illinois9: Illinois10: Illinois11: IllinoisNote that you can just diff with part2-expected-output.You should not edit the part2-functions.c file. In fact, when we grade your program, we will replace the part2-functions.c file with a new version of the file (and we’ll change the “Illinois” string so printing out “Illinois” in a for-loop will get you no credit).Compile and RunTo compile the release version of the code, run:make cleanmakeThis will compile your code with some optimizations enabled, and will not include debugging information. If you use a debugger on the ‘release’ build, it will not be able to show you the original source code, or line numbers. Optimizations sometimes expose bugs in your code that would not show up otherwise, but since optimizations tend to reorder your code while compiling, an optimized version of your code is not optimal for debugging.You probably don’t need to worry about the different build types very much for this assignment, but the distinction will become more important on future assignments.To compile your code in debug mode, run make debug instead of make.To run Part 1:./part1or./part1-debugTo run Part 2:./part2or./part2-debug"
  }
    ,
    
  {
    "url_slug": "pied-piper",
    "url": " /pied_piper",
    "learning_objectives": ["Using Pipes","System Call Resilience"],
    "wikibook": ["Pipes, Part 1: Introduction to pipes","Pipes, Part 2: Pipe programming secrets"],
   "title": "Pied Piper",
   "content": "WARNING:fork_and_knife: :bomb: :bangbang:If your code fork-bombs on any autograde, then you will automatically fail this MP. Please make sure that your fork code is correct before committing your code for the nightly autograder.To prevent you from fork bombing your own VM, we recommend looking into ulimit. This will allow you to set a limit for how many times you can fork.Since a learning objective of this assignment is to learn how to use pipes, if you use popen, you will automatically fail this MP.UNIX PipesThe UNIX philosophy embraces minimalist, modular software development. One common saying is, “write programs that do one thing and do it well”. Another one is, “write programs to handle text streams, because that is a universal interface”.In Unix-like operating systems, pipes are a standard way of gluing together small “tools” in accordance with this philosophy. In other word, pipes chain together multiple smaller programs by their standard streams (stdin &amp; stout) to form a larger, more complex processing pipeline. For instance, if you want to kill a process matching a specific name (let’s pretend pkill doesn’t exist), you can do this:ps aux | grep &lt;process name&gt; | grep -v grep | awk '{print $2}' | xargs killwhere the following programs are piped together:  ps aux: Print a list of running processes along with some informations to stdout. The output might look something like this:$ ps aux username     1925  0.0  0.1 129328  6112 ?        S    11:55   0:06 tint2 username     1931  0.0  0.3 154992 12108 ?        S    11:55   0:00 volumeicon username     1933  0.1  0.2 134716  9460 ?        S    11:55   0:24 parcellite username     1940  0.0  0.0  30416  3008 ?        S    11:55   0:10 xcompmgr -cC -t-5 -l-5 -r4.2 -o.55 -D6 username     1941  0.0  0.2 160336  8928 ?        Ss   11:55   0:00 xfce4-power-manager username     1943  0.0  0.0  32792  1964 ?        S    11:55   0:00 /usr/lib/xfconf/xfconfd username     1945  0.0  0.0  17584  1292 ?        S    11:55   0:00 /usr/lib/gamin/gam_server username     1946  0.0  0.5 203016 19552 ?        S    11:55   0:00 python /usr/bin/system-config-printer-applet username     1947  0.0  0.3 171840 12872 ?        S    11:55   0:00 nm-applet --sm-disable username     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:38 conky -q      grep &lt;process name&gt;: Read from stdin, find the lines containing the phrase &lt;process name&gt;, and print to stdout.        grep -v grep: Read from stdin, remove the lines containing the word “grep” (since “grep &lt;process name&gt;” is also a running process), and print to stdout.        awk '{print $2}': awk is a text processing scripting language, and here we’re using awk to fetch the second column of the input (the pid number in this case), and print to stdout.        xargs kill: Read from stdin, form a command consisting of kill &lt;PID&gt;, and executes it.  Voilà, the desired process is killed by the pipeline!How Pipes WorkPipes work simply by feeding the standard output of the first process into the standard input of the second, then feeding the standard output of the second into the standard input of the third, and so on. For instance, in the above example:ps aux | grep &lt;process name&gt; | grep -v grep | awk '{print $2}' | xargs killThe standard output of ps aux is fed into the standard input of grep &lt;process name&gt;, whose standard output is fed into the standard input of grep -v grep, and so on.The ProblemProblem occurs when some of the commands spuriously fail for some reason. This causes all other commands that rely on the output of the failed command to also fail. Once again, let’s take our pipe example:ps aux | grep &lt;process name&gt; | grep -v grep | awk '{print $2}' | xargs killImagine some prankster replaced the usual awk implementation with a misbehaving one that only works normally 50% of the time (the rest of the time, it just exits with a nonzero exit code). This might lead to two things:  If the upstream process (grep) is still writing to its pipe, it will receive a SIGPIPE signal and most likely crash, since it is attempting to write to a pipe with no readers available.  The downstream process (xargs) will not read anything from its stdin, and might throw an error like:kill: not enough argumentsWith larger and more complex pipelines, you can see how such errors might get aggravating. Your goal is, therefore, to build a “resilient pipe” that works like a bash pipe, but allows retries if any process in the pipeline exits with a nonzero exit code.Your SolutionSay we have a typical pipe command:grep piano &lt; inventory.txt | cut -f2 -d'\\t' | mail -s \"sing me a song\" piano_man@gmail.comAs a reminder, &lt; indicates that the file inventory.txt will be treated as the stdin for grep piano, and | (the pipe operator) pipes the stdout of the program on its left to the stdin of the program on its right. Go ahead and try it out yourself! See how the operator works.We’re going to create an executable that does almost the same thing:./pied_piper -i inventory.txt \"grep piano\" \"cut -f2 -d'\\t'\" \"mail -s \\\"sing me a song\\\" piano_man@gmail.com\"the only difference being that if one command fails, it will try again.So, in the above example, pied_piper will first check if the input file, inventory.txt, exists, then exec all three commands in double quotes with their standard streams chained together. And if one command fails, say the mail program terminates early due to a network error, pied_piper will try to execute all the commands again.Note that double quotes are used to create a single argument which may contain many spaces. So, in the above case, argv[3] in the main function would be the string grep piano. Note also that the arguments may contain escaped double quotes, which do not affect the scope of the arguments.In this MP, the argument parsing is done for you, so don’t worry about implementing this, but keep it in mind when you are testing commands with double quotes in them.If you’re interested in how the parser works, it uses the getopt function to get the arguments specified by the flags -i and -o, then it uses optind to find the next argument, which is our first command.The full usage is:./pied_piper [-i input_file] [-o output_file] \"command1 [args ...]\" \"command2 [args ...]\" ...ImplementationIn this MP, the boilerplate functionalities like file handling, argument parsing, and the main routine are handled for you. Your job is to implement the pied_piper() function in pied_piper.c, which does the real work—setting up redirection, and attempting resilience.Here are some pointers on how to proceed:  The pied_piper() function has three arguments:          input_fd: the file descriptor for input file.      output_fd: the file descriptor for output file.      executables: a null terminated char ** (similar to how argv ends with a NULL), containing all the commands to run.        If either the input or output file descriptor is negative, you should use stdin or stdout respectively (like normal).    Try executing all the commands and set up all the pipes.          The stdin of the first program should be redirected from the input file (if exits), and the stdout of the last program should be redirected to the output file (if exists).      Pipe the stdin and stdout of each program so they communicate with each other correctly.      You can use the exec_command() function in util.h, which is a wrapper for exec.      If you get a failure with exec, pipe, or dup2 for any reason, you can simply exit with a nonzero code, though you won’t be explicitly tested on it; these calls failing usually means the entire system is coming down (or maybe you passed a bad executable to exec(), in which case there isn’t much a resilient pipe can do for you).        Wait on all of the processes and check their return codes.  If any process has a non-zero return code, then restart the script (go back to step 2). Try restarting all the processes up a total of two additional times (three runs in total).  If everything goes well once, you are done! Exit with status 0 for success in the pied piper process.  If at least one process fails on the final run, print out a summary of commands, including their return codes and anything printed out to standard error for the last run (hint: look in the utils.h file). You should print out the info for every command, even the ones that succeeded. You should then exit with status EXIT_OUT_OF_RETRIES (see pied_piper.h).  Note: You don’t have to worry about the pipe filling up; the commands we run will have an output of less than the size of the pipe.TestingHow does one test with failures, you ask? You could try using a small C program that reads an environment variable that you set (hint: look up the export keyword), together with another that might sleep for a while before trying to write to a pipe, to ensure it receives SIGPIPE. Or, you could play with random number generators (are you feeling (un)lucky?), if you prefer a Russian roulette-like approach.You have also been provided with a fail_nth program that fails most of the time, and passes on the nth attempt. The code itself is pretty simple, so take a look to see what’s going on there.Hints  You may want to section out your code into the part that tries exec’ing all of the programs.  Our programs will not mangle the input file between runs; you can assume that it will not change. But keep in mind that if a run is halfway complete, and the output file has been partially written to before failure, that the output file should be cleared before you try again.  You do not have to worry about side effects, meaning that if a process completes halfway and changes some system state you will not be expected to change it back. Though this may cause the process to fail in the future, all you have to do is execute the pipeline again.QuizIz FormPlease submit the form here!"
  }
    ,
    
  {
    "url_slug": "savvy-scheduler",
    "url": " /savvy_scheduler",
    "learning_objectives": ["scheduling algorithms","preemptive vs non-preemptive","Relating the different algorithms with a priority queue"],
    "wikibook": ["Scheduling, Part 1: Scheduling Processes","Scheduling, Part 2: Scheduling Processes: Algorithms"],
   "title": "Savvy Scheduler",
   "content": "IntroductionIn this lab you’ll be writing a scheduler. Rather than interacting directly with the operating system, we’ve whipped up a userspace threading library!Before you startThink about how to implement a scheduler!Try to answer these questions…  What do you do for incoming jobs?  How do you sort your job so that you can find the next job according to different scheme?  What kind of data structures do you need?What a scheduler does is to put all the jobs it gets in a queue and then sort them in some order (related to scheme). Scheduler gives them to CPU one by one. The key in scheduler is the scheme it use, and the choice of scheduling algorithm depends on many factors. For example, First Come First Serve (FCFS) is really easy to implement but might keep a short job waiting really long for a long process at the front.So now we know that a scheduler puts jobs in a queue, sort them, and give them to CPU in some order. Then what will be the best data structure to store these jobs? Priority queue can do this job really well! A priority queue is a queue with a really nice feature. It puts every incoming node in correct position so that the queue is always ordered. Therefore, you don’t need to call sort() every time you get a new node (job). And you can simply give them out by pulling out the first element of the queue.An important question now is: “What do you mean by ordered?” Let’s take FCFS scheduling for example. Ideally, scheduler should be able to:  Receive a job.  Put it in a queue with some priority.  Pull the job with highest priority and give to the CPU.And since we are doing FCFS, we want the element that comes first to be at the front of the queue. So you should give jobs arriving earlier higher priority and jobs arriving afterwards lower priority.Take Shortest Job First (SJF) for another example. You can give those jobs that can be finished faster higher priority. As you can see here, the key to implement a scheduler is to decide PRIORITY. And the way to decide priority in a priority queue is by giving a comparator function. By defining a job A is better than a job B in a priority queue, we mean that A has higher priority than B.So basically, half of your job in this lab is simply writing a comparator function that helps you decide which job has higher priority.Mission[Part 1]: Priority QueueTo build a scheduler, a fundamental data structure is a priority queue. The first part of this lab requires you to implement read and understand libpriqueue, our priority queue library. You will be using this library in your scheduler.[Part 2]: SchedulerYou will need to implement scheduling callbacks for a userspace threading library.The scheduling algorithms you are going to implement are:  First Come First Served (FCFS)  Preemptive Priority (PPRI)  Priority (PRI)  Preemptive Shortest Remaining Time First (PSRTF)  Round Robin (RR)  Shortest Job First (SJF)You can read up on scheduling in the wikibook: Scheduling Part 1 and Scheduling Part 2You should use the priority queue that we provided to help you complete this part of the lab.To complete this lab, you must implement the six comparator functions and eight scheduler functions (and one optional one) defined in libscheduler.c. These functions are self-descriptive, but a full function outline for each function is provided for you in the SVN files. These functions will be utilized by the green threading library (Check out the section on Gthreads below).You might want to understand how scheduler works. So we put a detailed explanation in the bottom of this webpage.DirectionsTo help you finish this lab efficiently, we recommend you to follow these steps:  Understand when your function will be called.  Try to write pseudocode for each comparator first and see what kind of information you will need. For example, you probably need the arrival time of each job so you can implement FCFS by setting priority according to time.  Create data members in job_info you need for step 2.  Go back and complete your comparator functions.The second part of the lab is to set up scheduler itself and manage incoming jobs and completed jobs. Now you should implement those functions related to the CPU (like scheduler_new_job(), scheduler_job_finished(), scheduler_quantum_expired()).  Take a look at all these functions, write some pseudocode to realize your thoughts.  You might need to implement some helper functions to help you write these functions.  Finish these functions.The last part of your job is computing stats and clean-up, which is fairly trivial. You may need some extra variables to help you keep track of these stats.Job StructWe have provided a job struct defined in libscheduler.h. You do not need to modify the state, ctx, or stack_start fields. The only field you will be using or modifying is metadata, where you must insert your job_info struct that you will define in libscheduler.c.Functions you need to implementThe only graded file is libscheduler.c. You will need to augment the job_info struct and implement the following functions:void scheduler_start_up(scheme_t s)This function is implemented for you, but you can add some code to it if you need to initialize any global variables.int comparer_fcfs(const void *a, const void *b)Comparer function for fcfs schemeint comparer_ppri(const void *a, const void *b)Comparer function for ppri schemeint comparer_pri(const void *a, const void *b)Comparer function for pri sschemeint comparer_psrtf(const void *a, const void *b)Comparer function for psrtf schemeint comparer_rr(const void *a, const void *b)Comparer function for rr schemeint comparer_sjf(const void *a, const void *b)Comparer function for sjf schemevoid scheduler_new_job(job *newjob, int job_number, double time, scheduler_info *sched_data)This function is responsible for setting up a new job. You must populate newjob-&gt;metatdata with the information found in scheduler_info. The contents of newjob-&gt;metadata cannot be a pointer to sched_data since this variable may be on the stack of the calling function. Once you’ve set up newjob offer it to the queue.job *scheduler_quantum_expired(job *job_evicted, double time)This function is called at the end of every time quantum. If there is no job currently running, job_evicted will be NULL. If the current scheme is not premptive and job_evicted is not NULL, return job_evicted. In all other cases, if job_evicted is not NULL, place it back on the queue and return a pointer to the next job that should run. (Note, it is possible for the next job to be the same as job_evicted)void scheduler_job_finished(job *job_done, double time)This function will be called when a job is finished. You should update any statistics you are collecting and free any buffers you may have allocated for this job’s metadata.double scheduler_average_waiting_time()This function returns the average waiting time across all jobs so far.double scheduler_average_turnaround_time()This function returns the average turnaround time across all jobs so far.double scheduler_average_response_time()This function returns the average response time across all jobs so far.void scheduler_show_queue()This is an optional function that you can implement for debugging purposes.TestingWe have provided three interfaces to testing this lab. The firse testing interface is scheduler_test.c. This file allows you to directly test the functions you’ve implemented in libscheduler.c. We reccomend using this one, and have already populated it with a few test cases of our own! This is how the autograder will be testing your code. There are 10 tests that we have provided you. You can run each test with the following:./scheduler_test [test_no]On success the test will return zero (you can check the return code with echo $?). On failure one of the asserts will cause an error.The second testing interface is write your own tests similar to the ones in main.c in gtest.c. You can then run ./gtest and inspect gthreads.log or any printouts to check if your implementation works.The final testing interface should be thought of as more of a way to gain intuition behind the concepts rather than a way to test your code for correctness. This method is to run your scheduler with the green threading library. You can see example code in main.c which you will not be able to edit. The expected outputs for the various scheduling algorithms are stored in examples/ and you will be able to diff your output to see if your scheduler produces the correct output. There is an example below../main fcfs &gt; test.txtdiff test.txt examples/expected_fcfs.txtFor your convinience, we’ve wrapped this with the bash script testall.sh. Running ./testall.sh will run all the schemes and diff them with the expected output to check if your implementation is correct. If you’d like to test specific schemes, you can pass those in as arguments, for example ./testall.sh rr fcfs pri will only test round robin, first-come-first-serve and priority.However, since this method of testing relies on outputs generated every second, it may not accurately reflect the schedulers behavior, and may falsely report your solution as correctly working. To get around this, you can also take a look at the generated log in gthread.log. This contains information about each thread’s context switches and you can manually inspect it to see if it does what you expect.Using the log file, we have built a visualizer for this data that will display which thread ran in approximately 500ms intervals. Note that the visualizer doesn’t perfectly display all the context switches, and performs especially badly with rund robin output. However, it works well for schemes such as sjf and will display the following if gthread.log contains the log of running ./main sjf:['d10', 'd40', 'd70', 'da0', 'dd0']d10: ++                       d40:   +++                    d70:      +++++               da0:           +++++++        dd0:                  ++++++++There are couple things to note about this output. The first is that each ‘+’ represents something slightly more than half a second so we interpret every two ‘+’s as something close to 1s. The second thing is to note that the thread names are replaced by a uid in the log file. You can which ones corresponding to which by looking through the log for registration messages and the code to check which order the threads were created.Spooky bugsThis lab has some strange gotchas when testing with the gthread library. For this reason, we reccomend using (and augmenting) the tests in scheduler_test.c. If you notice any random segfaults or freezes in the program that occur non-deterministically (maybe only once or twice every 10 runs) please report this to us so we can get that patched! (This will not affect grading since the grader will directly test the functions in libscheduler.c as opposed to the actual context switches generated by the green threading library.The threading model - gthreads (optional reading)Initial idea and code from here.Gthreads is an implementation of green threads in c! It uses libscheduler to schedule the threads.NOTE: The green thread scheduler uses alarms and a SIGALRM handler, it is an error to use some other handler for SIGALRM with gthreads.ConstantsThere are two constants defined as enums in gthread.h, MaxGThreads (not used, remove) and StackSize. Stack size determines the size of the stack for each green thread spawned.Gthread FunctionsgtinitThis function should be called before anything elseThis function sets up the scheduler and a signal handler for SIGALRM. It is undefined behavior to call any other function in gthread before this one.Takes in a scheme_t detailing what scheduling algorithm to be used.gtgoThis is like pthread_create. It spawns a new green thread (won’t start until it’s actually scheduled).It takes in the function to execute and a scheduler_info* to get it’s scheduler attributes.gtstartThis function starts off the scheduling process with a call to ualarm.gtretThis function should be called from a thread to clean up and exit. If called from main it will wait for all other threads to finish before exiting with the status as the argument to gtret. If any other thread calls this function, it is equivalent to calling return.gtsleepThis function will sleep for at least the number of seconds specified by the argument. Unlike sleep(2), this function will also call yield and allow another thread to run (if there is one on the queue).gtdoyieldThis function is a wrapper around the internal function gtyield and might perform a context switch to another thread. The return value will be true if a context switch occured and false otherwise. The argument is not important, so long as it is not -1 or SIGALRM.gtcurrjobReturns a job* indicating the current running jobOkay, so how does this work?The idea of green threads is essentially to have a user-space thread that is lighter than a pthread, but at the cost of not executing in parallel. Instead a green thread will switch between many “threads of execution” giving the illusion of parallel processing. As you might have guessed, this switch involves what we call a “context switch” that allows us to save the current state of the thread before moving to a different one.To learn more about the concept, read this green threading intro article that we used as a starting point.Now, let’s talk about what we’ve added on top of that very simple implmentation. We need a way to preempt threads. For our purposes, a signal is an accpetable solution to this problem. We have used the function ualarm(3) to schedule alarms on regular intervals. The handler then calls gtyield which will call scheduler_quantum_expired to select the next job to run.Note that almost all the scheduling magic is implemented in libscheduler! The only exception is that the main thread will never be sent to any of the functions in libscheduler. Instead, every other quanta, gtyield will store the current job do a context switch to main, and the next time gtyield is called from main, the process will switch back to the stored job."
  }
    ,
    
  {
    "url_slug": "shell",
    "url": " /shell",
    "learning_objectives": ["Processes","Fork, Exec, Wait","Basic Signals","Learning How a Shell Works"],
    "wikibook": ["Forking, Part 1: Introduction","Forking, Part 2: Fork, Exec, Wait","Process Control, Part 1: Wait macros, using signals"],
   "title": "Shell",
   "content": "WARNING:fork_and_knife: :bomb: :bangbang:If your code fork-bombs on any autograde, then you will automatically fail this MP. Please make sure that your fork code is correct before committing your code for the nightly autograder.To prevent you from fork bombing your own VM, we recommend looking into ulimit. This will allow you to set a limit for how many times you can fork.Since a learning objective of this assignment is to use the fork-exec-wait pattern, if you use system, you will automatically fail this MP.BackstoryWell, we’ll keep it short – you got fired. Your boss brought you in for a code review and was more than disappointed. Apparently, she wanted a text editor like this one: we didn’t get the memo. Now it’s time to prove your worth. Your boss wants something fully functional and we’ve got a great idea. You’re going to drop a :fire: :fire: shell on her to get rehired.The basic function of a shell is to accept commands as inputs and execute the corresponding programs in response. You will be provided the vector and format.c libraries for your use. Hopefully, this will make things right and you can resume your work at insert hot tech company here. Feel free to refer to the Unix shell as a rough reference.format.hSince this MP requires your programs to print a variety of things like error messages, we have provided you with our own highly customized formatting library. You should not be printing out to stdout and stderr at all; instead, all output and errors should be printed using the functions provided in format.c and format.h. In format.h you can find documentation about what each function does, and you should use them whenever appropriate. This is our way of ensuring that you do not lose points for formatting issues, but it also means that you are responsible for handling any and all errors mentioned in format.c and format.h.Note: don’t worry if you don’t use all of the functions in format.c.OverviewThe shell is responsible for providing a command line for users to execute programs or scripts. You should be very familiar with bash by now, which will be the basis for your own shell.Starting Your ShellThe shell should run in a loop like this executing multiple commands:  Print a command prompt  Read the command from standard input  Print the PID of the process executing the command (with the exception of built-in commands), and run the commandThe shell must support the following two optional arguments:History-h takes the filename of the history file. The shell should load in the history file as its history. Upon exit, the exact same history file should be updated, even if the shell is in a different working directory than where it started../shell -h &lt;filename&gt;If the the -h flag is not specified, the shell will still keep a history of commands run, but will not read/write from/to a history file. Just think of it like private browsing mode for your terminal.File-f takes the name of the file to be executed by the shell. The shell will both print and run the commands in the file in sequential order until the end of the file. See the following example file and execution:commands.txt:cd cs241echo Hey!./shell -f commands.txt(pid=1234)/home/user$ cd cs241(pid=1234)/home/user/cs241$ echo Hey!Command executed by pid=1235Hey!If the user supplies an incorrect number of arguments, or the script file cannot be found, your shell should print the appropriate error from format.h and exit.The getopt function may come in handy. :smile:SpecificsPromptingWhen prompting for a command, the shell will print a prompt in the following format (from format.c/h):(pid=&lt;pid&gt;)&lt;path&gt;$&lt;pid&gt; is the current process ID, and &lt;path&gt; is a path to the current working directory. Note the lack of a newline at the end of this prompt.Reading in the CommandThe shell will read in a command from stdin (or a file if -f was specified).Running the CommandThe shell should run the command that was read in previously.If the command is run by a new process, the PID of the process should be printed like this:Command executed by pid=&lt;pid&gt;This should be printed before any of the output of the command is printed (prints to be used are in format.c/h).HistoryYour shell should store the command that was just executed, so the user can repeat it later if they wish. Every command should be stored unless otherwise noted. A vector may be useful here.Catching Ctrl+CUsually when we do Ctrl+C, the current running program will exit. However, we want the shell to ignore the Ctrl+C signal (SIGINT). The shell should not exit upon receiving SIGINT. Instead, it should check if there is a currently running foreground process, and if so, it should kill it using SIGINT (the kill() function might come in handy, here and elsewhere).CommandsShell supports two types of commands: built-in and external (i.e. non-built-in). While built-in commands are executed without creating a new process, an external command must create a new process to execute the program for that particular command.Command arguments will be space-separated without trailing whitespace. Your shell does not need to support quotes (for example, echo \"hello there\").Built-in CommandsThere are several built-in commands your shell is expected to support.cd &lt;path&gt;Changes the current working directory of the shell to &lt;path&gt;. Paths not starting with / should be followed relative to the current directory. If the directory does not exist, then print the appropriate error. Unlike your regular shell, the &lt;path&gt; argument is mandatory here. A missing path should be treated as a nonexistent directory.(pid=1234)/home/user$ cd code(pid=1234)/home/user/code$ cd imaginary_directoryimaginary_directory: No such file or directory(pid=1234)/home/user/code$!historyPrints out each command in the history, in order.(pid=1234)/home/user$ !history0    ls -l1    pwd2    ps(pid=1234)/home/user$:warning: This command is not stored in history.#&lt;n&gt;Prints and executes the nth command in history (in chronological order, from earliest to most recent), where n is a non-negative integer. Other values of n will not be tested. The command run should be stored in the history. If n is not a valid index, then print the appropriate error and do not store anything in the history.The following example assumes a fresh history:(pid=1234)/home/user$ echo Echo This!Command executed by pid=1235Echo This!(pid=1234)/home/user$ echo Another echoCommand executed by pid=1236Another echo(pid=1234)/home/user$ !history0    echo Echo This!1    echo Another echo(pid=1234)/home/user$ #1echo Another echoCommand executed by pid=1237Another echo(pid=1234)/home/user$ #9001Invalid Index(pid=1234)/home/user$ !history0    echo Echo This!1    echo Another echo2    echo Another echo(pid=1234)/home/user$:warning: Print out the command before executing if there is a match.:warning: The #&lt;n&gt; command itself is not stored in history, but the command being executed (if any) is.!&lt;prefix&gt;Prints and executes the last command that has the specified prefix. If no match is found, print the appropriate error and do not store anything in the history. The prefix may be empty. The following example assumes a fresh history:(pid=1234)/home/user$ echo Echo This!Command executed by pid=1235Echo This!(pid=1234)/home/user$ echo Another echoCommand executed by pid=1236Another echo(pid=1234)/home/user$ !eecho Another echoCommand executed by pid=1237Another echo(pid=1234)/home/user$ !echo Eecho Echo This!Command executed by pid=1238Echo This!(pid=1234)/home/user$ !dNo Match(pid=1234)/home/user$ !echo Echo This!Command executed by pid=1239Echo This!(pid=1234)/home/user$ !history0       echo Echo This!1       echo Another echo2       echo Another echo3       echo Echo This!4       echo Echo This!(pid=1234)/home/user$:warning: Print out the command before executing if there is a match.:warning: The !&lt;prefix&gt; command itself is not stored in history, but the command being executed (if any) is.exitThe shell will exit once it receives the exit command or an EOF. The latter is sent by typing Ctrl+D on an empty line, and from a script file (as used with the -f flag) this is sent once the end of the file is reached.  This should cause your shell to exit with exit status 0. You should make sure that all processes you’ve started have been cleaned up.Invalid Built-in CommandsYou should be printing appropriate errors in cases where built-in commands fail; for example, if the user tries to cd into a nonexistent directory.(pid=1234)/home/user$ cd /imaginary_directory/imaginary_directory: No such file or directory(pid=1234)/home/user$External CommandsFor commands that are not built-in, the shell should consider the command name to be the name of a file that contains executable binary code. Such a code must be executed in a process different from the one executing the shell. You must use fork, exec, and wait/waitpid.The fork/exec/wait paradigm is as follows: fork a child process. The child process must execute the command with exec*, while the parent must wait for the child to terminate before printing the next prompt.You are responsible of cleaning up all the child processes upon termination of your program. It is important to note that, upon a successful execution of the command, exec never returns to the child process. exec only returns to the child process when the command fails to execute successfully. If any of fork, exec, or wait fail, the appropriate error should be printed and your program should exit with exit status 1. For example, if fork fails:(pid=1234)/home/user$ echo hello worldFork Failed!$Some external commands you may test to see whether your shell works are:/bin/lsecho helloIt is good practice to flush the standard output stream before the fork to be able to correctly display the output.:bangbang: Please read the disclaimer at the top of the page! We don’t want to have to give any failing grades. :bangbang:Logical OperatorsLike bash, your shell should support &amp;&amp;, ||, and ; in between two commands.Important: each input can have at most one of &amp;&amp;, ||, or ;. You do not have to support chaining (e.g. x &amp;&amp; y || z; w).Important: you should not try to handle the combination of the !history, #&lt;n&gt;, !&lt;prefix&gt;, or exit commands with any logical operators. Rather, you can assume these commands will always be run on a line by themselves.AND&amp;&amp; is the AND operator.Input: x &amp;&amp; y  The shell first runs x, then checks the exit status.  If x exited successfully (status = 0), run y.  If x did not exit successfully (status ≠ 0), do not run y. This is also known as short-circuiting.This mimics short-circuiting AND in boolean algebra: if x is false, we know the result will be false without having to run y.:question: This is often used to run multiple commands in a sequence and stop early if one fails. For example, make &amp;&amp; ./shell will run your shell only if make succeeds.OR|| is the OR operator.Input: x || y  The shell first runs x, then checks the exit status.  If x exited successfully, the shell does not run y. This is short-circuiting.  If x did not exit successfully, run y.Boolean algebra: if x is true, we can return true right away without having to run y.:question: This is often used to recover after errors. For example, make || echo 'Make failed!' will run echo only if make does not succeed.Separator; is the command separator.Input: x; y  The shell first runs x.  The shell then runs y.:question: The two commands are run regardless of whether the first one succeeds.MemoryAs usual, you may not have any memory leaks or errors."
  }
    ,
    
  {
    "url_slug": "teaching-threads",
    "url": " /teaching_threads",
    "learning_objectives": ["Introduction to pthreads","Introduction to concurrency","Introduction to synchronization"],
    "wikibook": ["Pthreads, Part 1: Introduction","Pthreads, Part 2: Usage in Practice","Pthreads, Part 3: Parallel Problems (Bonus)","Synchronization, Part 1: Mutex Locks"],
   "title": "Teaching Threads",
   "content": "reduce()In functional programming, there is an operation called reduce. reduce takes three parameters: an input list, a function to apply to the elements of that list, and an initial value (or base case). The function takes two inputs and returns a value. It is first applied to the base case and the first element, and from then on, the function is repeatedly applied to the cumulative result and the next element. reduce then returns the “reduced” value of the entire list. Depending on which direction this is applied, this is sometimes called a left-fold or right-fold. In this problem, the functions are associative, so it does not matter.Here’s a concrete example. Say we have the input list [1, 2, 3], a callback function int add(int elem1, int elem2) which takes two numbers and returns their sum, and a base case of 0. If we call reduce, the resulting value would be add(add(add(0, 1), 2), 3) = 6.In C code, it looks something like this (you can find this in reduce.c):int reduce(int *list, size_t length, reducer reduce_func,           int base_case) {    int result = base_case;    for (size_t i = 0; i &lt; length; ++i) {            result = reduce_func(result, list[i]);    }    return result;}Notice that this is basically a for-loop on the list. There are no fancy algorithms we can use to improve runtime, since the callback function is essentially a black box. So, how can we make it faster? Parallelism to the rescue!par_reduce()Since we guarantee that all the given functions are commutative and associative, reduce becomes embarrassingly parallel, which means that:  it is easy to divide the problem into subproblems, and  none of the subproblems depend on each other.Given an input list [1, 2, 3, 4, 5, 6] and add(), we can meet the requirements for “embarrassingly parallel” by doing the following with 2 threads:  Thread 1: evaluate reduce([1, 2, 3])  Thread 2: evaluate reduce([4, 5, 6])  Thread 1: write reduce([1, 2, 3]) into index 0 of the new list  Thread 2: write reduce([4, 5, 6]) into index 1 of the new list  Join the threads  Main thread: evaluate reduce(new_list) = reduce([6, 15])Finally, we should have our answer of 21. Notice that the size of the list in the last call in the main thread is exactly the number of threads used, because we have one result from each thread. In this case, the final list is of size 2.Also, note that none of these subproblems depend on each other to evaluate due to our guarantees on the associative property, so they can safely be done concurrently.Now, it would be unfortunate if someone had to manually figure out the assignment of jobs to each thread every time some aspect of the problem changed, such as the size of the input list, the callback function, the number of threads, or the base case. To alleviate that, we are providing our users with a nice par_reduce() function that takes in an input list, callback function, base case, and the number of threads (not including the main thread). The end goal is that par_reduce() does exactly what reduce() does (in the case that the given functions are associative) except in parallel, with multiple threads. To the user, it’s the same old reduce() function—just faster!For this lab, you are responsible for implementing par_reduce() in par_reduce.c.Some food for thought:  What does int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); do?          What are start_routine and arg?        What information does each thread need to know in order to do its job?  How would you divide the problem among your threads?  What does int pthread_join(pthread_t thread, void **retval); do?          What is retval?        How can you make sure to always spawn the least number of threads?          You have an example above where the length of the list is greater than the number of threads, what about the opposite scenario?      Testing your codeWe have provided a makefile that will compile your code along with our framework. We recommend that you read through main.c so that you understand how we are calling your par_reduce in par_reduce.c.After running make, you can run the executable as follows:./par_reduce &lt;reducer_name&gt; &lt;list_len&gt; &lt;num_threads&gt;  &lt;reducer_name&gt; is one of the following: “add”, “multiply”, or “slow”.          “add” adds every element with a base case of 0.      “mult” multiplies every element with a base case of 1.      “slow” doesn’t perform any computation, but sleeps a small amount each time it is called. You may notice that add and multiply might get slower the more threads you use–this is because starting new threads takes time, and sometimes the extra time needed to spawn new threads exceeds the time saved in computation, especially for extremely quick ones like addition. So, we’ve given you a “slow” reducer that will let you test to make sure that running with n threads will take around 1/n time.        &lt;list_len&gt; is the number of elements in the list of random integers we’ll pass to your par_reduce.  &lt;num_threads&gt; is the number of threads to use.You can also run make debug and run the debugging executable with the same arguments:./par_reduce-debug &lt;reducer_name&gt; &lt;list_len&gt; &lt;num_threads&gt;"
  }
    ,
    
  {
    "url_slug": "text-editor",
    "url": " /text_editor",
    "learning_objectives": ["Writing a C program","File I/O, serializing/deserializing","String manipulation","Leveraging a datastructure","Writing an event-driven program"],
    "wikibook": ["C Programming, Part 1: Introduction","C Programming, Part 2: Text Input And Output","C Programming, Part 3: Common Gotchas","Memory, Part 1: Heap Memory Introduction"],
   "title": "Text Editor",
   "content": "BackstoryIt’s time to end the feud between vim, emacs and nano users (although everyone knows vim is the best). We’re going to be implementing a text editor that blows them all out of the water! Of course, a full-fledged text editor is a substantial project that’s usually open source, so you’ve got some “contributions” from the “open source community” (yours truly) and have been provided some of the components: namely, a vector library, an incomplete abstraction of a document, and a few different input methods (we’ll talk about those later).It’s your job to finish up the document abstraction and write the callbacks that actually edit the file.OverviewYour editor has two modes: a line editor mode (like ed) and a text user interface (TUI) mode (like vim or nano). These are described in more detail below. Both of these modes make use of the same text-editing functions that you will be implementing. You should use the line editor for initial testing, and you can try the TUI once you have completed some work on the code.Your basic line editor can be run with:$ ./editor &lt;filename&gt;For the TUI, add the -n flag:$ ./editor -n &lt;filename&gt;The file will be loaded into a document object for manipulation using document_create_from_file(). Then, editor_main.c will get input from the user in a loop and call the appropriate functions in editor.c. You will need to fill in the functions in editor.c.Important: Lines will be 1-indexed for this assignment! Characters within a line are still 0-indexed.Important: Send all your debug printing to stderr instead of stdout.Please keep the following in mind when implementing your text editor:  There is no limit on the number of lines.  There is no limit on the number of characters per line.  Some lines may be empty (you should treat these as empty strings, “”).  Only when the user gives the save command will the contents of the file on disk be modified.  All your editor operations should use the document library to modify the document. Don’t write directly to the file!FeaturesMake sure your editor can perform the following basic tasks:  Display the contents of a file.  Insert text into a file at a specified line number and character index.  Delete n characters of text from a file at a specified line number and character index.  Delete a line of text from a file.  Search: find the next occurrence of text in a file and return the location of the match.  Merge and split lines.  Save the file to disk.  Quit the editor.Format LibraryWe have provided a format library that handles all printing to stdout or stderr.  This is to ensure that you do not lose points for not matching the format that the autograder expects.Please take a look at format.c and format.h. These files include all the error messages and printouts that you need. (There aren’t many for this MP, but later ones will have more.)DocumentWe have provided an incomplete abstraction of a document that uses the vector API from the Perilous Pointers.You only need to implement the functions document_write_to_file, document_create_from_file, and document_insert_line.Since you’re working with files, you should have basic notions of serialization and deserialization. Serialization is the process of converting the state of a data structure or object into a representation that can be stored (in this case, in a file) or transmitted. Deserialization is the reverse process, where a serialized representation is converted into the original data structure or object. These two processes are equal and opposite, and will cancel each other out if sequentially applied on something. That is, deserialize(serialize(x)) == x.Make sure you’re completely clear on the difference between a vector and a document! Your document uses an underlying vector to represent the state of a file, and each entry in the vector corresponds to a single line in the file. This makes it much easier to manipulate individual lines.Recall that POSIX defines a line as “A sequence of zero or more non-&lt;newline&gt; characters plus a terminating &lt;newline&gt; character”. When you’re working with the document, be careful how you handle newlines in the files you’re opening. Remember, serialization and deserialization are equal and opposite. Your document already provides an abstraction for lines of text. Do you need to add the newline characters to the strings you store?Valid Documents and Inputs?When opening documents, assume that the document will always be a document created by this text editor. That means it will always have valid characters.Note that we do print tabs as a single space. This is to prevent graphical glitches in the TUI mode.Remember! An empty or non-existent file can be a valid document!sstream libraryBy now you’ve probably realized that the standard C library doesn’t have many tools for working with strings, at least not as many as some other languages, such as python, do by default. To make our lives easier we are going to be building a string library called sstream (which is short for ‘string stream’) that allows you to deal with strings at a higher level. To this end, we are going to provide you with the skeleton of this library so that you can implement some string manipulation functions, which will make your tasks in editor.c much simpler. Here’s a proof of concept.bytestring output = {NULL, 0};// size will be 4, position will be 0sstream *strm = sstream_create((bytestring ){\"\\0\\0\\0\\0\", 4}); // returns 3, output should be {\"\\0\\0\\0\", 3}sstream_read(strm, &amp;output, 3);// returns 3sstream_tell(strm);// returns 0, position is now 4sstream_seek(strm, 1, SEEK_CUR);// returns -1, position is still 4sstream_seek(strm, 1, SEEK_END);// returns 0sstream_remain(strm);// size will be 14, position is now 0sstream_str(strm, (bytestring ){\"Doesn't matter\\0 what comes after\", -1});// size will be 22, position still 0sstream_append(strm, (bytestring ){\", at all\", -1});sstream_seek(strm, 0, SEEK_END);// returns 22, position still 22, output-&gt;str is \"Doesn't matter, at all\"// output-&gt;size is 22sstream_read(strm, &amp;output, -39);sstream_seek(strm, 0, SEEK_SET);// entire expression returns 0, position now is at 11sstream_seek(strm, sstream_subseq(strm, (bytestring ){\"ter\", -1}), SEEK_CUR);// note that erase operations are commutative; order doesn't matter; after// both erases, stream buffer should contain \"Doesn't, at all\"sstream_erase(strm, 3);sstream_erase(strm, -4);// and now should contain \"Doesn't compute, at all\"sstream_insert(strm, (bytestring ){\" compute\", -1});// note that LONG_MIN=-9223372036854775808                          //                                                        |long will overflow here, starting with the 9sstream_write(strm, (bytestring ){\"-00009223372036854775809+30\", -1});long out;// returns 23, out = -922337203685477580sstream_parse_long(strm, &amp;out);// returns 1, out = 9sstream_parse_long(strm, &amp;out);// returns -1sstream_parse_long(strm, &amp;out);More details about the functions you will need to implement can be found in sstream.h.Line Editor ModeThis is what runs if you don’t add the -n flag. You should be doing some initial testing with this mode, as it is easier to debug with than the TUI.You have the following commands available with the line editor:  s:                                       Saves a file  q:                                       Quits the editor  p [optional lineno]:                     If no lineno is given, print the whole file; otherwise, print five lines centered around lineno  p [lineno] [idx] [max_lines] [max_cols]: Print at most max_lines lines starting from the lineno  d [lineno]:                              Deletes line at lineno (shifts all lines past lineno up by 1)  d [lineno] [idx] [num_chars]:            Deletes at most num_chars characters from line at lineno starting at character index idx (shifts all characters past idx+num_chars to the left)  w [lineno] [string to insert]:           Replaces line at lineno with string to insert  a [lineno] [string to insert]:           Appends string to insert to the line at lineno  i [lineno] [idx] [string to insert]:     Inserts string to insert to the line at lineno starting at the character index idx  m [lineno]:                              Merges line at lineno with lineast lineno+1  sp [lineno] [idx]:                       Splits a line at lineno from character index idx (All subsequent characters inserted on a new line below)  f [lineno] [idx] [search string]:        Searches for the next instance of the search string after line lineno and character index idxThe line editor works by matching your input against a few regular expressions. You do not need to implement this; we have provided the code in editor_main.c.Regular ExpressionsThis section is optional reading material! In case you wanted to know how our parser works, we use regular expressions (regexes) are powerful tools that are used to describe regular languages. Although there are things regex can and can’t do (it can’t parse HTML for instance), it is useful for searching for patterns in strings and input validation. vim, grep and a few other command-line utilities all use the POSIX regex syntax to allow users to search and perform other tasks. We can use it here to check for valid input strings.This is used in editor_main.c. To learn more about matching regex patterns in c try man regex. To learn more about POSIX regex syntax in general, see man 7 regex.Text User Interface (TUI)Because you want to really beat the competition, you’ve gone ahead and decided to use a text user interface (or TUI for short). Don’t worry though, we’ve already done this part for you. All you have to do is make sure that the callbacks for the TUI (defined in editor.c) work perfectly.The TUI supports the following interaction:  Inserting text (just by typing)  Splitting a line (press Enter while in the middle of a line)  Merging a line (press Delete at the end of a line or Backspace at the starting of one)  Deleting text (Delete or Backspace)  Deleting a line (Ctrl+W)  Finding text in the file (Ctrl+F to search; read below to see how search should work)  Saving the file (Ctrl+X)  Exiting (Ctrl+A)Note: You may be wondering why we use Ctrl+X instead of Ctrl+S to save. By default, Ctrl+S locks the terminal and Ctrl+Q unlocks it.Note: On Mac keyboards, Delete and Backspace are respectively Fn+Delete and Delete.Important: The TUI isn’t capable of using all of your editor’s features! For example, the TUI does not support deleting multiple characters at once. You still need to implement everything. We WILL be testing for ALL features.LocationIn order to keep track of the cursor position, we have provided a struct typedef’ed to location defined in editor.h as:typedef struct {  size_t line_no;  size_t idx;} location;Some functions you will be implementing will take in a location argument to know where to edit the file.EditorWe have defined and typedef’d a struct editor to keep track of various variables. Here is the definition from editor.h.typedef struct {  document *document;  sstream *stream;  char *filename;} editor;Most functions in editor.c that you will edit take in an editor*. This will allow you to access the underlying document and make use of the stream.FunctionalityThe functions you will have to implement are listed and documented in editor.h, document.h and sstream.h.This section explains what you need to implement for the editor portion of this MP in more detail.Display ContentsYour text editor should be able to print out the contents of the file that is loaded.Suppose we had a file things_on_my_table.txt which contained the following:mugsaltT.V. remoteNow, calling handle_display_command() with start_line and max_lines as 1would print out the following if things_on_my_table.txt was loaded as a document:1    mugHowever, calling handle_display_command() with start_line as 1 and max_lines as 5 would print out:1    mug2    salt3    T.V. remoteSince there were fewer than five lines of text.If max_lines == -1, you should print from start_line to the end of the document.You can ignore the variables start_col_index and max_cols (these are used for handling the TUI display)—just be sure to pass them on to the appropriate function in format.h.Again, make sure to use format.{c,h} to print these lines out.Note: This function could be called with ‘start_line’ as 0 for an empty document!ErrorsIf the user asks you to print a document which is empty, call print_document_empty_error() in format.{c,h} to tell the user that they can’t do that. You can assume that all of your functions which depend on cursor locations are always given valid locations.Inserting TextNow, using the same things_on_my_table.txt file:If a user were to call handle_insert_command() with line = \"peanuts \" and loc.line_no = 1 and loc.idx = 1, the result of the file would be:1    mpeanuts ug2    salt3    T.V. remoteYou can assume that loc.line_no is always greater than or equal to 1! (If you want to be really fancy, you can even add this in an assert!)Note: If the line a user is inserting to is currently empty, that’s fine!Note: If your editor is asked to insert to a line that does not exist yet, then it should fill in the gap with empty lines. (How can you use document to make this easy?) You must handle inserts at the end of a line (so that appending text is possible), but you do not need to handle inserts past the end of line.Writing/Appending TextThis overwrites/appends to any text that may already be on that line. If the line doesn’t exist, it will first create it (this is similar to how insert works).To make things more interesting, you will need to interpret \\ as an escape character. There is only one special escape sequence you need to recognize: \\ followed by a n for a newline. \\ followed by any other character (including the null byte) will be replaced with the second character. So \\n will need to split the line, but \\\\n will insert the text \\n. Likewise, \\d will be replaced with the character d.For every \\n (\\ followed by n) that you encounter, you will need to split the string there and then insert the remainder of the string on a line by itself. Note that there can be several \\n on a single input line.Escaping characters is only necessary for the functions handle_write_command and handle_append_command. Insert does not need to implement handling escape characters.For example, using the line editor mode, suppose the input file is:1       Hello2       Goodbye3       Hello again!4       Goodbye again!and I use the command w 3 Yes\\nNo, the file becomes:1       Hello2       Goodbye3       Yes4       No5       Goodbye again!Then, if I use a 1 \\nworld!\\nHaha, the file becomes:1       Hello2       world!3       Haha4       Goodbye5       Yes6       No7       Goodbye again!Then if I use a 1 \\\\n \\a\\, the file becomes:1       Hello\\n a2       world!3       Haha4       Goodbye5       Yes6       No7       Goodbye again!Deleting TextThere are two types of deletes: deleting characters and deleting lines.Deleting CharactersThis function is to be implemented in handle_delete_command. The current location of the cursor is defined by the location argument loc. The function will delete num_chars characters at the specified line number from the specified character index until the end of the line.Deleting LinesThis function is to be implemented in handle_delete_line. This function takes in a size_t argument called line_no to specify the line number which should be deleted.Finding TextYour text editor should be able to find the next occurrence of a string from the current cursor location. You will implement this in the function handle_search_command. The current location of the cursor is defined by the location argument loc. This function will return a location to inform the editor of the location of the results.Suppose we had the following file (already loaded into the editor):1    According to all known laws of aviation,2    there is no [w]ay that a bee should be3    bees beEs Bees beesAssume that [] represents the position of your cursorIf your user searches for the string “bee” then your cursor should move to the next instance of the string bee including and after the current character as shown below:1    According to all known laws of aviation,2    there is no way that a [b]ee should be3    bees beEs Bees beesNote: the TUI automatically increments the character index by one so that the search function doesn’t match the same result twice. If you’re writing your own test cases and want it to act the same way as the TUI, you should handle this increment on your own. Your function in editor.c should not account for this.Searching for “bee” again:1    According to all known laws of aviation,2    there is no way that a bee should be3    [b]ees beEs Bees beesNote that the string only has to contain the search string. It’s okay if there are characters before or after the found position.Additionally, the search is case-sensitive, so searching for bee again:1    According to all known laws of aviation,2    there is no way that a bee should be3    bees beEs Bees [b]ees…will skip the two instances of “bee” with capital letters.Finally, the search wraps around the file. So, if we search for bee one more time:1    According to all known laws of aviation,2    there is no way that a [b]ee should be3    bees beEs Bees beesWe’re back to the first instance of bee.If the search string is empty or not present in the file, return a location with line_no set to 0.The search string does not have to be a word by itself! For example if I was to search for the string ana in the following file:1    B[a]nanawill have the above result. Searching for ana again:1    Ban[a]naWill just find the second instance of ana.Hint: strstrMerging LinesWhen a user enters a Backspace at the beginning of a line, then the previous line and the current line should merge. Likewise, when they enter Delete at the end of the line, the current line and the next line should merge.You must implement the function handle_merge_line. This function has a location as an argument and requires you to merge the line located at line_no with the line located at line_no + 1. (We will always call this function with a valid line number, such that line_no and line_no + 1 both exist.)An example using the same lines as in the first example:1    mpeanutsug2    [s]alt3    T.V. remoteInputing m 1 or pressing backspace from the position specified by [] will merge the line:1    mpeanutsug[s]alt2    T.V. remoteSplitting LinesWhen a user inputs sp [lineno] [idx] or presses the Enter key anywhere in a line, the line should split.You must implement the function handle_split_line. This function has a location as an argument and requires you to split the line located at loc.line_no at the character index loc.idx.An example:1    mpeanutsug[s]alt2    T.V. remotePressing enter from the position specified by [] will split the line:1    mpeanutsug2    [s]alt3    T.V. remoteSaving TextThis should simply write the text to the file. Implement this in the function handle_save_command.(Optional) Extending the TUIThis part will not be graded.In order to make our text editor a real competitor with existing ones, we need to make sure thatwe have a good way of improving it and adding new features. An extensions system makes it easy forthe community to do all this hard work for with us.Take a look at exts/Instructions.md for more information on how to make your own extension.For example, you could implement a copy/paste function for lines or words. I would really like to see someone implement a search and replace extension. Please reach out to us if you do that.Share your extensions on Piazza if you come up with a cool feature!Managing MemoryRemember, man is man’s best friend. Since you’re working with dynamic memory, there are quite a few functions you should be familiar with before you proceed. malloc, free, realloc,  calloc, memmove are your friends; don’t shy away!  man 3 malloc  man 3 free  …et ceteraUndefined BehaviorUndefined behavior is a scenario or edge case for which there is no documentation describing how the code should react. For example, man pages do not describe what happens when you feed NULL into strcmp. Your open-source contributors will not answer questions like “What if my user wants an element past the end of the vector?”, because that is undefined behavior.So, for this MP, you should use assert statements to check that your user is passing valid input to your function before operating on the input. For example, if you were implementing strcmp(const char *s1, const char *s2), then your code might look like this:#include &lt;assert.h&gt;strcmp(const char *s1, const char *s2) {    assert(s1 != NULL &amp;&amp; s2 != NULL);    // Compare the two strings    .    .    .    return rv;}TestingWe have provided a file editor_test.c where you can programmatically testyour editor. This compiles to editor_test and editor_test-debug. We strongly recommend testing by adding test cases to editor_test.c and running editor_test instead of just testing using editor, as this will make your life a lot easier as you can test very specific things faster.Line Editor ScriptsHere’s a feature you don’t find everywhere! (To be fair, you actually can do this and more with sed.)Suppose we have a file with the following test:1      Somebody once told the world was gonna roll2      I ain't the sharpest tool in the shed3      She was looking kinda dumb with her finger and her thumb4      According to all known laws of aviation5      In the shape of an L on her foreheadand I use the following commands:d 4a 1  mew 5 #I'mSorryForTheBadJokesqI should have the following:1      Somebody once told the world was gonna roll me2      I ain't the sharpest tool in the shed3      She was looking kinda dumb with her finger and her thumb4      In the shape of an L on her forehead5      #I'mSorryForTheBadJokeWhat if I wanted to save this process so that I can edit other files with the same error?You can! Just save the commands to a file commands.txt, containing:d 4a 1  mew 5 #I'mSorryForTheBadJokesqand then you can run it by using cat commands.txt | ./editor [inputfile]This can be used to test the editor’s behavior quickly!"
  }
    ,
    
  {
    "url_slug": "utilities-unleashed",
    "url": " /utilities_unleashed",
    "learning_objectives": ["Fork, Exec, Wait","Environment Variables","Writing a C Program","Using argv, argc","Introduction to core utils"],
    "wikibook": ["Forking, Part 1: Introduction","Forking, Part 2: Fork, Exec, Wait"],
   "title": "Utilities Unleashed",
   "content": "OverviewIn this lab, you will be implementing the following C utilities:  time  envNotes:  Do not worry about flags or features that we do not mention.  Do not print any of your debug information out for your final submission.  All printing (except env vars) should be handled with format.h.  A common issue is double printouts. If this happens to you, try flushing stdout before you fork/exec. If this solves your issue, ask yourself why.WARNING!If you fork bomb on any autograder run, you will receive a zero on this assignment.To prevent you from fork bombing your own VM, we recommend looking into ulimit. This will allow you to set a limit for how many times you can fork.format.c and .hSince this lab requires your programs to print messages to stdout and stderr, we have provided you with format.c and format.h. You should not be printing out to stdout and stderr at all. Instead, you should be using the provided functions. You can find documentation for each function in format.h. Please read the documentation in format.h multiple times to determine when each function should be used. This is our way of ensuring that you do not lose points for formatting issues, but it also means that you are responsible for handling any errors mentioned in format.c and format.h.It is common for students to fail certain test cases on this assignent with seemingly functional code, it is almost always because of improper usage of format.h.timeIn this lab, you will be implementing time.time – run a program and report how long it tookSo if a user enters:./time sleep 2then time will run sleep with the argument 2 and print how long it took in seconds:2.002345 secondsFor more examples, you can play with Linux’s builtin time command by typing time YOURCOMMAND (time ls -l, for example) in your terminal. Be sure to add ./ to the beginning (or use the full path to your time executable file if you are in another directory), otherwise the builtin time will be called.Note that we only care about wall-clock time, and we recommend using clock_gettime with CLOCK_MONOTONIC.Pro tip: 1 second == 1,000,000,000 nanoseconds.Nota bene:  You may not use the existing time program.  You must use fork, exec, and wait (no other solutions will be accepted).  If the child process does not terminate successfully (where its exit status is non-zero), you should exit with status 1 without printing the time.  We will only run time with one program.  The commands we will run can take any number of arguments.  Do your time computations with double-precision floating pointer numbers (double) rather that single-precision (float).  We have provided functions in format.h that we expect you to use wherever appropriate.Useful Resources  Program arguments: argc &amp; argv  fork, exec, wait  fork and waitpidenvIn this lab, you will be implementing a special version of env.env – run a program in modified environmentsUsage:./env [-n #] [key=val1,val2,...] [key2=val1,val2,...] ... -- cmd [args] ..Please re-read this section multiple times before starting:  -n N is an optional flag that indicates how many values there are for each variable. N must be a number more than zero, and is only required if more than 1. This means that if each key only has 1 value, -n is NOT needed.  Each variable is in the form of NAME=v1,v2,v3...vN, separated by spaces.  For each variable, there can either be one or N values. (There can only be N if and only if the -n flag is used.)  Values may contain references to environment variables in the form %NAME, including variables that were set earlier. As a result, variables should be processed from left to right.  Each reference should be replaced with its value.  The names of variables (both in key and in value) only contain letters, numbers, or underscore characters.  For each environment variable key/value pair, env will assign value to key in the current environment. If N is more than 1, you must iterate through all pairs of values.  Each execution must be done with fork, exec, and wait.  The executions must be done sequentially, not in parallel.  The last variable/value(s) pairing is followed by a --.  Everything following the -- is the command and any arguments that will be executed by env.  So, if A=1,2,3 and B=4,5,6 and we want to exec cmd, cmd will be executed three times. Once with A = 1, B = 4, then A = 2, B = 5, and finally A = 3, B = 6.  If any key has one value instead of N, you should set that key to that value N times.  If A=1 and B=4,5,6, then you want to execute cmd three times again, but each time has A=1, and B switches between 4, 5, and then 6.  Since variables can contain references to environment variables, and execution has to be done sequentially - you can have something of the form A=1,2,3 and B=4,%A,6, then you want to execute cmd three times again, once with A = 1, B = 4, then A = 2, B = 2, and finally A = 3, B = 6.  Invalid input should result in the usage being printed. It is your job to enforce correct usage! You shouldn’t ignore bad usage.This is the canonical example and a practical use case:$ ./env -n 4 TZ=EST5EDT,CST6CDT,MST7MDT,PST8PDT -- dateSat Sep  9 19:19:42 EDT 2017Sat Sep  9 18:19:42 CDT 2017Sat Sep  9 17:19:42 MDT 2017Sat Sep  9 16:19:42 PDT 2017$It runs date four times, once for each time zone, and shows us the result.(Note: the output is in order of the variables, and is done sequentially.)Example of using references to other variables:$ ./env -n 4 TEMP=EST5EDT,CST6CDT,MST7MDT,PST8PDT TZ=%TEMP -- dateSat Sep  9 19:19:42 EDT 2017Sat Sep  9 18:19:42 CDT 2017Sat Sep  9 17:19:42 MDT 2017Sat Sep  9 16:19:42 PDT 2017$This has the exact same behavior as before, because TEMP is first set to EST5EDT, and then when TZ is set to %TEMP, the value of EST5EDT is retrieved and then TZ is set to that.Notice that the variables are set sequentially, or else it wouldn’t work.Again like time, you can play with Linux’s builtin env command by typing env &lt;var-list&gt; &lt;command-name&gt; (env MYVAR=CS241 printenv, for example) in your terminal. Again, remember to add ./ to the beginning (or the full path to your env executable file if you are in another directory), otherwise the builtin env will be called. Keep in mind that the builtin env does not match our specifications.In addition, keep in mind that the builtin env uses $ instead of % to denote environment variables, and they are separated by spaces in the var list instead of commas.In practice, it can be very useful to change some environment variables when running certain command.For example, you may notice people write #!/usr/bin/env python on the first line of their Python script. This line ensures the Python interpreter used is the first one on user’s environment $PATH. However, users may want to use another version of Python, and it may not be the first one on $PATH. Say, your desired location is /usr/local/bin for instance.One way to solve this is by exporting $PATH to the correct position in your terminal, however, this may mess up other commands or executable under the same session.An alternative and better way is to use our env, and enter:./env PATH=/usr/local/bin -- ./XXX.pythen it runs the script with the desired Python interpreter.Nota bene:  You may not use the existing env program. (Our specification is different than the existing env program.)  You may not replace % with $ or use wordexp(3).  You may not use execvpe, execve, or execle.  All changes in environment variables and execution must happen only in the child process.  You must use fork/exec/wait.  If a variable doesn’t exist, interpret its value as a zero-length string.  Do not fork bomb the autograder! You will fail if you forkbomb the AG. (See the warning.)Useful Resources  Environment variables  Environment variable functions  string.h  Split a string by a delimiterQuizIZSubmit your QuizIZ username"
  }
    ,
    
  {
    "url_slug": "vector",
    "url": " /vector",
    "learning_objectives": ["Implementing a C++ style Vector in C","Using Dynamic/Heap Memory","Using malloc(), free(), calloc(), realloc()","Function Pointers","OOP in C","String manipulation in C"],
    "wikibook": ["C Programming, Part 1: Introduction","C Programming, Part 2: Text Input And Output","C Programming, Part 3: Common Gotchas","Memory, Part 1: Heap Memory Introduction"],
   "title": "Vector",
   "content": "Groundwork For Text Editor and ShellYou are an intern at Macrohard, where you’ll be writing a text editor and shell for everyone on your team.These projects will take you several weeks, and your mentor has decided on the following timetable:  Week A: Vector and Sstream  Week B: Text Editor  Week C: ShellThe Text Editor will use a TUI that another intern has written. Your mentor has decided to create a library to make dealing with strings in C easier.The Shell is a terminal. Like all good terminals, your shell will need to remember what processes are running.However, after hearing tales of your talent, and with vectors being all the rage, other team leads have asked for vectors that they can use in their own projects. One option would be to write a vector for each team. However, being a good programmer, you know that code duplication is bad. Also, you’re a lazy programmer, so you want to write as little code as possible to accomplish everything. You decide to implement a generic vector, something that every team can use with minimal changes.VectorA vector is an array that grows as a user adds and removes items from it. (Since CS 225 was a prerequisite, you probably knew all of that already.) However, your vector will need to be feature-rich enough for someone to easily create a document from it, or anything else the other sneaky teams want for their projects.Your implementation should go in vector.c, which is the only file that will be sent to your team lead for review. As an intern looking to become a full-time employee, you should create test cases in vector_test.c to show you are a responsible programmer. Your mentor has left notes in vector.h guiding your implementation.In case a fellow employee asks what you learned in CS 225, here’s some review:  Lectures  Array Resizing  Lecture RecordingSince this vector is generic, it will have to call custom constructor, destructor, and default constructor functions when objects are added or removed. (How is this better than a single function which handles all possible types?) Thus, your vector structure will contain pointers to your constructor or destructor routines, and you can initialize the vector by passing pointers to these functions as parameters.What you’ll end up with is a useful general-purpose vector, capable of dynamically expanding. (No more fixed-sized buffers!)Note: Remember that vector size (the number of actual objects held in the vector) and capacity (size of the storage space currently allocated for the vector) are two different things. Refer to documentation in vector.h and vector.c for more information.sstringSString is a wrapper around c strings which makes dealing with strings easierwith higher level functions. We have not specified the definition of the sstringstruct, and left that up to you! Below are some brief descriptions of what eachfunction should do.sstring *cstr_to_sstring(char *input)This function should take in a c-string and return a pointer to a sstring on theheap.char *sstring_to_cstr(sstring *this)This function should take in a sstring an return a pointer to a c-string on theheap.int sstring_append(sstring *this, sstring *addition)This function should take in two sstrings, append the second to the first, andreturn the length of the first sstring after the append.vector *sstring_split(sstring *this, char delimiter)This function should take an sstring and a character and split the sstring intoa vector of c-strings on the delimeter.(e.g. sstring_split(cstr_to_sstring(\"abcdeefg\"), 'e') == [ \"abcd\", \"\", \"fg\" ])int sstring_substitute(sstring *this, size_t offset, char *target, char *substitution)This function should substitute one occurance of target in this afteroffset bytes with substitution. If there are no occurances of target afteroffset bytes, return -1.  Otherwise return 0.char *sstring_slice(sstring *this, int start, int end)This function takes in a sstring, a start index and an end index. Return ac-string representing the bytes between start (inclusive) and end (exclusive).void sstring_destroy(sstring *this)This function cleans up any allocated memory for a sstring.Managing memoryRemember, man is man’s best friend. Since you’re working with dynamic memory, there are quite a few functions you should be familiar with before you proceed. malloc(), free(), realloc(),  calloc(), memmove() are your friends; don’t shy away!  man 3 malloc  man 3 free  …there’s a pattern hereUndefined behaviorUndefined behavior is a scenario or edge case for which there is no documentation describing how the code should react. For example, man pages do not describe what happens when you feed NULL into strcmp(). Your mentor will not answer questions like “What if my user wants an element past the end of the vector?”, because that is undefined behavior.So, for the entirety of this MP, you should use assert() statements to check that your user is passing valid input to your function before operating on the input. For example, if you were implementing strcmp(const char *s1, const char *s2), then your code might look like this:#include &lt;assert.h&gt;strcmp(const char *s1, const char *s2) {    assert(s1 != NULL &amp;&amp; s2 != NULL);    // Compare the two strings    .    .    .    return rv;}Writing test casesJust to emphasize how important test cases are, this lab spec will repeat itself and remind you that as good programmers, you are expected to write your own test cases for sstring and vector."
  }
      
      ,
      
    
  

  {
    "title": "C Programming, Part 1: Introduction",
    "url": " /wikibook/c-programming-part-1-introduction",
   "content": "Want a quick introduction to C?  Keep reading for the quick crash-course to C Programming below                              Then see the [[C Gotchas wiki page          C Programming, Part 3: Common Gotchas]].                                                  And learn about [[text I/O          C Programming, Part 2: Text Input And Output]].                      Kick back relax with Lawrence’s intro videos (Also there is a virtual machine-in-a-browser you can play with!)External resources  Learn X in Y (Highly recommended to skim through!)  C for C++/Java Programmers  C Tutorial by Brian Kernighan  c faq  C Bootcamp  C/C++ function reference  gdb (Gnu debugger) tutorial Tip: run gdb with the “-tui” command line argument to get a full-screen version of the debugger.  Add your favorite resources hereCrash course intro to CWarning new page Please fix typos and formatting mistakes for me and add useful links too.*How do you write a complete hello world program in C?#include &lt;stdio.h&gt;int main(void) {     printf(\"Hello World\\n\");    return 0; }Why do we use ‘#include &lt;stdio.h&gt;’?We’re lazy! We don’t want to declare the printf function. It’s already done for us inside the file ‘stdio.h’. The #include includes the text of the file as part of our file to be compiled.Specifically, the #include directive takes the file stdio.h (which stands for standard input and output) located somewhere in your operating system, copies the text, and substitutes it where the #include was.How are C strings represented?They are represented as characters in memory.  The end of the string includes a NULL (0) byte. So “ABC” requires four(4) bytes ['A','B','C','\\0']. The only way to find out the length of a C string is to keep reading memory until you find the NULL byte. C characters are always exactly one byte each.When you write a string literal \"ABC\" in an expression the string literal evaluates to a char pointer (char *), which points to the first byte/char of the string.  This means ptr in the example below will hold the memory address of the first character in the string.char *ptr = \"ABC\"Some common ways to initialize a string include:char *str = \"ABC\";char str[] = \"ABC\";char str[]={'A','B','C','\\0'};How do you declare a pointer?A pointer refers to a memory address. The type of the pointer is useful - it tells the compiler how many bytes need to be read/written. You can declare a pointer as follows.int *ptr1;char *ptr2;Due to C’s grammar, an int* or any pointer is not actually its own type. You have to precede each pointer variable with an asterisk. As a common gotcha, the followingint* ptr3, ptr4;Will only declare *ptr3 as a pointer. ptr4 will actually be a regular int variable. To fix this declaration, keep the * preceding to the pointerint *ptr3, *ptr4;How do you use a pointer to read/write some memory?Let’s say that we declare a pointer int *ptr. For the sake of discussion, let’s say that ptr points to memory address 0x1000. If we want to write to a pointer, we can dereference and assign *ptr.*ptr = 0; // Writes some memory.What C will do is take the type of the pointer which is an int and writes sizeof(int) bytes from the start of the pointer, meaning that bytes 0x1000, 0x1001, 0x1002, 0x1003 will all be zero. The number of bytes written depends on the pointer type. It is the same for all primitive types but structs are a little different.What is pointer arithmetic?You can add an integer to a pointer. However, the pointer type is used to determine how much to increment the pointer. For char pointers this is trivial because characters are always one byte:char *ptr = \"Hello\"; // ptr holds the memory location of 'H'ptr += 2; //ptr now points to the first'l'If an int is 4 bytes then ptr+1 points to 4 bytes after whatever ptr is pointing at.char *ptr = \"ABCDEFGH\";int *bna = (int *) ptr;bna +=1; // Would cause iterate by one integer space (i.e 4 bytes on some systems)ptr = (char *) bna;printf(\"%s\", ptr);/* Notice how only 'EFGH' is printed. Why is that? Well as mentioned above, when performing 'bna+=1' we are increasing the **integer** pointer by 1, (translates to 4 bytes on most systems) which is equivalent to 4 characters (each character is only 1 byte)*/return 0;Because pointer arithmetic in C is always automatically scaled by the size of the type that is pointed to, you can’t perform pointer arithmetic on void pointers.You can think of pointer arithmetic in C as essentially doing the followingIf I want to doint *ptr1 = ...;int *offset = ptr1 + 4;Thinkint *ptr1 = ...;char *temp_ptr1 = (char*) ptr1;int *offset = (int*)(temp_ptr1 + sizeof(int)*4);To get the value. Every time you do pointer arithmetic, take a deep breath and make sure that you are shifting over the number of bytes you think you are shifting over.What is a void pointer?A pointer without a type (very similar to a void variable). Void pointers are used when either a datatype you’re dealing with is unknown or when you’re interfacing C code with other programming languages. You can think of this as a raw pointer, or just a memory address. You cannot directly read or write to it because the void type does not have a size. For Examplevoid *give_me_space = malloc(10);char *string = give_me_space;This does not require a cast because C automatically promotes void* to its appropriate type.Note:gcc and clang are not total ISO-C compliant, meaning that they will let you do arithmetic on a void pointer. They will treat it as a char pointer but do not do this because it may not work with all compilers!Does printf call write or does write call printf?printf calls write. printf includes an internal buffer so, to increase performance printf may not call write everytime you call printf. printf is a C library function. write is a system call and as we know system calls are expensive. On the other hand, printf uses a buffer which suits our needs better at that pointHow do you print out pointer values? integers? strings?Use format specifiers “%p” for pointers, “%d” for integers and “%s” for Strings.A full list of all of the format specifiers is found hereExample of integer:int num1 = 10;printf(\"%d\", num1); //prints num1Example of integer pointer:int *ptr = (int *) malloc(sizeof(int));*ptr = 10;printf(\"%p\\n\", ptr); //prints the address pointed to by the pointerprintf(\"%p\\n\", &amp;ptr); /*prints the address of pointer -- extremely usefulwhen dealing with double pointers*/printf(\"%d\", *ptr); //prints the integer content of ptrreturn 0;Example of string:char *str = (char *) malloc(256 * sizeof(char));strcpy(str, \"Hello there!\");printf(\"%p\\n\", str); // print the address in the heapprintf(\"%s\", str);return 0;Strings as Pointers &amp; Arrays @ BUHow would you make standard out be saved to a file?Simplest way: run your program and use shell redirectione.g../program &gt; output.txt#To read the contents of the file,cat output.txtMore complicated way: close(1) and then use open to re-open the file descriptor.See [[http://cs-education.github.io/sys/#chapter/0/section/3/activity/0]]What’s the difference between a pointer and an array? Give an example of something you can do with one but not the other.char ary[] = \"Hello\";char *ptr = \"Hello\";ExampleThe array name points to the first byte of the array. Both ary and ptr can be printed out:char ary[] = \"Hello\";char *ptr = \"Hello\";// Print out address and contentsprintf(\"%p : %s\\n\", ary, ary);printf(\"%p : %s\\n\", ptr, ptr);The array is mutable, so we can change its contents (be careful not to write bytes beyond the end of the array though). Fortunately, ‘World’ is no longer than ‘Hello”In this case, the char pointer ptr points to some read-only memory (where the statically allocated string literal is stored), so we cannot change those contents.strcpy(ary, \"World\"); // OKstrcpy(ptr, \"World\"); // NOT OK - Segmentation fault (crashes)We can, however, unlike the array, we change ptr to point to another piece of memory,ptr = \"World\"; // OK!ptr = ary; // OK!ary = (..anything..) ; // WONT COMPILE// ary is doomed to always refer to the original array.printf(\"%p : %s\\n\", ptr, ptr);strcpy(ptr, \"World\"); // OK because now ptr is pointing to mutable memory (the array)What to take away from this is that pointers * can point to any type of memory while C arrays [] can only point to memory on the stack. In a more common case, pointers will point to heap memory in which case the memory referred to by the pointer CAN be modified.sizeof() returns the number of bytes. So using above code, what is sizeof(ary) and sizeof(ptr)?sizeof(ary): ary is an array. Returns the number of bytes required for the entire array (5 chars + zero byte = 6 bytes)sizeof(ptr): Same as sizeof(char *). Returns the number bytes required for a pointer (e.g. 4 or 8 for a 32 bit or 64-bit machine)sizeof is a special operator. Really it’s something the compiler substitutes in before compiling the program because the size of all types is known at compile time. When you have sizeof(char*) that takes the size of a pointer on your machine (8 bytes for a 64-bit machine and 4 for a 32 bit and so on). When you try sizeof(char[]), the compiler looks at that and substitutes the number of bytes that the entire array contains because the total size of the array is known at compile time.char str1[] = \"will be 11\";char* str2 = \"will be 8\";sizeof(str1) //11 because it is an arraysizeof(str2) //8 because it is a pointerBe careful, using sizeof for the length of a string!Which of the following code is incorrect or correct and why?int* f1(int *p) {    *p = 42;    return p;} // This code is correct;char* f2() {    char p[] = \"Hello\";    return p;} // Incorrect!Explanation: An array p is created on the stack for the correct size to hold H,e,l,l,o, and a null byte i.e. (6) bytes. This array is stored on the stack and is invalid after we return from f2.char* f3() {    char *p = \"Hello\";    return p;} // OKExplanation: p is a pointer. It holds the address of the string constant. The string constant is unchanged and valid even after f3 returns.char* f4() {    static char p[] = \"Hello\";    return p;} // OKExplanation: The array is static meaning it exists for the lifetime of the process (static variables are not on the heap or the stack).How do you look up information C library calls and system calls?Use the man pages. Note the man pages are organized into sections. Section 2 = System calls. Section 3 = C libraries.Web: Google “man7 open”shell: man -S2 open  or man -S3 printfHow do you allocate memory on the heap?Use malloc. There’s also realloc and calloc.Typically used with sizeof. e.g. enough space to hold 10 integersint *space = malloc(sizeof(int) * 10);What’s wrong with this string copy code?void mystrcpy(char*dest, char* src) {   // void means no return value     while( *src ) { dest = src; src ++; dest++; }  }In the above code it simply changes the dest pointer to point to source string. Also the nuls bytes are not copied. Here’s a better version -  while( *src ) { *dest = *src; src ++; dest++; }   *dest = *src;Note it’s also usual to see the following kind of implementation, which does everything inside the expression test, including copying the nul byte.  while( (*dest++ = *src++ )) {};How do you write a strdup replacement?// Use strlen+1 to find the zero byte... char* mystrdup(char*source) {   char *p = (char *) malloc ( strlen(source)+1 );   strcpy(p,source);   return p;}How do you unallocate memory on the heap?Use free!int *n = (int *) malloc(sizeof(int));*n = 10;//Do some workfree(n);What is double free error? How can you avoid? What is a dangling pointer? How do you avoid?A double free error is when you accidentally attempt to free the same allocation twice.int *p = malloc(sizeof(int));free(p);*p = 123; // Oops! - Dangling pointer! Writing to memory we don't own anymorefree(p); // Oops! - Double free!The fix is first to write correct programs! Secondly, it’s good programming hygiene to reset pointersonce the memory has been freed. This ensures the pointer can’t be used incorrectly without the program crashing.Fix:p = NULL; // Now you can't use this pointer by mistakeWhat is an example of buffer overflow?Famous example: Heart Bleed (performed a memcpy into a buffer that was of insufficient size).Simple example: implement a strcpy and forget to add one to strlen, when determining the size of the memory required.What is ‘typedef’ and how do you use it?Declares an alias for a type. Often used with structs to reduce the visual clutter of having to write ‘struct’ as part of the type.typedef float real; real gravity = 10;// Also typedef gives us an abstraction over the underlying type used. // In the future, we only need to change this typedef if we// wanted our physics library to use doubles instead of floats.typedef struct link link_t; //With structs, include the keyword 'struct' as part of the original typesIn this class, we regularly typedef functions. A typedef for a function can be this for exampletypedef int (*comparator)(void*,void*);int greater_than(void* a, void* b){    return a &gt; b;}comparator gt = greater_than;This declares a function type comparator that accepts two void* params and returns an integer.Wow that was a lot of CDon’t worry more to come!Next: C Programming, Part 2: Text Input And Output"
  },{
    "title": "C Programming, Part 2: Text Input And Output",
    "url": " /wikibook/c-programming-part-2-text-input-and-output",
   "content": "Printing to StreamsHow do I print strings, ints, chars to the standard output stream?Use printf. The first parameter is a format string that includes placeholders for the data to be printed. Common format specifiers are %s treat the argument as a c string pointer, keep printing all characters until the NULL-character is reached; %d print the argument as an integer; %p print the argument as a memory address.A simple example is shown below:char *name = ... ; int score = ...;printf(\"Hello %s, your result is %d\\n\", name, score);printf(\"Debug: The string and int are stored at: %p and %p\\n\", name, &amp;score );// name already is a char pointer and points to the start of the array. // We need \"&amp;\" to get the address of the int variableBy default, for performance, printf does not actually write anything out (by calling write) until its buffer is full or a newline is printed.How else can I print strings and single characters?Use puts( name ) and putchar( c )  where name is a pointer to a C string and c is just a charHow do I print to other file streams?Use fprintf( _file_ , \"Hello %s, score: %d\", name, score);Where _file_ is either predefined ‘stdout’ ‘stderr’ or a FILE pointer that was returned by fopen or fdopenCan I use file descriptors?Yes! Just use dprintf(int fd, char* format_string, ...); Just remember the stream may be buffered, so you will need to assure that the data is written to the file descriptor.How do I print data into a C string?Use sprintf or better snprintf.char result[200];int len = snprintf(result, sizeof(result), \"%s:%d\", name, score);snprintf returns the number of characters written excluding the terminating byte. In the above example, this would be a maximum of 199.The return value of snprintf is the length that would have been written given enough space, excluding the ending NULL byte.char x[5];int size = snprintf(x, 5, \"%s%s%s\", \"12\", \"34\", \"56\"); // writes \"1234\" + nullprintf(\"%d\\n\", size); // output 6Source: this StackOverflow post and man page.What if I really really want printf to call write without a newline?Use fflush( FILE* inp ). The contents of the file will be written. If I wanted to write “Hello World” with no newline, I could write it like this.int main(){    fprintf(stdout, \"Hello World\");    fflush(stdout);    return 0;}How is perror helpful?Let’s say that you have a function call that just failed (because you checked the man page and it is a failing return code). perror(const char* message) will print the English version of the error to stderrint main(){    int ret = open(\"IDoNotExist.txt\", O_RDONLY);    if(ret &lt; 0){        perror(\"Opening IDoNotExist:\");    }    //...    return 0;}Parsing InputHow do I parse numbers from strings?Use long int strtol(const char *nptr, char **endptr, int base); or long long int strtoll(const char *nptr, char **endptr, int base);.What these functions do is take the pointer to your string *nptr and a base (ie binary, octal, decimal, hexadecimal etc) and an optional pointer endptr and returns a parsed value.int main(){    const char *nptr = \"1A2436\";    char* endptr;    long int result = strtol(nptr, &amp;endptr, 16);    return 0;}Be careful though! Error handling is tricky because the function won’t return an error code. If you give it a string that is not a number it will return 0. This means you cant differentiate between a valid “0” and an invalid string. See the man page for more details on strol behavior with invalid and out of bounds values. A safer alternative is use to sscanf (and check the return value).int main(){    const char *input = \"0\"; // or \"!##@\" or \"\"    char* endptr;    long int parsed = strtol(input, &amp;endptr, 10);    if(parsed == 0){        // Either the input string was not a valid base-10 number or it really was zero!    }    return 0;}How do I parse input using scanf into parameters?Use scanf (or fscanf or sscanf) to get input from the default input stream, an arbitrary file stream or a C string respectively.It’s a good idea to check the return value to see how many items were parsed.scanf functions require valid pointers. It’s a common source of error to pass in an incorrect pointer value. For example,int *data = (int *) malloc(sizeof(int));char *line = \"v 10\";char type;// Good practice: Check scanf parsed the line and read two values:int ok = 2 == sscanf(line, \"%c %d\", &amp;type, &amp;data); // pointer errorWe wanted to write the character value into c and the integer value into the malloc’d memory.However, we passed the address of the data pointer, not what the pointer is pointing to! So sscanf will change the pointer itself. i.e. the pointer will now point to address 10 so this code will later fail e.g. when free(data) is called.How do I stop scanf from causing a buffer overflow?The following code assumes the scanf won’t read more than 10 characters (including the terminating byte) into the buffer.char buffer[10];scanf(\"%s\",buffer);You can include an optional integer to specify how many characters EXCLUDING the terminating byte:char buffer[10];scanf(\"%9s\", buffer); // reads up to 9 charactes from input (leave room for the 10th byte to be the terminating byte)Why is gets dangerous? What should I use instead?The following code is vulnerable to buffer overflow. It assumes or trusts that the input line will be no more than 10 characters, including the terminating byte.char buf[10];gets(buf); // Remember the array name means the first byte of the arraygets is deprecated in C99 standard and has been removed from the latest C standard (C11). Programs should use fgets or getline instead.Where each has the following structure respectively:char *fgets (char *str, int num, FILE *stream); ssize_t getline(char **lineptr, size_t *n, FILE *stream);Here’s a simple, safe way to read a single line. Lines longer than 9 characters will be truncated:char buffer[10];char *result = fgets(buffer, sizeof(buffer), stdin);The result is NULL if there was an error or the end of the file is reached.Note, unlike gets,  fgets copies the newline into the buffer, which you may want to discard-if (!result) { return; /* no data - don't read the buffer contents */}int i = strlen(buffer) - 1;if (buffer[i] == '\\n')     buffer[i] = '\\0';How do I use getline?One of the advantages of getline is that will automatically (re-) allocate a buffer on the heap of sufficient size.// ssize_t getline(char **lineptr, size_t *n, FILE *stream); /* set buffer and size to 0; they will be changed by getline */char *buffer = NULL;size_t size = 0;ssize_t chars = getline(&amp;buffer, &amp;size, stdin);// Discard newline character if it is present,if (chars &gt; 0 &amp;&amp; buffer[chars-1] == '\\n')     buffer[chars-1] = '\\0';// Read another line.// The existing buffer will be re-used, or, if necessary,// It will be `free`'d and a new larger buffer will `malloc`'dchars = getline(&amp;buffer, &amp;size, stdin);// Later... don't forget to free the buffer!free(buffer);Back: C Programming, Part 1: Introduction |Next: C Programming, Part 3: Common Gotchas"
  },{
    "title": "C Programming, Part 3: Common Gotchas",
    "url": " /wikibook/c-programming-part-3-common-gotchas",
   "content": "What common mistakes do C programmers make?Memory mistakesString constants are constantchar array[] = \"Hi!\"; // array contains a mutable copy strcpy(array, \"OK\");char *ptr = \"Can't change me\"; // ptr points to some immutable memorystrcpy(ptr, \"Will not work\");String literals are character arrays stored in the code segment of the program, which is immutable. Two string literals may share the same space in memory. An example follows:char *str1 = \"Brandon Chong is the best TA\";char *str2 = \"Brandon Chong is the best TA\";The strings pointed to by str1 and str2 may actually reside in the same location in memory.Char arrays, however, contain the literal value which has been copied from the code segment into either the stack or static memory. These following char arrays do not reside in the same place in memory.char arr1[] = \"Brandon Chong didn't write this\";char arr2[] = \"Brandon Chong didn't write this\";Buffer overflow/ underflow#define N (10)int i = N, array[N];for (; i &gt;= 0; i--) array[i] = i;C does not check that pointers are valid. The above example writes into array[10] which is outside the array bounds. This can cause memory corruption because that memory location is probably being used for something else.In practice, this can be harder to spot because the overflow/underflow may occur in a library call e.g.gets(array); // Let's hope the input is shorter than my array!Returning pointers to automatic variablesint *f() {    int result = 42;    static int imok;    return &amp;imok; // OK - static variables are not on the stack    return &amp;result; // Not OK}Automatic variables are bound to stack memory only for the lifetime of the function.After the function returns it is an error to continue to use the memory.Insufficient memory allocationstruct User {   char name[100];};typedef struct User user_t;user_t *user = (user_t *) malloc(sizeof (user_t *));In the above example, we needed to allocate enough bytes for the struct. Instead, we allocated enough bytes to hold a pointer. Once we start using the user pointer we will corrupt memory. The correct code is shown below.struct User {   char name[100];};typedef struct User user_t;user_t *user = (user_t *) malloc(sizeof (user_t));Strings require strlen(s)+1 bytesEvery string must have a null byte after the last characters. To store the string \"Hi\" it takes 3 bytes: [H] [i] [\\0].char *strdup(const char *input) {     /* return a copy of 'input' */    char *copy;    copy = malloc(sizeof (char *));     /* nope! this allocates space for a pointer, not a string */    copy = malloc(strlen(input));     /* Almost...but what about the null terminator? */    copy = malloc(strlen(input) + 1); /* That's right. */    strcpy(copy, input);   /* strcpy will provide the null terminator */    return copy;}Using uninitialized variablesint myfunction() {    int x;    int y = x + 2;    ...Automatic variables hold garbage (whatever bit pattern happened to be in memory). It is an error to assume that it will always be initialized to zero.Assuming Uninitialized memory will be zeroedvoid myfunct() {    char array[10];    char *p = malloc(10);Automatic (temporary variables) are not automatically initialized to zero.Heap allocations using malloc are not automatically initialized to zero.Double-freechar *p = malloc(10);free(p);//  .. later ...free(p); It is an error to free the same block of memory twice.Dangling pointerschar *p = malloc(10);strcpy(p, \"Hello\");free(p);//  .. later ...strcpy(p,\"World\"); Pointers to freed memory should not be used. A defensive programming practice is to set pointers to null as soon as the memory is freed.It is a good idea to turn free into the following snippet that automatically sets the freed variable to null right after:(vim - ultisnips)snippet free \"free(something)\" bfree(${1});$1 = NULL;${2}endsnippetLogic and Program flow mistakesForgetting breakint flag = 1; // Will print all three lines.switch (flag) {case 1: printf(\"I'm printed\\n\");case 2: printf(\"Me too\\n\");case 3: printf(\"Me three\\n\");}Case statements without a break will just continue onto the code of the next case statement. The correct code is shown below. The break for the last statements is unnecessary because there are no more cases to be executed after the last one. If more are added, it can cause some bugs.int flag = 1; // Will print only \"I'm printed\\n\"switch (flag) {case 1:     printf(\"I'm printed\\n\");    break;case 2:     printf(\"Me too\\n\");    break;case 3:     printf(\"Me three\\n\");    break; //unnecessary}Equal vs. equalityint answer = 3; // Will print out the answer.if (answer = 42) { printf(\"I've solved the answer! It's %d\", answer); }Undeclared or incorrectly prototyped functionstime_t start = time();The system function ‘time’ actually takes a parameter (a pointer to some memory that can receive the time_t structure). The compiler did not catch this error because the programmer did not provide a valid function prototype by including time.hExtra Semicolonsfor (int i = 0; i &lt; 5; i++) ; printf(\"I'm printed once\");while (x &lt; 10); x++ ; // X is never incrementedHowever, the following code is perfectly OK.for (int i = 0; i &lt; 5; i++) {    printf(\"%d\\n\", i);;;;;;;;;;;;;}It is OK to have this kind of code, because the C language uses semicolons (;) to separate statements. If there is no statement in between semicolons, then there is nothing to do and the compiler moves on to the next statementOther GotchasPreprocessorWhat is the preprocessor? It is an operation that the compiler performs before actually compiling the program. It is a copy and paste command. Meaning that if I do the following.#define MAX_LENGTH 10char buffer[MAX_LENGTH]After preprocessing, it’ll look like this.char buffer[10]C Preprocessor macros and side-effects#define min(a,b) ((a)&lt;(b) ? (a) : (b))int x = 4;if (min(x++, 100)) printf(\"%d is six\", x);Macros are simple text substitution so the above example expands to x++ &lt; 100 ? x++ : 100 (parenthesis omitted for clarity)C Preprocessor macros and precedence#define min(a,b) a&lt;b ? a : bint x = 99;int r = 10 + min(99, 100); // r is 100!Macros are simple text substitution so the above example expands to 10 + 99 &lt; 100 ? 99 : 100C Preprocessor logical gotcha#define ARRAY_LENGTH(A) (sizeof((A)) / sizeof((A)[0]))int static_array[10]; // ARRAY_LENGTH(static_array) = 10int *dynamic_array = malloc(10); // ARRAY_LENGTH(dynamic_array) = 2 or 1What is wrong with the macro? Well, it works if we have a static array like the first array because sizeof a static array returns the bytes that array takes up, and dividing it by the sizeof(an_element) would give you the number of entries. But if we use a pointer to a piece of memory, taking the sizeof the pointer and dividing it by the size of the first entry won’t always give us the size of the array.Does sizeof do anything?int a = 0;size_t size = sizeof(a++);printf(\"size: %lu, a: %d\", size, a);What does the code print out?size: 4, a: 0Because sizeof is not actually evaluated at runtime. The compiler assigns the type of all expressions and discards the extra results of the expression.Back: C Programming, Part 2: Text Input And Output |Next: C Programming, Part 4: Strings and Structs"
  },{
    "title": "C Programming, Part 4: Strings and Structs",
    "url": " /wikibook/c-programming-part-4-strings-and-structs",
   "content": "Strings, Structs, and Gotcha’sSo what’s a string?In C we have Null Terminated strings rather than Length Prefixed for historical reasons. What that means for your average everyday programming is that you need to remember the null character! A string in C is defined as a bunch of bytes until you reach ‘\\0’ or the Null Byte.Two places for stringsWhenever you define a constant string (ie one in the form char* str = \"constant\") That string is stored in the data or code segment that is read-only meaning that any attempt to modify the string will cause a segfault.If one, however, malloc’s space, one can change that string to be whatever they want.Memory MismanagementOne common gotcha is when you write the followingchar* hello_string = malloc(14);                       ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___// hello_string ----&gt; | g | a | r | b | a | g | e | g | a | r | b | a | g | e |                       ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾hello_string = \"Hello Bhuvan!\";// (constant string in the text segment)// hello_string ----&gt; [ \"H\" , \"e\" , \"l\" , \"l\" , \"o\" , \" \" , \"B\" , \"h\" , \"u\" , \"v\" , \"a\" , \"n\" , \"!\" , \"\\0\" ]                       ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___// memory_leak -----&gt; | g | a | r | b | a | g | e | g | a | r | b | a | g | e |                       ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾hello_string[9] = 't'; //segfault!!What did we do? We allocated space for 14 bytes, reassigned the pointer and successfully segfaulted! Remember to keep track of what your pointers are doing. What you probably wanted to do was use a string.h function strcpy.strcpy(hello_string, \"Hello Bhuvan!\");Remember the NULL byte!Forgetting to NULL terminate a string is a big affect on the strings! Bounds checking is important. The heart bleed bug mentioned earlier in the wiki book is partially because of this.Where can I find an In-Depth and Assignment-Comprehensive explanation of all of these functions?Right Here!String Information/Comparison: strlen strcmpint strlen(const char *s) returns the length of the string not including the null byteint strcmp(const char *s1, const char *s2) returns an integer determining the lexicographic order of the strings. If s1 where to come before s2 in a dictionary, then a -1 is returned. If the two strings are equal, then 0. Else, 1.With most of these functions, they expect the strings to be readable and not NULL but there is undefined behavior when you pass them NULL.String Alteration: strcpy strcat strdupchar *strcpy(char *dest, const char *src) Copies the string at src to dest. assumes dest has enough space for srcchar *strcat(char *dest, const char *src) Concatenates the string at src to the end of destination. This function assumes that there is enough space for src at the end of destination including the NULL bytechar *strdup(const char *dest) Returns a malloc‘ed copy of the string.String Search: strchr strstrchar *strchr(const char *haystack, int needle) Returns a pointer to the first occurrence of needle in the haystack. If none found, NULL is returned.char *strstr(const char *haystack, const char *needle) Same as above but this time a string!String Tokenize: strtokA dangerous but useful function strtok takes a string and tokenizes it. Meaning that it will transform the strings into separate strings. This function has a lot of specs so please read the man pages a contrived example is below.#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main(){    char* upped = strdup(\"strtok,is,tricky,!!\");    char* start = strtok(upped, \",\");    do{        printf(\"%s\\n\", start);    }while((start = strtok(NULL, \",\")));    return 0;}Outputstrtokistricky!!What happens when I change upped like this?char* upped = strdup(\"strtok,is,tricky,,,!!\");Memory Movement: memcpy and memmoveWhy are memcpy and memmove both in &lt;string.h&gt;? Because strings are essentially raw memory with a null byte at the end of them!void *memcpy(void *dest, const void *src, size_t n) moves n bytes starting at src to dest. Be careful, there is undefined behavior when the memory regions overlap. This is one of the classic works on my machine examples because many times valgrind won’t be able to pick it up because it will look like it works on your machine. When the autograder hits, fail. Consider the safer version which is.void *memmove(void *dest, const void *src, size_t n) does the same thing as above, but if the memory regions overlap then it is guaranteed that all the bytes will get copied over correctly.So what’s a struct?In low-level terms, a struct is just a piece of contiguous memory, nothing more. Just like an array, a struct has enough space to keep all of its members. But unlike an array, it can store different types. Consider the contact struct declared abovestruct contact {    char firstname[20];    char lastname[20];    unsigned int phone;};struct contact bhuvan;Brief aside/* a lot of times we will do the following typdef so we can just write contact contact1 */typedef struct contact contact;contact bhuvan;/* You can also declare the struct like this to get it done in one statement */typedef struct optional_name {    ...} contact;If you compile the code without any optimizations and reordering, you can expect the addresses of each of the variables to look like this.&amp;bhuvan           // 0x100&amp;bhuvan.firstname // 0x100 = 0x100+0x00&amp;bhuvan.lastname  // 0x114 = 0x100+0x14&amp;bhuvan.phone     // 0x128 = 0x100+0x28Because all your compiler does is say ‘hey reserve this much space, and I will go and calculate the offsets of whatever variables you want to write to’.What do these offsets mean?The offsets are where the variable starts at. The phone variables starts at the 0x128th bytes and continues for sizeof(int) bytes, but not always. Offsets don’t determine where the variable ends though. Consider the following hack that you see in a lot of kernel code.typedef struct {    int length;    char c_str[0];} string;const char* to_convert = \"bhuvan\";int length = strlen(to_convert);// Let's convert to a c stringstring* bhuvan_name;bhuvan_name = malloc(sizeof(string) + length+1);/*Currently, our memory looks like this with junk in those black spaces                ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ bhuvan_name = |   |   |   |   |   |   |   |   |   |   |   |                ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾*/bhuvan_name-&gt;length = length;/*This writes the following values to the first four bytesThe rest is still garbage                ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ bhuvan_name = | 0 | 0 | 0 | 6 |   |   |   |   |   |   |   |                ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾*/strcpy(bhuvan_name-&gt;c_str, to_convert);/*Now our string is filled in correctly at the end of the struct                ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ____ bhuvan_name = | 0 | 0 | 0 | 6 | b | h | u | v | a | n | \\0 |                ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾‾*/strcmp(bhuvan_name-&gt;c_str, \"bhuvan\") == 0 //The strings are equal!But not all structs are perfectStructs may require something called padding (tutorial). **We do not expect you to pack structs in this course, just know that it is there This is because in the early days (and even now) when you have to an address from memory you have to do it in 32bit or 64bit blocks. This also meant that you could only request addresses that were multiples of that. Meaning thatstruct picture{    int height;    pixel** data;    int width;    char* enconding;}// You think picture looks like this           height      data         width     encoding           ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___picture = |       |               |       |               |           ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾Would conceptually look like thisstruct picture{    int height;    char slop1[4];    pixel** data;    int width;    char slop2[4];    char* enconding;}           height   slop1       data        width   slop2  encoding           ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___picture = |       |       |               |       |       |               |           ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾This is on a 64-bit system. This is not always the case because sometimes your processor supports unaligned accesses. What does this mean? Well there are two options you can set an attributestruct __attribute__((packed, aligned(4))) picture{    int height;    pixel** data;    int width;    char* enconding;}// Will look like this           height       data        width     encoding           ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___picture = |       |               |       |               |           ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾But now, every time I want to access data or encoding, I have to do two memory accesses. The other thing you can do is reorder the struct, although this is not always possiblestruct picture{    int height;    int width;    pixel** data;    char* enconding;}// You think picture looks like this           height   width        data         encoding           ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___picture = |       |       |               |               |           ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾ ‾‾‾Back: C Programming, Part 3: Common Gotchas |Next: C Programming, Part 5: Debugging"
  },{
    "title": "C Programming, Part 5: Debugging",
    "url": " /wikibook/c-programming-part-5-debugging",
   "content": "The Hitchhiker’s Guide to Debugging C ProgramsThis is going to be a massive guide to helping you debug your C programs. There are different levels that you can check errors and we will be going through most of them. Feel free to add anything that you found helpful in debugging C programs including but not limited to, debugger usage, recognizing common error types, gotchas, and effective googling tips.In-Code DebuggingClean codeMake your code modular using helper functions. If there is a repeated task (getting the pointers to contiguous blocks in the malloc MP, for example), make them helper functions. And make sure each function does one thing very well, so that you don’t have to debug twice.Let’s say that we are doing selection sort by finding the minimum element each iteration like so,void selection_sort(int *a, long len){     for(long i = len-1; i &gt; 0; --i){         long max_index = i;         for(long j = len-1; j &gt;= 0; --j){             if(a[max_index] &lt; a[j]){                  max_index = j;             }         }         int temp = a[i];         a[i] = a[max_index];         a[max_index] = temp;     }}Many can see the bug in the code, but it can help to refactor the above method intolong max_index(int *a, long start, long end);void swap(int *a, long idx1, long idx2);void selection_sort(int *a, long len);And the error is specifically in one function.In the end, we are not a class about refactoring/debugging your code. In fact, most systems code is so atrocious that you don’t want to read it. But for the sake of debugging, it may benefit you in the long run to adopt some practices.Asserts!Use assertions to make sure your code works up to a certain point – and importantly, to make sure you don’t break it later. For example, if your data structure is a doubly linked list, you can do something like assert(node-&gt;size == node-&gt;next-&gt;prev-&gt;size) to assert that the next node has a pointer to the current node. You can also check the pointer is pointing to an expected range of memory address, not null, -&gt;size is reasonable etc.The NDEBUG macro will disable all assertions, so don’t forget to set that once you finish debugging. http://www.cplusplus.com/reference/cassert/assert/Here’s a quick example with assert. Let’s say that I’m writing code using memcpyassert(!(src &lt; dest+n &amp;&amp; dest &lt; src+n)); //Checks overlapmemcpy(dest, src, n);This check can be turned off at compile time, but will save you tons of trouble debugging!printfsWhen all else fails, print like crazy! Each of your functions should have an idea of what it is going to do (ie find_min better find the minimum element). You want to test that each of your functions is doing what it set out to do and see exactly where your code breaks. In the case with race conditions, tsan may be able to help, but having each thread print out data at certain times could help you identify the race condition.ValgrindValgrind is a suite of tools designed to provide debugging and profiling tools to make your programs more correct and detect some runtime issues. The most used of these tools is Memcheck, which can detect many memory-related errors that are common in C and C++ programs and that can lead to crashes and unpredictable behaviour (for example, unfreed memory buffers).To run Valgrind on your program:valgrind --leak-check=yes myprogram arg1 arg2orvalgrind ./myprogramArguments are optional and the default tool that will run is Memcheck. The output will be presented in form of number of allocations, number of freed allocations, and the number of errors.ExampleHere’s an example to help you interpret the above results. Suppose we have a simple program like this:  #include &lt;stdlib.h&gt;  void dummy_function()  {     int* x = malloc(10 * sizeof(int));     x[10] = 0;        // error 1:as you can see here we write to an out of bound memory address  }                    // error 2: memory leak the allocated x not freed  int main(void)  {     dummy_function();     return 0;  }Let’s see what Valgrind will output (this program compiles and run with no errors).==29515== Memcheck, a memory error detector==29515== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.==29515== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info==29515== Command: ./a==29515== ==29515== Invalid write of size 4==29515==    at 0x400544: dummy_function (in /home/rafi/projects/exocpp/a)==29515==    by 0x40055A: main (in /home/rafi/projects/exocpp/a)==29515==  Address 0x5203068 is 0 bytes after a block of size 40 alloc'd==29515==    at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)==29515==    by 0x400537: dummy_function (in /home/rafi/projects/exocpp/a)==29515==    by 0x40055A: main (in /home/rafi/projects/exocpp/a)==29515== ==29515== ==29515== HEAP SUMMARY:==29515==     in use at exit: 40 bytes in 1 blocks==29515==   total heap usage: 1 allocs, 0 frees, 40 bytes allocated==29515== ==29515== LEAK SUMMARY:==29515==    definitely lost: 40 bytes in 1 blocks==29515==    indirectly lost: 0 bytes in 0 blocks==29515==      possibly lost: 0 bytes in 0 blocks==29515==    still reachable: 0 bytes in 0 blocks==29515==         suppressed: 0 bytes in 0 blocks==29515== Rerun with --leak-check=full to see details of leaked memory==29515== ==29515== For counts of detected and suppressed errors, rerun with: -v==29515== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)Invalid write: It detected our heap block overrun (writing outside of allocated block)Definitely lost: Memory leak—you probably forgot to free a memory blockValgrind is a very effective tool to check for errors at runtime. C is very special when it comes to such behavior, so after compiling your program you can use Valgrind to fix errors that your compiler may not catch and that usually happen when your program is running.For more information, you can refer to the official website.TsanThreadSanitizer is a tool from Google, built into clang (and gcc), to help you detect race conditions in your code. For more information about the tool, see the Github wiki.Note that running with tsan will slow your code down a bit.#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;int Global;void *Thread1(void *x) {    Global++;    return NULL;}int main() {    pthread_t t[2];    pthread_create(&amp;t[0], NULL, Thread1, NULL);    Global = 100;    pthread_join(t[0], NULL);}// compile with gcc -fsanitize=thread -pie -fPIC -ltsan -g simple_race.cWe can see that there is a race condition on the variable Global. Both the main thread and the thread created with pthread_create will try to change the value at the same time. But, does ThreadSantizer catch it?$ ./a.out==================WARNING: ThreadSanitizer: data race (pid=28888)  Read of size 4 at 0x7f73ed91c078 by thread T1:    #0 Thread1 /home/zmick2/simple_race.c:7 (exe+0x000000000a50)    #1  :0 (libtsan.so.0+0x00000001b459)  Previous write of size 4 at 0x7f73ed91c078 by main thread:    #0 main /home/zmick2/simple_race.c:14 (exe+0x000000000ac8)  Thread T1 (tid=28889, running) created by main thread at:    #0  :0 (libtsan.so.0+0x00000001f6ab)    #1 main /home/zmick2/simple_race.c:13 (exe+0x000000000ab8)SUMMARY: ThreadSanitizer: data race /home/zmick2/simple_race.c:7 Thread1==================ThreadSanitizer: reported 1 warningsIf we compiled with the debug flag, then it would give us the variable name as well.GDBIntroduction: http://www.cs.cmu.edu/~gilpin/tutorial/Setting breakpoints programmaticallyA very useful trick when debugging complex C programs with GDB is setting breakpoints in the source code.int main() {    int val = 1;    val = 42;    asm(\"int $3\"); // set a breakpoint here    val = 7;}$ gcc main.c -g -o main &amp;&amp; ./main(gdb) r[...]Program received signal SIGTRAP, Trace/breakpoint trap.main () at main.c:66\t    val = 7;(gdb) p val$1 = 42Checking memory contenthttp://www.delorie.com/gnu/docs/gdb/gdb_56.htmlFor example,int main() {    char bad_string[3] = {'C', 'a', 't'};    printf(\"%s\", bad_string);}$ gcc main.c -g -o main &amp;&amp; ./main$ Cat ZVQ� $(gdb) l1\t#include &lt;stdio.h&gt;2\tint main() {3\t    char bad_string[3] = {'C', 'a', 't'};4\t    printf(\"%s\", bad_string);5\t}(gdb) b 4Breakpoint 1 at 0x100000f57: file main.c, line 4.(gdb) r[...]Breakpoint 1, main () at main.c:44\t    printf(\"%s\", bad_string);(gdb) x/16xb bad_string0x7fff5fbff9cd:\t0x63\t0x61\t0x74\t0xe0\t0xf9\t0xbf\t0x5f\t0xff0x7fff5fbff9d5:\t0x7f\t0x00\t0x00\t0xfd\t0xb5\t0x23\t0x89\t0xff(gdb)Here, by using the x command with parameters 16xb, we can see that starting at memory address 0x7fff5fbff9c (value of bad_string), printf would actually see the following sequence of bytes as a string because we provided a malformed string without a null terminator.0x63 0x61 0x74 0xe0 0xf9 0xbf 0x5f 0xff 0x7f 0x00Back: C Programming, Part 4: Strings and Structs| Back: C Programming, Review Questions"
  },{
    "title": "C Programming: Review Questions",
    "url": " /wikibook/c-programming-review-questions",
   "content": "Warning - question numbers subject to changeMemory and StringsQ1.1In the example below, which variables are guaranteed to print the value of zero?int a;static int b;void func() {   static int c;   int d;   printf(\"%d %d %d %d\\n\",a,b,c,d);}Q 1.2In the example below, which variables are guaranteed to print the value of zero?void func() {   int* ptr1 = malloc( sizeof(int) );   int* ptr2 = realloc(NULL, sizeof(int) );   int* ptr3 = calloc( 1, sizeof(int) );   int* ptr4 = calloc( sizeof(int) , 1);      printf(\"%d %d %d %d\\n\",*ptr1,*ptr2,*ptr3,*ptr4);}Q 1.3Explain the error in the following attempt to copy a string.char* copy(char*src) { char*result = malloc( strlen(src) );  strcpy(result, src);  return result;}Q 1.4Why does the following attempt to copy a string sometimes work and sometimes fail?char* copy(char*src) { char*result = malloc( strlen(src) +1 );  strcat(result, src);  return result;}Q 1.4Explain the two errors in the following code that attempts to copy a string.char* copy(char*src) { char result[sizeof(src)];  strcpy(result, src);  return result;}Q 1.5Which of the following is legal?char a[] = \"Hello\"; strcpy(a, \"World\");char b[] = \"Hello\"; strcpy(b, \"World12345\", b);char* c = \"Hello\"; strcpy(c, \"World\");Q 1.6Complete the function pointer typedef to declare a pointer to a function that takes a void* argument and returns a void*. Name your type ‘pthread_callback’typedef ______________________;Q 1.7In addition to the function arguments what else is stored on a thread’s stack?Q 1.8Implement a version of char* strcat(char*dest, const char*src) using only strcpy  strlen and pointer arithmeticchar* mystrcat(char*dest, const char*src) {  ? Use strcpy strlen here  return dest;}Q 1.9Implement version of size_t strlen(const char*) using a loop and no function calls.size_t mystrlen(const char*s) {}Q 1.10Identify the three bugs in the following implementation of strcpy.char* strcpy(const char* dest, const char* src) {  while(*src) { *dest++ = *src++; }  return dest;}PrintingQ 2.1Spot the two errors!fprintf(\"You scored 100%\");Formatting and Printing to a fileQ 3.1Complete the following code to print to a file. Print the name, a comma and the score to the file ‘result.txt’char* name = .....;int score = ......FILE *f = fopen(\"result.txt\",_____);if(f) {    _____}fclose(f);Printing to a stringQ 4.1How would you print the values of variables a,mesg,val and ptr to a string? Print a as an integer, mesg as C string, val as a double val and ptr as a hexadecimal pointer. You may assume the mesg points to a short C string(&lt;50 characters).Bonus: How would you make this code more robust or able to cope with?char* toString(int a, char*mesg, double val, void* ptr) {   char* result = malloc( strlen(mesg) + 50);    _____   return result;}Input parsingQ 5.1Why should you check the return value of sscanf and scanf?Q 5.2Why is ‘gets’ dangerous?Q 5.3Write a complete program that uses getline. Ensure your program has no memory leaks.Heap memoryWhen would you use calloc not malloc? When would realloc be useful?(Todo - move this question to another page)What mistake did the programmer make in the following code? Is it possible to fix it i) using heap memory? ii) using global (static) memory?static int id;char* next_ticket() {  id ++;  char result[20];  sprintf(result,\"%d\",id);  return result;}"
  },{
    "title": "Deadlock, Part 1: Resource Allocation Graph",
    "url": " /wikibook/deadlock-part-1-resource-allocation-graph",
   "content": "What is a Resource Allocation Graph?A resource allocation graph tracks which resource is held by which process and which process is waiting for a resource of a particular type. It is very powerful and simple tool to illustrate how interacting  processes can deadlock. If a process is using a resource, an arrow is drawn from the resource node to the process node. If a process is requesting a resource, an arrow is drawn from the process node to the resource node.If there is a cycle in the Resource Allocation Graph and each resource in the cycle provides only one instance, then the processes will deadlock. For example, if process 1 holds resource A, process 2 holds resource B and process 1 is waiting for B and process 2 is waiting for A, then process 1 and 2 process will be deadlocked.Here’s another example, that shows Processes 1 and 2 acquiring resources 1 and 2 while process 3 is waiting to acquire both resources. In this example there is no deadlock because there is no circular dependency.Deadlock!A lot of times, we don’t know the specific order that a resource may be acquired so we can draw the graph directed.As a possibility matrix. Then we can draw arrows and see if there is a directed version that would lead us to a deadlock.Consider the following resource allocation graph (assume that the processes ask for exclusive access to the file). If you have a bunch of processes running and they request resources and the operating system ends up in this state, you deadlock! You may not see this because the operating system may *preempt some processes breaking the cycle but there is still a chance that your three lonely processes could deadlock. You can also make these kind of graphs with make and rule dependencies (with our parmake MP for example)."
  },{
    "title": "Deadlock, Part 2: Deadlock Conditions",
    "url": " /wikibook/deadlock-part-2-deadlock-conditions",
   "content": "Coffman conditionsThere are four necessary and sufficient conditions for deadlock. These are known as the Coffman conditions.  Mutual Exclusion  Circular Wait  Hold and Wait  No pre-emptionIf you break any of them, you cannot have deadlock!All of these conditions are required for deadlock, so let’s discuss each one in turn. First the easy ones-  Mutual Exclusion: The resource cannot be shared  Circular Wait: There exists a cycle in the Resource Allocation Graph. There exists a set of processes {P1,P2,…} such that P1 is waiting for resources held by P2, which is waiting for P3,…, which is waiting for P1.  Hold and Wait: A process acquires an incomplete set of resources and holds onto them while waiting for the other resources.  No pre-emption: Once a process has acquired a resource, the resource cannot be taken away from a process and the process will voluntarily give up a resource.Breaking the Coffman ConditionsTwo students need a pen and paper:  The students share a pen and paper. Deadlock is avoided because Mutual Exclusion was not required.  The students both agree to grab the pen before grabbing the paper. Deadlock is avoided because there cannot be a circular wait.  The students grab both the pen and paper in one operation (“Get both or get none”). Deadlock is avoided because there is no Hold and Wait  The students are friends and will ask each other to give up a held resource. Deadlock is avoided because pre-emption is allowed.LivelockLivelock is not deadlock-Consider the following ‘solution’  The students will put down one held resource if they are unable to pick up the other resource within 10 seconds. This solution avoids deadlock however it may suffer from livelock.Livelock occurs when a process continues to execute but is unable to make progress.In practice Livelock may occur because the programmer has taken steps to avoid deadlock. In the above example, in a busy system, the student will continually release the first resource because they are never able to obtain the second resource. The system is not deadlock (the student process is still executing) however it’s not making any progress either.Deadlock Prevention/Avoidance vs Deadlock DetectionDeadlock prevention is making sure that deadlock cannot happen, meaning that you break a coffman condition. This works the best inside a single program and the software engineer making the choice to break a certain coffman condition. Consider the Banker’s Algorithm. It is another algorithm for deadlock avoidance. The whole implementation is outside the scope of this class, just know that there are more generalized algorithms for operating systems.Deadlock detection on the other hand is allowing the system to enter a deadlocked state. After entering, the system uses the information that it has to break deadlock. As an example, consider multiple processes accessing files. The operating system is able to keep track of all of the files/resources through file descriptors at some level (either abstracted through an API or directly). If the operating system detects a directed cycle in the operating system file descriptor table it may break one process’ hold (through scheduling for example) and let the system proceed.Dining PhilosophersThe Dining Philosophers problem is a classic synchronization problem. Imagine I invite N (let’s say 5) philosophers to a meal. We will sit them at a table with 5 chopsticks (one between each philosopher). A philosopher alternates between wanting to eat or think. To eat the philosopher must pick up the two chopsticks either side of their position (the original problem required each philosopher to have two forks). However these chopsticks are shared with his neighbor.Is it possible to design an efficient solution such that all philosophers get to eat? Or, will some philosophers starve, never obtaining a second chopstick? Or will all of them deadlock? For example, imagine each guest picks up the chopstick on their left and then waits for the chopstick on their right to be free. Oops - our philosophers have deadlocked!"
  },{
    "title": "Deadlock, Part 3: Dining Philosophers",
    "url": " /wikibook/deadlock-part-3-dining-philosophers",
   "content": "BackstorySo you have your philosophers sitting around a table all wanting to eat some pasta (or whatever that is) and they are really hungry. Each of the philosophers are essentially the same, meaning that each philosopher has the same instruction set based on the other philosopher ie you can’t tell every even philosopher to do one thing and every odd philosopher to do another thing.Failed SolutionsLeft-Right DeadlockWhat do we do? Let’s try a simple solutionvoid* philosopher(void* forks){     info phil_info = forks;     pthread_mutex_t* left_fork = phil_info-&gt;left_fork;     pthread_mutex_t* right_fork = phil_info-&gt;right_fork;     while(phil_info-&gt;simulation){          pthread_mutex_lock(left_fork);          pthread_mutex_lock(right_fork);          eat(left_fork, right_fork);          pthread_mutex_unlock(left_fork);          pthread_mutex_unlock(right_fork);     }}But this runs into a problem! What if everyone picks up their left fork and is waiting on their right fork? We have deadlocked the program. It is important to note that deadlock doesn’t happen all the time and the probability that this solution deadlocks goes down as the number of philosophers goes up. What is really important to note is that eventually that this solution will deadlock, letting threads starve which is bad.Trylock? More like livelockSo now you are thinking about breaking one of the coffman conditions. We have  Mutual Exclusion  No Preemption  Hold and wait  Circular WaitWell we can’t have two philosophers use a fork at the same time, mutual exclusion is out of the picture. In our current, simple model, we can’t have the philosopher let go of the mutex lock once he/she has a hold of it, so we will take this solution out right now – there are some notes at the bottom of the page about this solution. Let’s break Hold and Wait!void* philosopher(void* forks){     info phil_info = forks;     pthread_mutex_t* left_fork = phil_info-&gt;left_fork;     pthread_mutex_t* right_fork = phil_info-&gt;right_fork;     while(phil_info-&gt;simulation){          pthread_mutex_lock(left_fork);          int failed = pthread_mutex_trylock(right_fork);          if(!failed){               eat(left_fork, right_fork);               pthread_mutex_unlock(right_fork);          }          pthread_mutex_unlock(left_fork);     }}Now our philosopher picks up the left fork and tries to grab the right. If it’s available, they eat. If it’s not available, they put the left fork down and try again. No deadlock!But, there is a problem. What if all the philosophers pick up their left at the same time, try to grab their right, put their left down, pick up their left, try to grab their right…. We have now livelocked our solution! Our poor philosopher are still starving, so let’s give them some proper solutions.Viable SolutionsArbitrator (Naive and Advanced).The naive arbitrator solution is have one arbitrator (a mutex for example). Have each of the philosopher ask the arbitrator for permission to eat. This solution allows one philosopher to eat at a time. When they are done, another philosopher can ask for permission to eat.This prevents deadlock because there is no circular wait! No philosopher has to wait on any other philosopher.The advanced arbitrator solution is to implement a class that determines if the philosopher’s forks are in the arbitrator’s possession. If they are, they give them to the philosopher, let him eat, and take the forks back. This has the added bonus of being able to have multiple philosopher eat at the same time.Problems:  These solutions are slow  They have a single point of failure, the arbitrator making it a bottleneck  The arbitrator needs to also be fair, and be able to determine deadlock in the second solution  In practical systems, the arbitrator tends to give the forks repeatedly to philosophers that just ate because of process schedulingLeaving the Table (Stallings’ Solution)Why does the first solution deadlock? Well there are n philosophers and n chopsticks. What if there is only 1 philsopher at the table? Can we deadlock? No.How about 2 philsophers? 3? … You can see where this is going. Stallings’ solutions says to remove philosophers from the table until deadlock is not possible – think about what the magic number of philosophers at the table is. The way to do this in actual system is through semaphores and letting a certain number of philosopher through.Problems:  The solution requires a lot of context switching which is very expensive for the CPU  You need to know about the number of resources before hand in order to only let that number of philosophers  Again priority is given to the processes who have already eaten.Partial Ordering (Dijkstra’s Solution)This is Dijkstra’s solution (he was the one to propose this problem on an exam). Why does the first solution deadlock? Dijkstra thought that the last philosopher who picks up his left fork (causing the solution to deadlock) should pick up his right. He accomplishes it by number the forks 1..n, and tells each of the philosopher to pick up his lower number fork.Let’s run through the deadlock condition again. Everyone tries to pick up their lower number fork first. Philosopher 1 gets fork 1, Philosopher 2 gets fork 2, and so on until we get to Philosopher n. They have to choose between fork 1 and n. fork 1 is already held up by philosopher 1, so they can’t pick up that fork, meaning he won’t pick up fork n. We have broken circular wait! Meaning deadlock isn’t possible.Problems:  The philosopher needs to know the set of resources in order before grabbing any resources.  You need to define a partial order to all of the resources.  Prioritizes philosopher who have already eaten.Advanced SolutionsThere are many more advanced solutions a non-exhaustive list includes  Clean/Dirty Forks (Chandra/Misra Solution)  Actor Model (other Message passing models)  Super Arbitrators (Complicated pipelines)"
  },{
    "title": "Deadlock Review Questions",
    "url": " /wikibook/deadlock-review-questions",
   "content": "TopicsCoffman ConditionsResource Allocation GraphsDining Philosophers  Failed DP Solutions  Livelocking DP Solutions  Working DP Solutions: Benefits/DrawbacksQuestions  What are the Coffman Conditions?  What do each of the Coffman conditions mean? (e.g. can you provide a definition of each one)  Give a real life example of breaking each Coffman condition in turn. A situation to consider: Painters, Paint, Paintbrushes etc. How would you assure that work would get done?  Be able to identify when Dining Philosophers code causes a deadlock (or not).For example, if you saw the following code snippet which Coffman condition is not satisfied?    // Get both locks or none.pthread_mutex_lock( a );if( pthread_mutex_trylock( b ) ) { /*failed*/ pthread_mutex_unlock( a ); ...}    If one thread calls    pthread_mutex_lock(m1) // successpthread_mutex_lock(m2) // blocks    and another threads calls    pthread_mutex_lock(m2) // successpthread_mutex_lock(m1) // blocks    What happens and why? What happens if a third thread calls pthread_mutex_lock(m1) ?    How many processes are blocked? As usual assume that a process is able to complete if it is able to acquire all of the resources listed below.          P1 acquires R1      P2 acquires R2      P1 acquires R3      P2 waits for R3      P3 acquires R5      P1 waits for R4      P3 waits for R1      P4 waits for R5      P5 waits for R1      (Draw out the resource graph!)"
  },{
    "title": "Exam Topics",
    "url": " /wikibook/exam-topics",
   "content": "The final exam will likely include multiple choice questions that test your mastery of the following.CSP (critical section problems)HTTPSIGINTTCPTLBVirtual Memoryarraysbarrierc stringschmodclient/servercoffman conditionscondition variablescontext switchdeadlockdining philosophersepollexitfile I/Ofile system representationfork/exec/waitfprintffreeheap allocatorheap/stackinode vs namemallocmkfifommapmutexesnetwork portsopen/closeoperating system termspage faultpage tablespipespointer arithmeticpointersprinting (printf)producer/consumerprogress/mutexrace conditionsread/writereader/writerresource allocation graphsring bufferscanf bufferingschedulingselectsemaphoressignalssizeofstatstderr/stdoutsymlinksthread control (_create, _join, _exit)variable initializersvariable scopevm thrashingwait macroswrite/read with errno, EINTR and partial data"
  },{
    "title": "#Example Markdown",
    "url": " /wikibook/example%20markdown",
   "content": "ExampleSubsectionHere’s some code,int main() {  int a = 4;  a = a + 1;  return a;}"
  },{
    "title": "File System, Part 1: Introduction",
    "url": " /wikibook/file-system-part-1-introduction",
   "content": "Navigation/TerminologyDesign a file system! What are your design goals?The design of a file system is difficult problem because there many high-level design goals that we’d like to satisfy. An incomplete list of ideal goals include:  Reliable and robust (even with hardware failures or incomplete writes due to power loss)  Access (security) controls  Accounting and quotas  Indexing and search  Versioning and backup capabilities  Encryption  Automatic compression  High performance (e.g. Caching in-memory)  Efficient use of storage de-duplicationNot all filesystems natively support all of these goals. For example, many filesystems do not automatically compress rarely-used filesWhat are ., .., and ...?In standard unix file systems:  . represents the current directory  .. represents the parent directory  ... is NOT a valid representation of any directory (this not the grandparent directory). It could however be the name of a file on disk.What are absolute and relative paths?Absolute paths are paths that start from the ‘root node’ of your directory tree. Relative paths are paths that start from your current position in the tree.What are some examples of relative and absolute paths?If you start in your home directory (“~” for short), then Desktop/cs241 would be a relative path. Its absolute path counterpart might be something like /Users/[yourname]/Desktop/cs241.How do I simplify a/b/../c/./?Remember that .. means ‘parent folder’ and that . means ‘current folder’.Example: a/b/../c/./  Step 1: cd a (in a)  Step 2: cd b (in a/b)  Step 3: cd .. (in a, because .. represents ‘parent folder’)  Step 4: cd c (in a/c)  Step 5: cd . (in a/c, because . represents ‘current folder’)Thus, this path can be simplified to a/c.So what’s a File System?A filesystem is how information is organized on disk. Whenever you want to access a file, the filesystem dictates how the file is read. Here is a sample image of a filesystem.Whoa that’s a lot let’s break it down  Superblock: This block contains metadata about the filesystem, how large, last modified time, a journal, number of inodes and the first inode start, number of data block and the first data block start.  Inode: This is the key abstraction. An inode is a file.  Disk Blocks: These are where the data is stored. The actual contents of the fileHow does inode store the file contents?From Wikipedia:  In a Unix-style file system, an index node, informally referred to as an inode, is a data structure used to represent a filesystem object, which can be one of various things including a file or a directory. Each inode stores the attributes and disk block location(s) of the filesystem object’s data. Filesystem object attributes may include manipulation metadata (e.g. change, access, modify time), as well as owner and permission data (e.g. group-id, user-id, permissions).To read the first few bytes of the file, follow the first direct block pointer to the first direct block and read the first few bytes, writing is the same process. If you want to read the entire file, keep reading direct blocks until your size runs out (we will talk about indirect blocks in a bit)  “All problems in computer science can be solved by another level of indirection.” - David WheelerWhy make disk blocks the same size as memory pages?To support virtual memory, so we can page stuff in and out of memory.What information do we want to store for each file?  Filename  File size  Time created, last modified, last accessed  Permissions  Filepath  Checksum  File data (inode)What are the traditional permissions: user – group – other permissions for a file?Some common file permissions include:  755: rwx r-x r-xuser: rwx, group: r-x, others: r-xUser can read, write and execute. Group and others can only read and execute.  644: rw- r-- r--user: rw-, group: r--, others: r--User can read and write. Group and others can only read.What are the the 3 permission bits for a regular file for each role?  Read (most significant bit)  Write (2nd bit)  Execute (least significant bit)What do “644” “755” mean?These are examples of permissions in octal format (base 8). Each octal digit corresponds to a different role (user, group, world).We can read permissions in octal format as follows:  644 - R/W user permissions, R group permissions, R world permissions  755 - R/W/X user permissions, R/X group permissions, R/X world permissionsHow many pointers can you store in each indirection table?As a worked example, suppose we divide the disk into 4KB blocks and we want to address up to 2^32 blocks.The maximum disk size is 4KB *2^32 = 16TB  (remember 2^10 = 1024)A disk block can store 4KB / 4B (each pointer needs to be 32 bits) = 1024 pointers. Each pointer refers to a 4KB disk block - so you can refer up to 1024*4KB = 4MB of dataFor the same disk configuration, a double indirect block stores 1024 pointers to 1024 indirection tables. Thus a double-indirect block can refer up to 1024 * 4MB = 4GB of data.Similarly, a triple indirect block can refer up to 4TB of data.Go to File System: Part 2"
  },{
    "title": "File System, Part 2: Files are inodes",
    "url": " /wikibook/file-system-part-2-files-are-inodes",
   "content": "Big idea: Forget names of files: The ‘inode’ is the file.It is common to think of the file name as the ‘actual’ file. It’s not! Instead consider the inode as the file. The inode holds the meta-information (last accessed, ownership, size) and points to the disk blocks used to hold the file contents.So… How do we implement a directory?A directory is just a mapping of names to inode numbers.POSIX provides a small set of functions to read the filename and inode number for each entry (see below)Let’s think about what it looks like in the actual file system. Theoretically, directories are just like actual files. The disk blocks will contain directory entries or dirents. What that means is that our disk block can look like this| inode_num | name ||———–|——|| 2043567   | hi.txt |…Each directory entry could either be a fixed size, or a variable c-string. It depends on how the particular filesystem implements it at the lower level.How can I find the inode number of a file?From a shell, use ls with the -i option$ ls -i12983989 dirlist.c\t\t12984068 sandwich.cFrom C, call one of the stat functions (introduced below).How do I find out meta-information about a file (or directory)?Use the stat calls. For example, to find out when my ‘notes.txt’ file was last accessed -   struct stat s;   stat(\"notes.txt\", &amp;s);   printf(\"Last accessed %s\", ctime(&amp;s.st_atime));There are actually three versions of stat;       int stat(const char *path, struct stat *buf);       int fstat(int fd, struct stat *buf);       int lstat(const char *path, struct stat *buf);For example you can use fstat to find out the meta-information about a file if you already have an file descriptor associated with that file   FILE *file = fopen(\"notes.txt\", \"r\");   int fd = fileno(file); /* Just for fun - extract the file descriptor from a C FILE struct */   struct stat s;   fstat(fd, &amp; s);   printf(\"Last accessed %s\", ctime(&amp;s.st_atime));The third call ‘lstat’ we will discuss when we introduce symbolic links.In addition to access,creation, and modified times, the stat structure includes the inode number, length of the file and owner information.struct stat {               dev_t     st_dev;     /* ID of device containing file */               ino_t     st_ino;     /* inode number */               mode_t    st_mode;    /* protection */               nlink_t   st_nlink;   /* number of hard links */               uid_t     st_uid;     /* user ID of owner */               gid_t     st_gid;     /* group ID of owner */               dev_t     st_rdev;    /* device ID (if special file) */               off_t     st_size;    /* total size, in bytes */               blksize_t st_blksize; /* blocksize for file system I/O */               blkcnt_t  st_blocks;  /* number of 512B blocks allocated */               time_t    st_atime;   /* time of last access */               time_t    st_mtime;   /* time of last modification */               time_t    st_ctime;   /* time of last status change */           };How do I list the contents of a directory ?Let’s write our own version of ‘ls’ to list the contents of a directory.#include &lt;stdio.h&gt;#include &lt;dirent.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char **argv) {    if(argc == 1) {        printf(\"Usage: %s [directory]\\n\", *argv);        exit(0);    }    struct dirent *dp;    DIR *dirp = opendir(argv[1]);    while ((dp = readdir(dirp)) != NULL) {        puts(dp-&gt;d_name);    }    closedir(dirp);    return 0;}How do I read the contents of a directory?Ans: Use opendir readdir closedirFor example, here’s a very simple implementation of ‘ls’ to list the contents of a directory.#include &lt;stdio.h&gt;#include &lt;dirent.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char **argv) {    if(argc ==1) {        printf(\"Usage: %s [directory]\\n\", *argv);        exit(0);    }    struct dirent *dp;    DIR *dirp = opendir(argv[1]);    while ((dp = readdir(dirp)) != NULL) {        printf(\"%s %lu\\n\", dp-&gt; d_name, (unsigned long)dp-&gt; d_ino );    }    closedir(dirp);    return 0;}Note: after a call to fork(), either (XOR) the parent or the child can use readdir(), rewinddir() or seekdir(). If both the parent and the child use the above, behavior is undefined.How do I check to see if a file is in the current directory?For example, to see if a particular directory includes a file (or filename) ‘name’, we might write the following code. (Hint: Can you spot the bug?)int exists(char *directory, char *name)  {    struct dirent *dp;    DIR *dirp = opendir(directory);    while ((dp = readdir(dirp)) != NULL) {        puts(dp-&gt;d_name);        if (!strcmp(dp-&gt;d_name, name)) { \t    return 1; /* Found */        }    }    closedir(dirp);    return 0; /* Not Found */}The above code has a subtle bug: It leaks resources! If a matching filename is found then ‘closedir’ is never called as part of the early return. Any file descriptors opened, and any memory allocated, by opendir are never released. This means eventually the process will run out of resources and an open or opendir call will fail.The fix is to ensure we free up resources in every possible code-path. In the above code this means calling closedir before return 1. Forgetting to release resources is a common C programming bug because there is no support in the C lanaguage to ensure resources are always released with all codepaths.What are the gotcha’s of using readdir? For example to recursively search directories?There are two main gotchas and one consideration:The readdir function returns “.” (current directory) and “..” (parent directory). If you are looking for sub-directories, you need to explicitly exclude these directories.For many applications it’s reasonable to check the current directory first before recursively searching sub-directories. This can be achieved by storing the results in a linked list, or resetting the directory struct to restart from the beginning.One final note of caution: readdir is not thread-safe! For multi-threaded searches use readdir_r which requires the caller to pass in the address of an existing dirent struct.See the man page of readdir for more details.How do I determine if a directory entry is a directory?Ans: Use S_ISDIR to check the mode bits stored in the stat structureAnd to check if a file is regular file use S_ISREG,   struct stat s;   if (0 == stat(name, &amp;s)) {      printf(\"%s \", name);      if (S_ISDIR( s.st_mode)) puts(\"is a directory\");      if (S_ISREG( s.st_mode)) puts(\"is a regular file\");   } else {      perror(\"stat failed - are you sure I can read this file's meta data?\");   }Does a directory have an inode too?Yes! Though a better way to think about this, is that a directory (like a file) is an inode (with some data - the directory name and inode contents). It just happens to be a special kind of inode.From Wikipedia:  Unix directories are lists of association structures, each of which contains one filename and one inode number.Remember, inodes don’t contain filenames–only other file metadata.How can I have the same file appear in two different places in my file system?First remember that a file name != the file. Think of the inode as ‘the file’ and a directory as just a list of names with each name mapped to an inode number. Some of those inodes may be regular file inodes, others may be directory inodes.If we already have a file on a file system we can create another link to the same inode using the ‘ln’ command$ ln file1.txt blip.txtHowever blip.txt is the same file; if I edit blip I’m editing the same file as ‘file1.txt!’We can prove this by showing that both file names refer to the same inode:$ ls -i file1.txt blip.txt134235 file1.txt134235 blip.txtThese kinds of links (aka directory entries) are called ‘hard links’The equivalent C call is linklink(const char *path1, const char *path2);link(\"file1.txt\", \"blip.txt\");For simplicity the above examples made hard links inside the same directory however hard links can be created anywhere inside the same filesystem.What happens when I rm (remove) a file?When you remove a file (using rm or unlink) you are removing an inode reference from a directory.However the inode may still be referenced from other directories. In order to determine if the contents of the file are still required, each inode keeps a reference count that is updated whenever a new link is created or destroyed.Case study: Back up software that minimizes file duplicationAn example use of hard-links is to efficiently create multiple archives of a file system at different points in time. Once the archive area has a copy of a particular file, then future archives can re-use these archive files rather than creating a duplicate file. Apple’s “Time Machine” software does this.Can I create hard links to directories as well as regular files?No. Well yes. Not really… Actually you didn’t really want to do this, did you?The POSIX standard says no you may not! The ln command will only allow root to do this and only if you provide the -d option. However even root may not be able to perform this because most filesystems prevent it!Why does POSIX prevent hard links to directories?The integrity of the file system assumes the directory structure (excluding softlinks which we will talk about later) is a non-cyclic tree that is reachable from the root directory. It becomes expensive to enforce or verify this constraint if directory linking is allowed. Breaking these assumptions can cause file integrity tools to not be able to repair the file system. Recursive searches potentially never terminate and directories can have more than one parent but “..” can only refer to a single parent. All in all, a bad idea.Back: File System, Part 1 |Next: File System, Part 3"
  },{
    "title": "File System, Part 3: Permissions",
    "url": " /wikibook/file-system-part-3-permissions",
   "content": "Remind Me What do Permissions mean again?Every file and directory has a set of 9 permission bits and a type field  r, permission to read the file  w, permission to write to the file  x, permission to execute the filechmod 777             chmod      7      7      7                  01      111      111      111              d      rwx      rwx      rwx              1      2      3      4        Type of the file  Owner Permissions  Group Permissions  Everybody else’s permissionmknod changes the first field, the type of the file.chmod takes a number and a file and changes the permission bits.The file has an owner. If your process has the same user id as the owner (or root) then the permissions in the first triad apply to you. If you are in the same group as the file (all files are also owned by a group) then the next set of permission bits applies to you. If none of the above apply, the last triad applies to you.How do I change the permissions on a file?Use chmod  (short for “change the file mode bits”)There is a system call, int chmod(const char *path, mode_t mode); but we will concentrate on the shell command. There’s two common ways to use chmod ; with an octal value or with a symbolic string:$ chmod 644 file1$ chmod 755 file2$ chmod 700 file3$ chmod ugo-w file4$ chmod o-rx file4The base-8 (‘octal’) digits describe the permissions for each role: The user who owns the file, the group and everyone else. The octal number is the sum of three values given to the three types of permission: read(4), write(2), execute(1)Example: chmod 755 myfile  r + w + x = digit  user has 4+2+1, full permission  group has 4+0+1, read and execute permission  all users have 4+0+1, read and execute permissionHow do I read the permission string from ls?Use `ls -l’. Note that the permissions will output in the format ‘drwxrwxrwx’. The first character indicates the type of file type. Possible values for the first character:  (-) regular file  (d) directory  (c) character device file  (l) symbolic link  (p) pipe  (b) block device  (s) socketWhat is sudo?Use sudo to become the admin on the machine.e.g. Normally (unless explicitly specified in the ‘/etc/fstab’ file, you need root access to mount a filesystem). sudo can be used to temporarily run a command as root (provided the user has sudo privileges)$ sudo mount /dev/sda2 /stuff/mydisk$ sudo adduser fredHow do I change ownership of a file?Use chown username filenameHow do I set permissions from code?chmod(const char *path, mode_t mode);Why are some files ‘setuid’? What does this mean?The set-user-ID-on-execution bit changes the user associated with the process when the file is run. This is typically used for commands that need to run as root but are executed by non-root users. An example of this is sudoThe set-group-ID-on-execution changes the group under which the process is run.Why are they useful?The most common usecase is so that the user can have root(admin) access for the duration of the program.What permissions does sudo run as ?$ ls -l /usr/bin/sudo-r-s--x--x  1 root  wheel  327920 Oct 24 09:04 /usr/bin/sudoThe ‘s’ bit means execute and set-uid; the effective userid of the process will be different from the parent process. In this example it will be rootWhat’s the difference between getuid() and geteuid()?  getuid returns the real user id (zero if logged in as root)  geteuid returns the effective userid (zero if acting as root, e.g. due to the setuid flag set on a program)How do I ensure only privileged users can run my code?  Check the effective permissions of the user by calling geteuid(). A return value of zero means the program is running effectively as root.Go to File System: Part 4"
  },{
    "title": "File System, Part 4: Working with directories",
    "url": " /wikibook/file-system-part-4-working-with-directories",
   "content": "How do I find out if file (an inode) is a regular file or directory?Use the S_ISDIR macro to check the mode bits in the stat struct:struct stat s;stat(\"/tmp\", &amp;s);if (S_ISDIR(s.st_mode)) { ... Note, later we will write robust code to verify that the stat call succeeds (returns 0); if the stat call fails, we should assume the stat struct content is arbitrary.How do I recurse into subdirectories?First a puzzle - how many bugs can you find in the following code?void dirlist(char *path) {    struct dirent *dp;  DIR *dirp = opendir(path);  while ((dp = readdir(dirp)) != NULL) {     char newpath[strlen(path) + strlen(dp-&gt;d_name) + 1];     sprintf(newpath,\"%s/%s\", newpath, dp-&gt;d_name);     printf(\"%s\\n\", dp-&gt;d_name);     dirlist(newpath);  }}int main(int argc, char **argv) { dirlist(argv[1]); return 0; }Did you find all 5 bugs?// Check opendir result (perhaps user gave us a path that can not be opened as a directoryif (!dirp) { perror(\"Could not open directory\"); return; }// +2 as we need space for the / and the terminating 0char newpath[strlen(path) + strlen(dp-&gt;d_name) + 2]; // Correct parametersprintf(newpath,\"%s/%s\", path, dp-&gt;d_name); // Perform stat test (and verify) before recursingif (0 == stat(newpath,&amp;s) &amp;&amp; S_ISDIR(s.st_mode)) dirlist(newpath)// Resource leak: the directory file handle is not closed after the while loopclosedir(dirp);What are symbolic links? How do they work? How do I make one?symlink(const char *target, const char *symlink);To create a symbolic link in the shell use ln -sTo read the contents of the link as just a file use readlink$ readlink myfile.txt../../dir1/notes.txtTo read the meta-(stat) information of a symbolic link use lstat not statstruct stat s1, s2;stat(\"myfile.txt\", &amp;s1); // stat info about  the notes.txt filelstat(\"myfile.txt\", &amp;s2); // stat info about the symbolic linkAdvantages of symbolic links  Can refer to files that don’t exist yet  Unlike hard links, can refer to directories as well as regular files  Can refer to files (and directories) that exist outside of the current file systemMain disadvantage: Slower than regular files and directories. When the links contents are read, they must be interpreted as a new path to the target file.What is /dev/null and when is it used?The file /dev/null is a great place to store bits that you never need to read!Bytes sent to /dev/null/ are never stored - they are simply discarded. A common use of /dev/null is to discard standard output. For example,$ ls . &gt;/dev/nullWhy would I want to set a directory’s sticky bit?When a directory’s sticky bit is set only the file’s owner, the directory’s owner, and the root user can rename (or delete) the file. This is useful when multiple users have write access to a common directory.A common use of the sticky bit is for the shared and writable /tmp directory.Why do shell and script programs start with #!/usr/bin/env python ?Ans: For portability!While it is possible to write the fully qualified path to a python or perl interpreter, this approach is not portable because you may have installed python in a different directory.To overcome this use the env utility is used to find and execute the program on the user’s path.The env utility itself has historically been stored in /usr/bin - and it must be specified with an absolute path.How do I make ‘hidden’ files i.e. not listed by “ls”? How do I list them?Easy! Create files (or directories) that start with a “.” - then (by default) they are not displayed by standard tools and utilities.This is often used to hide configuration files inside the user’s home directory.For example ssh stores its preferences inside a directory called .sshdTo list all files including the normally hidden entries use ls with  -a option$ ls -a.\t\t\ta.c\t\t\tmyls..\t\t\ta.out\t\t\tother.txt.secret\tWhat happens if I turn off the execute bit on directories?The execute bit for a directory is used to control whether the directory contents is listable.$ chmod ugo-x dir1$ ls -ldrw-r--r--   3 angrave  staff   102 Nov 10 11:22 dir1However when attempting to list the contents of the directory,$ ls dir1ls: dir1: Permission deniedIn other words, the directory itself is discoverable but its contents cannot be listed.What is file globbing (and who does it)?Before executing the program the shell expands parameters into matching filenames. For example, if the current directory has three filenames that start with my ( my1.txt mytext.txt myomy), then$ echo my*Expands to$ echo my1.txt mytext.txt myomyThis is known as file globbing and is processed before the command is executed.ie the command’s parameters are identical to manually typing every matching filename.Creating secure directoriesSuppose you created your own directory in /tmp and then set the permissions so that only you can use the directory (see below). Is this secure?$ mkdir /tmp/mystuff$ chmod 700 /tmp/mystuffThere is a window of opportunity between when the directory is created and when it’s permissions are changed. This leads to several vulnerabilities that are based on a race condition (where an attacker modifies the directory in some way before the privileges are removed). Some examples include:Another user replaces mystuff with a hardlink to an existing file or directory owned by the second user, then they would be able to read and control the contents of the mystuff directory. Oh no - our secrets are no longer secret!However in this specific example the /tmp directory has the sticky bit set, so other users may not delete the mystuff directory, and the simple attack scenario described above is impossible. This does not mean that creating the directory and then later making the directory private is secure! A better version is to atomically create the directory with the correct permissions from its inception -$ mkdir -m 700 /tmp/mystuffHow do I automatically create parent directories?$ mkdir -p d1/d2/d3Will automatically create d1 and d2 if they don’t exist.My default umask 022; what does this mean?The umask subtracts (reduces) permission bits from 777 and is used when new files and new directories are created by open,mkdir etc. Thus 022 (octal) means that group and other privileges will not include the writable bit . Each process (including the shell) has a current umask value. When forking, the child inherits the parent’s umask value.For example, by setting the umask to 077 in the shell, ensures that future file and directory creation will only be accessible to the current user,$ umask 077$ mkdir secretdirAs a code example, suppose a new file is created with open() and mode bits 666 (write and read bits for user,group and other):open(\"myfile\", O_CREAT, S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IWOTH);If umask is octal 022, then the permissions of the created file will be 0666 &amp; ~022ie.           S_IRUSR | S_IWUSR | S_IRGRP | S_IROTHHow can I copy bytes from one file to another?Use  the versatile dd command. For example, the following command copies 1 MB of data from the file /dev/urandom to the file /dev/null. The data is copied as 1024 blocks of blocksize 1024 bytes.$ dd if=/dev/urandom of=/dev/null bs=1k count=1024Both the input and output files in the example above are virtual - they don’t exist on a disk. This means the speed of the transfer is unaffected by hardware power. Instead they are part of the dev filesystem, which is virtual filesystem provided by the kernel.The virtual file /dev/urandom provides an infinite stream of random bytes, while the virtal file /dev/null ignores all bytes written to it. A common use of /dev/null is to discard the output of a command,$ myverboseexecutable &gt; /dev/nullAnother commonly used /dev virtual file is /dev/zero which provides an infinite stream of zero bytes.For example, we can benchmark the operating system performance of reading stream zero bytes in the kernel into a process memory and writing the bytes back to the kernel without any disk I/O. Note the throughput (~20GB/s) is strongly dependent on blocksize. For small block sizes the overhead of additional read and write system calls will  dominate.$ dd if=/dev/zero of=/dev/null bs=1M count=10241024+0 records in1024+0 records out1073741824 bytes (1.1 GB) copied, 0.0539153 s, 19.9 GB/sWhat happens when I touch a file?The touch executable creates file if it does not exist and also updates the file’s last modified time to be the current time. For example, we can make a new private file with the current time:$ umask 077       # all future new files will maskout all r,w,x bits for group and other access$ touch file123   # create a file if it does not exist, and update its modified time$ stat file123  File: `file123'  Size: 0         \tBlocks: 0          IO Block: 65536  regular empty fileDevice: 21h/33d\tInode: 226148      Links: 1Access: (0600/-rw-------)  Uid: (395606/ angrave)   Gid: (61019/     ews)Access: 2014-11-12 13:42:06.000000000 -0600Modify: 2014-11-12 13:42:06.001787000 -0600Change: 2014-11-12 13:42:06.001787000 -0600An example use of touch is to force make to recompile a file that is unchanged after modifying the compiler options inside the makefile. Remeber that make is ‘lazy’ - it will compare the modified time of the source file with the corresponding output file to see if the file needs to be recompiled$ touch myprogram.c   # force my source file to be recompiled$ makeGo to File System: Part 5"
  },{
    "title": "File System, Part 5: Virtual file systems",
    "url": " /wikibook/file-system-part-5-virtual-file-systems",
   "content": "Virtual file systemsPOSIX systems, such as Linux and Mac OSX (which is based on BSD) include several virtual filesystems that are mounted (available) as part of the file-system. Files inside these virtual filesystems do not exist on the disk; they are generated dynamically by the kernel when a process requests a directory listing.Linux provides 3 main virtual filesystems/dev  - A list of physical and virtual devices (for example network card, cdrom, random number generator)/proc - A list of resources used by each process and (by tradition) set of system information/sys - An organized list of internal kernel entitiesFor example if I want a continuous stream of 0s, I can cat /dev/zero.How do I find out what filesystems are currently available (mounted)?Use mountUsing mount without any options generates a list (one filesystem per line) of mounted filesystems including networked, virtual and local (spinning disk / SSD-based) filesystems. Here is a typical output of mount$ mount/dev/mapper/cs241--server_sys-root on / type ext4 (rw)proc on /proc type proc (rw)sysfs on /sys type sysfs (rw)devpts on /dev/pts type devpts (rw,gid=5,mode=620)tmpfs on /dev/shm type tmpfs (rw,rootcontext=\"system_u:object_r:tmpfs_t:s0\")/dev/sda1 on /boot type ext3 (rw)/dev/mapper/cs241--server_sys-srv on /srv type ext4 (rw)/dev/mapper/cs241--server_sys-tmp on /tmp type ext4 (rw)/dev/mapper/cs241--server_sys-var on /var type ext4 (rw)rw,bind)/srv/software/Mathematica-8.0 on /software/Mathematica-8.0 type none (rw,bind)engr-ews-homes.engr.illinois.edu:/fs1-homes/angrave/linux on /home/angrave type nfs (rw,soft,intr,tcp,noacl,acregmin=30,vers=3,sec=sys,sloppy,addr=128.174.252.102)Notice that each line includes the filesystem type source of the filesystem and mount point.To reduce this output we can pipe it into grep and only see lines that match a regular expression.&gt;mount | grep proc  # only see lines that contain 'proc'proc on /proc type proc (rw)none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)Differences between random and urandom?/dev/random is a file which contains number generator where the entropy is determined from environmental noise. Random will block/wait until enough entropy is collected from the environment./dev/urandom is like random, but differs in the fact that it allows for repetition (lower entropy threshold), thus wont block.Other Filesystems$ cat /proc/sys/kernel/random/entropy_avail$ hexdump /dev/random$ hexdump /dev/urandom$ cat /proc/meminfo$ cat /proc/cpuinfo$ cat /proc/cpuinfo | grep bogomips$ cat /proc/meminfo | grep Swap$ cd /proc/self$ echo $$; cd /proc/12345; cat mapsMounting a filesystemLet’s say I have a filesystem hooked up on /dev/cdrom that I want to read from. I have to mound it to a directory before I can do any operations.$ sudo mount /dev/cdrom /media/cdrom$ mount$ mount | grep procHow do I mount a disk image?Suppose you had downloaded a bootable linux disk image…wget http://cosmos.cites.illinois.edu/pub/archlinux/iso/2015.04.01/archlinux-2015.04.01-dual.isoBefore putting the filesystem on a CD, we can mount the file as a filesystem and explore its contents. Note, mount requires root access, so let’s run it using sudo$ mkdir arch$ sudo mount -o loop archlinux-2015.04.01-dual.iso ./arch$ cd archBefore the mount command, the arch directory is new and obviously empty. After mounting, the contents of arch/ will be drawn from the files and directories stored in the filesystem stored inside the archlinux-2014.11.01-dual.iso file.The loop option is required because we want to mount a regular file not a block device such as a physical disk.The loop option wraps the original file as a block device - in this example we will find out below that the file system is provided under /dev/loop0 : We can check the filesystem type and mount options by running the mount command without any parameters. We will pipe the output into grep so that we only see the relevant output line(s) that contain ‘arch’$ mount | grep arch/home/demo/archlinux-2014.11.01-dual.iso on /home/demo/arch type iso9660 (rw,loop=/dev/loop0)The iso9660 filesystem is a read-only filesystem originally designed for optical storage media (i.e. CDRoms). Attempting to change the contents of the filesystem will fail$ touch arch/nocandotouch: cannot touch `/home/demo/arch/nocando': Read-only file systemGo to File System: Part 6"
  },{
    "title": "File System, Part 6: Memory mapped files and Shared memory",
    "url": " /wikibook/file-system-part-6-memory-mapped-files-and-shared-memory",
   "content": "How does the operating system load my process and libraries into memory?By mapping the files’ contents into the address-space of the process.If many programs only need read-access to the same file (e.g. /bin/bash, the C library) then the same physical memory can be shared between multiple processes.The same mechanism can be used by programs to directly map files into memoryHow do I map a file into memory?A simple program to map a file into memory is shown below. The key points to notice are:  mmap requires a filedescriptor, so we need to open the file first  We seek to our desired size and write one byte to ensure that the file is sufficient length  When finished call munmap to unmap the file from memory.This example also shows the preprocessor constants “LINE” and “FILE” that hold the current line number and filename of the file currently being compiled.#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/mman.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;int fail(char *filename, int linenumber) {   fprintf(stderr, \"%s:%d %s\\n\", filename, linenumber, strerror(errno));   exit(1);  return 0; /*Make compiler happy */}#define QUIT fail(__FILE__, __LINE__ )int main() {  // We want a file big enough to hold 10 integers    int size = sizeof(int) * 10;  int fd = open(\"data\", O_RDWR | O_CREAT | O_TRUNC, 0600); //6 = read+write for me!  lseek(fd, size, SEEK_SET);  write(fd, \"A\", 1);    void *addr = mmap(0, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);  printf(\"Mapped at %p\\n\", addr);  if (addr == (void*) -1 ) QUIT;    int *array = addr;  array[0] = 0x12345678;  array[1] = 0xdeadc0de;  munmap(addr,size);  return 0;  }The contents of our binary file can be listed using hexdump$ hexdump data0000000 78 56 34 12 de c0 ad de 00 00 00 00 00 00 00 000000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 000000020 00 00 00 00 00 00 00 00 41   The careful reader may notice that our integers were written in least-significant-byte format (because that is the endianess of the CPU) and that we allocated a file that is one byte too many!The PROT_READ | PROT_WRITE options specify the virtual memory protection. The option PROT_EXEC (not used here) can be set to allow CPU execution of instructions in memory (e.g. this would be useful if you mapped an executable or library).What are the advantages of memory mapping a fileFor many applications the main advantages are:Simplified coding - the file data is immediately available. No need to parse the incoming data and store it in new memory structures.Sharing of files - memory mapped files are particularly efficient when the same data is shared between multiple processes.Note for simple sequential processing memory mapped files are not necessarily faster than standard ‘stream-based’ approaches of read / fscanf etc.How do I share memory between a parent and child process?Easy -  Use mmap without a file - just specify the MAP_ANONYMOUS and MAP_SHARED options!#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/mman.h&gt; /* mmap() is defined in this header */#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;int main() {    int size = 100 * sizeof(int);    void *addr = mmap(0, size, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);  printf(\"Mapped at %p\\n\", addr);    int *shared = addr;  pid_t mychild = fork();  if (mychild &gt; 0) {    shared[0] = 10;    shared[1] = 20;  } else {    sleep(1); // We will talk about synchronization later    printf(\"%d\\n\", shared[1] + shared[0]);  }  munmap(addr,size);  return 0;}Can I use shared memory for IPC ?Yes! As a simple example you could reserve just a few bytes and change the value in shared memory when you want the child process to quit.Sharing memory is a very efficient form of inter-process communication because there is no copying overhead - the two processes literally share the same physical frame of memory.Go to File System: Part 7"
  },{
    "title": "File System, Part 7: Scalable and Reliable Filesystems",
    "url": " /wikibook/file-system-part-7-scalable-and-reliable-filesystems",
   "content": "Reliable Single Disk FilesystemsHow and why does the kernel cache the filesystem?Most filesystems cache significant amounts of disk data in physical memory.Linux, in this respect, is particularly extreme: All unused memory is used as a giant disk cache.The disk cache can have significant impact on overall system performance because disk I/O is slow. This is especially true for random access requests on spinning disks where the disk read-write latency is dominated by the seek time required to move the read-write disk head to the correct position.For efficiency, the kernel caches recently used disk blocks. For writing we have to choose a trade-off between performance and reliability: Disk writes can also be cached (“Write-back cache”) where modified disk blocks are stored in memory until evicted. Alternatively a ‘write-through cache’ policy can be employed where disk writes are sent immediately to the disk. The latter is safer (as filesystem modifications are quickly stored to persistent media) but slower than a write-back cache; If writes are cached then they can be delayed and efficiently scheduled based on the physical position of each disk block.Note this is a simplified description because solid state drives (SSDs) can be used as a secondary write-back cache.Both solid state disks (SSD) and spinning disks have improved performance when reading or writing sequential data. Thus operating system can often use a read-ahead strategy to amortize the read-request costs (e.g. time cost for a spinning disk) and request several contiguous disk blocks per request. By issuing an I/O request for the next disk block before the user application requires the next disk block, the apparent disk I/O latency can be reduced.My data is important! Can I force the disk writes to be saved to the physical media and wait for it to complete?Yes (almost). Call sync to request that a filesystem changes be written (flushed) to disk.However, not all operating systems honor this request and even if the data is evicted from the kernel buffers the disk firmware use an internal on-disk cache or may not yet have finished changing the physical media.Note you can also request that all changes associated with a particular file descriptor are flushed to disk using fsync(int fd)What if my disk fails in the middle of an important operation?Don’t worry most modern file systems do something called journalling that work around this. What the file system does is before it completes a potentially expensive operation, is that it writes what it is going to do down in a journal. In the case of a crash or failure, one can step through the journal and see which files are corrupt and fix them. This is a way to salvage hard disks in cases there is critical data and there is no apparent backup.How likely is a disk failure?Disk failures are measured using “Mean-Time-Failure”. For large arrays, the mean failure time can be surprisingly short. For example if the MTTF(single disk) = 30,000 hours, then the MTTF(100 disks)= 30000/100=300 hours  ie about 12 days!RedundancyHow do I protect my data from disk failure?Easy! Store the data twice! This is the main principle of a “RAID-1” disk array. RAID is short for redundant array of inexpensive disks. By duplicating the writes to a disk with writes to another (backup disk) there are exactly two copies of the data. If one disk fails, the other disk serves as the only copy until it can be re-cloned. Reading data is faster (since data can be requested from either disk) but writes are potentially twice as slow (now two write commands need to be issued for every disk block write) and, compared to using a single disk, the cost of storage per byte has doubled.Another common RAID scheme is RAID-0, meaning that a file could be split up amoung two disks, but if any one of the disks fail then the files are irrecoverable. This has the benefit of halving write times because one part of the file could be writing to hard disk one and another part to hard disk two.It is also common to combine these systems. If you have a lot of hard disks, consider RAID-10. This is where you have two systems of RAID-1, but the systems are hooked up in RAID-0 to each other. This means you would get roughly the same speed from the slowdowns but now any one disk can fail and you can recover that disk. (If two disks from opposing raid partitions fail there is a chance that recover can happen though we don’t could on it most of the time).What is RAID-3?RAID-3 uses parity codes instead of mirroring the data. For each N-bits written we will write one extra bit, the ‘Parity bit’ that ensures the total number of 1s written is even.  The parity bit is written to an additional disk. If any one disk (including the parity disk) is lost, then its contents can still be computed using the contents of the other disks.One disadvantage of RAID-3 is that whenever a disk block is written, the parity block will always be written too. This means that there is effectively a bottleneck in a separate disk. In practice, this is more likely to cause a failure because one disk is being used 100% of the time and once that disk fails then the other disks are more prone to failure.How secure is RAID-3 to data-loss?A single disk failure will not result in data loss (because there is sufficient data to rebuild the array from the remaining disks). Data-loss will occur when a two disks are unusable because there is no longer sufficient data to rebuild the array. We can calculate the probability of a two disk failure based on the repair time which includes not just the time to insert a new disk but the time required to rebuild the entire contents of the array.MTTF = mean time to failureMTTR = mean time to repairN = number of original disksp = MTTR / (MTTF-one-disk / (N-1))Using typical numbers (MTTR=1day, MTTF=1000days, N-1 = 9,, p=0.009There is a 1% chance that another drive will fail during the rebuild process (at that point you had better hope you still have an accessible backup of your original data.In practice the probability of a second failure during the repair process is likely higher because rebuilding the array is I/O-intensive (and on top of normal I/O request activity). This higher I/O load will also stress the disk arrayWhat is RAID-5?RAID-5 is similar to RAID-3 except that the check block (parity information) is assigned to different disks for different blocks. The check-block is ‘rotated’ through the disk array. RAID-5 provides better read and write performance than RAID-3 because there is no longer the bottleneck of the single parity disk. The one drawback is that you need more disks to have this setup and there are more complicated algorithms need to be usedDistributed storageFailure is the common caseGoogle reports 2-10% of disks fail per yearNow multiply that by 60,000+ disks in a single warehouse…Must survive failure of not just a disk, but a rack of servers or a whole data centerSolutions:  Simple redundancy (2 or 3 copies of each file) e.g., Google GFS (2001)  More efficient redundancy (analogous to RAID 3++) e.g., Google Colossus filesystem (~2010)  customizable replication including Reed-Solomon codes with 1.5x redundancyGo to File System: Part 8"
  },{
    "title": "File System, Part 8: Removing preinstalled malware from an Android device",
    "url": " /wikibook/file-system-part-8-removing-preinstalled-malware-from-an-android-device",
   "content": "Case study: Removing malware from an Android deviceThis section uses filesystem features and system programming tools discussed in this wikibook to find and remove unwanted malware from an Android tablet.DISCLAIMER. ENSURE ANY VALUABLE INFORMATION ON YOUR DEVICE IS BACKED UP BEFORE ATTEMPTING TO MODIFY YOUR TABLET. MODIFYING SYSTEM SETTINGS AND SYSTEM FILES IS NOT RECOMMENDED. ATTEMPTING TO MODIFY A DEVICE USING THIS CASE STUDU GUIDE MAY CAUSE YOUR TABLET TO SHARE, LOSE OR CORRUPT YOUR DATA. FURTHER YOUR TABLET MAY FUNCTION INCORRECTLY OR TO STOP FUNCTIONING ALTOGETHER. USE THIS CASE STUDY AT YOUR OWN RISK. THE AUTHORS ASSUME NO RESPONSIBILITY AND MAKE NO WARRANTY ABOUT THE CORRECTNESS OR COMPLETENESS OF THESE INSTRUCTIONS INCLUDED IN THIS CASE STUDY. THE AUTHORS ASSUME NO RESPONSIBILITY AND MAKE NO WARRANTY ABOUT ANY SOFTWARE INCLUDING EXTERNAL THIRD PARTY SOFTWARE DESCRIBED OR LINKED TO IN THIS GUIDE.BackgroundAn E97 Android tablet purchased from Amazon had developed some peculiar quirks. Most noticeable was that the browser app always opened a website at gotoamazing.com rather than the home page set in the app’s preferences (known as browser ‘hijacking’). Can we use the knowledge from this wikibook to understand how this unwanted behavior occurs and also remove unwanted pre-installed apps from the device?Tools usedWhile it is possible to use the Android developer tools installed on a remote USB-connected machine, this guide uses only system tools on the tablet. The following apps were installed -  Malwarebytes - A free vulnerability and malware tool.  Terminal emulator - A simple terminal window that gives us shell access on the tablet.  KingRoot - A tool that uses known exploits in the linux kernel to gain root access.Installing any app can potentially allow arbitrary code to be executed if it is able to break out of the Android security model. Of the apps mentioned above, KingRoot is the most extreme example because it exploits system vulnerabilities to gain root access for our purposes. However in doing so, it could also Of these, KingRoot is the most questionable tool to install - we are trusting it not to install any of its own malware. A potentially safer alternative is to use https://github.com/android-rooting-tools/Overview of terminalThe most useful commands are  su grep mount and Android’s package manager tool, pm.  grep -s abc * /   (search for abc in current directory and immediate sub directories)  su ( aka “switch user” become root - requires a rooted device)  mount -o rw,remount /system  (allow /system partition to be writeable)  pm disable  (aka ‘package manager’ disable an Android app package)Overview of filesystem layoutOn this specific tablet that runs Android 4.4.2, pre-installed apps are unmodifiable and are located in/system/app//system/priv-app/and preferences and app-data are stored in the /data partitionEach app is typically packaged inside an apk file, which is essentially a zip file. When an app is installed the code is expanded into a file that can be directly parsed by the Android virtual machine. The binary code (at least for this particular virtual machine) has an odex extension.We can search the code of the installed system apps for the string ‘gotoamazing’grep -s gotoamazing /system/app/* /system/priv-app/*This didn’t find anything; it appears this string was not hardcoded into the source code of the given system apps. To verify that we can findLet’s check the data area of all installed appscd /data/datagrep -s gotoamazing * */* */*/*produced the followingdata/com.android.browser/shared_prefs/xbservice.xml: &lt;string name=\"URL\"&gt;http://www.gotoamazing...The -s option “silent option” stops grep from complaining about trying to grep directories and other invalid files. Note we could have also used -r to recursively search directories but it was fun to use file globbing (wildcard expansion of the * by the shell).Now we are getting somewhere! It looks like this string is part of the app ‘com.android.browser’ but let’s also find out which app binary code opens the ‘xbservice’ preference. Perhaps this unwanted service is hiding inside another app and managed to secretly load as an extension to the browser?Let’s look for any file that contains xbservice. This time we will recursively search in the directories of /system that include the ‘app’grep -r -s xbservice /system/*app*Binary file /system/app/Browser.odex matchesFinally - it appears the factory browser was shipped with the the home page hijacking pre-installed. Let’s uninstall it. For this, let’s become root.$ su# pm list packages -sAndroid’s package manager has many commands and options. The above example lists all currently installed system apps. We can uninstall the browser app using the following commandpm disable com.android.browserpm uninstall com.android.browserUsing pm list packages you can list all installed packages (use -s options to see just system packages). We disabled the following system apps. Of course there is no real guarantee that we successfully removed all unwanted software, or that one of these is a false-positive. As such we would not recommend keeping sensitive information on such a tablet.  com.android.browser  com.adups.fota.sysoper  elink.com  com.google.android.apps.cloudprint  com.mediatek.CrashService  com.get.googleApps  com.adups.fota (an over-the-air package that can install arbitrary items in the future).  com.mediatek.appguide.pluginIt is likely that you could just re-enable a package using pm enable package-name or pm install and the relevant .apk file in /system/app or /system/priv-app"
  },{
    "title": "File System, Part 9: Disk blocks example",
    "url": " /wikibook/file-system-part-9-disk-blocks-example",
   "content": "Under constructionPlease can you explain a simple model of how the file’s content is stored in a simple i-node based filesystem?Sure! To answer this question, we’ll build a virtual disk and then write some C code to access its contents. Our filesystem will divide the bytes available into space for inodes and a much larger space for disk blocks. Each disk block will be 4096 bytes-// Disk size:#define MAX_INODE (1024)#define MAX_BLOCK (1024*1024)// Each block is 4096 bytes:typedef char[4096] block_t;// A disk is an array of inodes and an array of disk blocks:struct inode[MAX_INODE] inodes;block[MAX_BLOCK] blocks;Note for clarity we will not use ‘unsigned’ in this code example. Our fixed-sized inodes will contain the file’s size in bytes, permission, user, group information, time meta-data. What is most relevant to the problem-at hand is that it will also include ten pointers to disk blocks that we will use to refer to the actual file’s contents!struct inode {    int[10] directblocks; // indices for the block array i.e. where to the find the file's content    long size;    // ... standard inode meta-data e.g.    int mode, userid, groupid;    time_t ctime, atime, mtime;}Now we can work out how to read a byte at offset position of our file:char readbyte(inode *inode, long position) {    if (position &lt; 0 || position &gt;= inode-&gt;size) return -1; // invalid offset    int block_count = position / 4096, offset = position % 4096;      // block count better be 0..9 !    int physical_idx = lookup_physical_block_index(inode, block_count );    // sanity check that the disk block index is reasonable...    assert (physical_idx &gt;= 0 &amp;&amp; physical_idx &lt; MAX_BLOCK);    // read the disk block from our virtual disk 'blocks' and return the specific byte    return blocks[physical_idx][offset];}Our initial version of lookup_physical_block is simple - we can use our table of 10 direct blocks!int lookup_physical_block_index(inode *inode, int block_count) {    assert (block_count &gt;= 0 &amp;&amp; block_count &lt; 10);    return inode-&gt;directblocks[block_count]; // returns an index value between [0,MAX_BLOCK)}This simple representation is reasonable provided we can represent all possible files with just ten blocks i.e. up to 40KB. What about larger files? We need the inode struct to always be the same size so just increasing the existing direct block array to 20 would roughly double the size of our inodes. If most of our files require less than 10 blocks, then our inode storage is now wasteful. To solve this problem we will use a disk block called the indirect block to extend the array of pointers at our disposal. We will only need this for files &gt; 40KBstruct inode {    int[10] directblocks; // if size&lt;4KB then only the first one is valid    int indirectblock; // valid value when size &gt;= 40KB    int size;    ...}The indirect block is just a regular disk block of 4096 bytes, but we will use it to hold pointers to disk blocks. Our pointers in this case are just integers, so we need to cast the pointer to an integer pointer:int lookup_physical_block_index(inode *inode, int block_count) {    assert (sizeof (int) == 4); // Warning this code assumes an index is 4 bytes!    assert (block_count &gt;= 0 &amp;&amp; block_count &lt; 1024 + 10); // 0 &lt;= block_count&lt; 1034    if (block_count &lt; 10)        return inode-&gt;directblocks[block_count];      // read the indirect block from disk:    block_t* oneblock = &amp;blocks[inode-&gt;indirectblock];    // Treat the 4KB as an array of 1024 pointers to other disk blocks    int *table = (int *) oneblock;      // Look up the correct entry in the table    // Offset by 10 because the first 10 blocks of data are already     // accounted for    return table[block_count - 10];}For a typical filesystem, our index values are 32 bits i.e. 4bytes. Thus in 4096 bytes we can store 4096 / 4 = 1024 entries.This means our indirect block can refer to 1024 * 4KB = 4MB of data. With the first ten direct blocks, we can therefore accommodate files up to 40KB + 1024 * 4KB= 4136KB . Some of the later table entries can be invalid for files that are smaller than this.For even larger files, we could use two indirect blocks. However there’s a better alternative, that will allow us to efficiently scale up to huge files. We will include a double-indirect pointer and if that’s not enough a triple indirect pointer. The double indirect pointer means we have a table of 1024 entries to disk blocks that are used as 1024 entries. This means we can refer to 1024*1024 disk blocks of data.(source: http://uw714doc.sco.com/en/FS_admin/graphics/s5chain.gif)int lookup_physical_block_index(inode *inode, int block_count) {    if (block_count &lt; 10)        return inode-&gt;directblocks[block_count];    // Use indirect block for the next 1024 blocks:    // Assumes 1024 ints can fit inside each block!    if (block_count &lt; 1024 + 10) {           int *table = (int *) &amp;blocks[inode-&gt;indirectblock];        return table[block_count - 10];    }    // For huge files we will use a table of tables    int i = (block_count - 1034) / 1024 , j = (block_count - 1034) % 1024;    assert (i &lt; 1024); // triple-indirect is not implemented here!    int *table1 = (int *) &amp;blocks[inode-&gt;doubleindirectblock];    // The first table tells us where to read the second table ...    int *table2 = (int *) &amp;blocks[table1[I]];    return table2[j];     // For gigantic files we will need to implement triple-indirect (table of tables of tables)}Notice that reading a byte using double indirect requires 3 disk block reads (two tables and the actual data block)."
  },{
    "title": "File Systems Review Questions",
    "url": " /wikibook/file-systems-review-questions",
   "content": "Topics  Superblock  Data Block  Inode  Relative Path  File Metadata  Hard and Soft Links  Permission Bits  Working with Directories  Virtual File System  Reliable File Systems  RAIDQuestions  How big can files be on a file system with 15 Direct blocks, 2 double, 3 triple indirect, 4kb blocks and 4byte entries? (Assume enough infinite blocks)  What is a superblock? Inode? Datablock?  How do I simplify /./proc/../dev/./random/  In ext2, what is stored in an inode, and what is stored in a directory entry?  What are /sys, /proc, /dev/random, and /dev/urandom?  What are permission bits?  How do you use chmod to set user/group/owner read/write/execute permissions?  What does the “dd” command do?  What is the difference between a hard link and a symbolic link? Does the file need to exist?  “ls -l” shows the size of each file in a directory. Is the size stored in the directory or in the file’s inode?"
  },{
    "title": "Files, Part 1: Working with files",
    "url": " /wikibook/files-part-1-working-with-files",
   "content": "Two types of filesOn linux, there are two abstractions with files. The first is the linux fd level abstraction that means you can use  open  read  write  close  lseek  fcntl…And so on. The linux interface is very powerful and expressive, but sometimes we need portability (for example if we are writing for a mac or windows). This is where C’s abstraction comes into play. On different operating systems, C uses the low level functions to create a wrapper around files you can use everywhere, meaning that C on linux uses the above calls. C has a few of the following  fopen  fread or fgetc/fgets or fscanf  fwrite or fprintf  fclose  fflushBut you don’t get the expressiveness that linux gives you with system calls you can convert back and forth between them with int fileno(FILE* stream) and FILE* fdopen(int fd...).Another important aspect to note is the C files are buffered meaning that their contents may not be written right away by default. You can can change that with C options.How do I tell how large a file is?For files less than the size of a long, using fseek and ftell is a simple way to accomplish this:Move to the end of the file and find out the current position.fseek(f, 0, SEEK_END);long pos = ftell(f);This tells us the current position in the file in bytes - i.e. the length of the file!fseek can also be used to set the absolute position.fseek(f, 0, SEEK_SET); // Move to the start of the file fseek(f, posn, SEEK_SET);  // Move to 'posn' in the file.All future reads and writes in the parent or child processes will honor this position.Note writing or reading from the file will change the current position.See the man pages for fseek and ftell for more information.But try not to do thisNote: This is not recommended in the usual case because of a quirk with the C language. That quirk is that longs only need to be 4 Bytes big meaning that the maximum size that ftell can return is a little under 2 Gigabytes (which we know nowadays our files could be hundreds of gigabytes or even terabytes on a distributed file system). What should we do instead? Use stat! We will cover stat in a later part but here is some code that will tell you the size of the filestruct stat buf;if(stat(filename, &amp;buf) == -1){\treturn -1;}return (ssize_t)buf.st_size;buf.st_size is of type off_t which is big enough for insanely large files.What happens if a child process closes a filestream using fclose or close?Closing a file stream is unique to each process. Other processes can continue to use their own file-handle. Remember, everything is copied over when a child is created, even the relative positions of the files.How about mmap for files?One of the general uses for mmap is to map a file to memory. This does not mean that the file is malloc’ed to memory right away. Take the following code for example.int fd = open(...); //File is 2 Pageschar* addr = mmap(..fd..);addr[0] = 'l';The kernel may say, “okay I see that you want to mmap the file into memory, so I’ll reserve some space in your address space that is the length of the file”. That means when you write to addr[0] that you are actually writing to the first byte of the file. The kernel can actually do some optimizations too. Instead of loading the file into memory, it may only load pages at a time because if the file is 1024 pages; you may only access 3 or 4 pages making loading the entire file a waste of time (that is why page faults are so powerful! They let the operating system take control of how much you use your files).For every mmapRemember that once you are done mmapping that you munmap to tell the operating system that you are no longer using the pages allocated, so the OS can write it back to disk and give you the addresses back in case you need to malloc later."
  },{
    "title": "Filesystem: Review Questions",
    "url": " /wikibook/filesystem-review-questions",
   "content": "  Question numbers subject to changeQ1Write a function that uses fseek and ftell to replace the middle character of a file with an ‘X’void xout(char* filename) {  FILE *f = fopen(filename, ____ );  }Q2In an ext2 filesystem how many inodes are read from disk to access the first byte of the file /dir1/subdirA/notes.txt ? Assume the directory names and inode numbers in the root directory (but not the inodes themselves) are already in memory.Q3In an ext2 filesystem what is the minimum number of disk blocks that must be read from disk to access the first byte of the file /dir1/subdirA/notes.txt ? Assume the directory names and inode numbers in the root directory and all inodes are already in memory.Q4In an ext2 filesystem with 32 bit addresses and 4KB disk blocks, an inodes that can store 10 direct disk block numbers. What is the minimum file size required to require an single indirection table? ii) a double direction table?Q5Fix the shell command chmod below to set the permission of a file secret.txt  so that the owner can read,write,and execute permissions the group can read and everyone else has no access.chmod 000 secret.txt"
  },{
    "title": "Forking, Part 1: Introduction",
    "url": " /wikibook/forking-part-1-introduction",
   "content": "A word of warningProcess forking is a very powerful (and very dangerous) tool. If you mess up and cause a fork bomb (explained later on this page), you can bring down the entire system. To reduce the chances of this, limit your maximum number of processes to a small number e.g 40 by typing ulimit -u 40 into a command line. Note that this limit is only for the user, which means if you fork bomb, then you won’t be able to kill all of the processes you just created since calling killall requires your shell to fork() … ironic right? So what can we do about this. One solution is to spawn another shell instance as another user (for example root) before hand and kill processes from there. Another is to use the built in exec command to kill all the user processes (careful you only have one shot at this). Finally you could reboot the system :)When testing fork() code, ensure that you have either root and/or physical access to the machine involved. If you must work on fork () code remotely, remember that kill -9 -1 will save you in the event of an emergency.TL;DR: Fork can be extremely dangerous if you aren’t prepared for it. You have been warned.Intro to ForkWhat does fork do?The fork system call clones the current process to create a new process. It creates a new process (the child process) by duplicating the state of the existing process with a few minor differences (discussed below). The child process does not start from main. Instead it returns from fork() just as the parent process does.Just as a side remark, in older UNIX systems, the entire address space of the parent process was directly copied (regardless of whether the resource was modified or not). These days, kernel performs copy-on-write, which saves a lot of resources, while being very time efficient.What is the simplest fork() example?Here’s a very simple example…printf(\"I'm printed once!\\n\");fork();// Now there are two processes running// and each process will print out the next line.printf(\"You see this line twice!\\n\");Why does this example print 42 twice?The following program prints out 42 twice - but the fork() is after the printf!? Why?#include &lt;unistd.h&gt; /*fork declared here*/#include &lt;stdio.h&gt; /* printf declared here*/int main() {   int answer = 84 &gt;&gt; 1;   printf(\"Answer: %d\", answer);   fork();   return 0;}The printf line is executed only once however notice that the printed contents is not flushed to standard out (there’s no newline printed, we didn’t call fflush, or change the buffering mode).The output text is therefore still in process memory waiting to be sent.When fork() is executed the entire process memory is duplicated including the buffer. Thus the child process starts with a non-empty output buffer which will be flushed when the program exits.How do you write code that is different for the parent and child process?Check the return value of fork().If fork() returns -1, that implies something went wrong in the process of creating a new child. One should check the value stored in errno to determine what kind of error occurred; commons one include EAGAIN and ENOMEM (check this page to get a description of the errors).Similarly, a return value of 0 indicates that we are in the child process, while a positive integer shows that we are in parent process. The positive value returned by fork() gives as the process id (pid) of the child.Here’s one way to remember which is which:The child process can find its parent - the original process that was duplicated -  by calling getppid() - so does not need any additional return information from fork(). The parent process however can only find out the id of the new child process from the return value of fork:pid_t id = fork();if (id == -1) exit(1); // fork failed if (id &gt; 0){ // I'm the original parent and // I just created a child process with id 'id'// Use waitpid to wait for the child to finish} else { // returned zero// I must be the newly made child process}What is a fork bomb ?A ‘fork bomb’ is when you attempt to create an infinite number of processes. A simple example is shown below:while (1) fork();This will often bring a system to a near-standstill as it attempts to allocate CPU time and memory to a very large number of processes that are ready to run. Comment: System administrators don’t like fork-bombs and may set upper limits on the number of processes each user can have or may revoke login rights because it creates a disturbance in the force for other users’ programs. You can also limit the number of child processes created by using setrlimit().fork bombs are not necessarily malicious - they occasionally occur due to student coding errors.Angrave suggests that the Matrix trilogy, where the machine and man finally work together to defeat the multiplying Agent-Smith, was a cinematic plot based on an AI-driven fork-bomb.Waiting and ExecingHow does the parent process wait for the child to finish?Use waitpid (or wait).pid_t child_id = fork();if (child_id == -1) { perror(\"fork\"); exit(EXIT_FAILURE);}if (child_id &gt; 0) {   // We have a child! Get their exit code  int status;   waitpid( child_id, &amp;status, 0 );  // code not shown to get exit status from child} else { // In child ...  // start calculation  exit(123);}Can I make the child process execute another program?Yes. Use one of the exec functions after forking. The exec set of functions replaces the process image with the the process image of what is being called. This means that any lines of code after the exec call are replaced. Any other work you want the child process to do should be done before the exec call.The Wikipedia article does a great job helping you make sense of the names of the exec family.The naming schemes can be shortened like this  The base of each is exec (execute), followed by one or more letters:  e – An array of pointers to environment variables is explicitly passed to the new process image.  l – Command-line arguments are passed individually (a list) to the function.  p – Uses the PATH environment variable to find the file named in the file argument to be executed.  v – Command-line arguments are passed to the function as an array (vector) of pointers.#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt; #include &lt;sys/wait.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int main(int argc, char**argv) {  pid_t child = fork();  if (child == -1) return EXIT_FAILURE;  if (child) { /* I have a child! */    int status;    waitpid(child , &amp;status ,0);    return EXIT_SUCCESS;  } else { /* I am the child */    // Other versions of exec pass in arguments as arrays    // Remember first arg is the program name    // Last arg must be a char pointer to NULL    execl(\"/bin/ls\", \"ls\",\"-alh\", (char *) NULL);    // If we get to this line, something went wrong!    perror(\"exec failed!\");  }}A simpler way to execute another programUse system. Here is how to use it:#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char**argv) {  system(\"ls\");  return 0;}The system call will fork, execute the command passed by parameter and the original parent process will wait for this to finish. This also means that system is a blocking call: The parent process can’t continue until the process started by system exits. This may or may not be useful. Also, system actually creates a shell which is then given the string, which is more overhead than just using exec directly. The standard shell will use the PATH environment variable to search for a filename that matches the command. Using system will usually be sufficient for many simple run-this-command problems but can quickly become limiting for more complex or subtle problems, and it hides the mechanics of the fork-exec-wait pattern so we encourage you to learn and use fork exec and waitpid instead.What is the silliest fork example?A slightly silly example is shown below. What will it print? Try it with multiple arguments to your program.#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(int argc, char **argv) {  pid_t id;  int status;   while (--argc &amp;&amp; (id=fork())) {    waitpid(id,&amp;status,0); /* Wait for child*/  }  printf(\"%d:%s\\n\", argc, argv[argc]);  return 0;}The amazing parallel apparent-O(N) sleepsort is today’s silly winner. First published on 4chan in 2011 . A version of this awful but amusing sorting algorithm is shown below.int main(int c, char **v){        while (--c &gt; 1 &amp;&amp; !fork());        int val  = atoi(v[c]);        sleep(val);        printf(\"%d\\n\", val);        return 0;}Note: The algorithm isn’t actually O(N) because of how the system scheduler works. Though there are parallel algorithms that run in O(log(N)) per process, this is sadly not one of them.What is different in the child process than the parent process?The key differences include:  The process id returned by getpid(). The parent process id returned by getppid().  The parent is notified via a signal, SIGCHLD, when the child process finishes but not vice versa.  The child does not inherit pending signals or timer alarms.For a complete list see the fork man pageDo child processes share open filehandles?Yes! In fact both processes use the same underlying kernel file descriptor. For example if one process rewinds the random access position back to the beginning of the file, then both processes are affected.Both child and parent should close (or fclose) their file descriptors or file handle respectively.How can I find out more?Read the man pages!  fork  exec  waitBack: Processes, Part 1: Introduction |Next: Forking, Part 2: Fork, Exec, Wait"
  },{
    "title": "Forking, Part 2: Fork, Exec, Wait",
    "url": " /wikibook/forking-part-2-fork-exec-wait",
   "content": "The PatternWhat does the following ‘exec’ example do?#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt; // O_CREAT, O_APPEND etc. defined hereint main() {   close(1); // close standard out   open(\"log.txt\", O_RDWR | O_CREAT | O_APPEND, S_IRUSR | S_IWUSR);   puts(\"Captain's log\");   chdir(\"/usr/include\");   // execl( executable,  arguments for executable including program name and NULL at the end)   execl(\"/bin/ls\", /* Remaining items sent to ls*/ \"/bin/ls\", \".\", (char *) NULL); // \"ls .\"   perror(\"exec failed\");   return 0; // Not expected}There’s no error checking in the above code (we assume close,open,chdir etc works as expected).  open: will use the lowest available file descriptor (i.e. 1) ; so standard out now goes to the log file.  chdir : Change the current directory to /usr/include  execl : Replace the program image with /bin/ls and call its main() method  perror : We don’t expect to get here - if we did then exec failed.Subtle forkbomb bugWhat’s wrong with this code#include &lt;unistd.h&gt;#define HELLO_NUMBER 10int main(){    pid_t children[HELLO_NUMBER];    int i;    for(i = 0; i &lt; HELLO_NUMBER; i++){        pid_t child = fork();        if(child == -1){            break;        }        if(child == 0){ //I am the child             execlp(\"ehco\", \"echo\", \"hello\", NULL);        }        else{            children[i] = child;        }    }    int j;    for(j = 0; j &lt; i; j++){        waitpid(children[j], NULL, 0);    }    return 0;}We misspelled ehco, so we can’t exec it. What does this mean? Instead of creating 10 processes we just created 2**10 processes, fork bombing our machine. How could we prevent this? Put an exit right after exec so in case exec fails we won’t end up fork bombing our machine.What does the child inherit from the parent?  Open file handles. If the parent later seeks, say, to the back to the beginning of the file then this will affect the child too (and vice versa).  Signal handlers  Current working directory  Environment variablesSee the fork man page for more details.What is different in the child process than the parent process?The process id is different. In the child calling getppid() (notice the two ‘p’s) will give the same result as calling getpid() in the parent. See the fork man page for more details.How do I wait for my child to finish?Use waitpid or wait. The parent process will pause until wait (or waitpid) returns. Note this explanation glosses over the restarting discussion.What is the fork-exec-wait patternA common programming pattern is to call fork followed by exec and wait. The original process calls fork, which creates a child process. The child process then uses exec to start execution of a new program. Meanwhile the parent uses wait (or waitpid) to wait for the child process to finish.See below for a complete code example.How do I start a background process that runs at the same time?Don’t wait for them! Your parent process can continue to execute code without having to wait for the child process. Note in practice background processes can also be disconnected from the parent’s input and output streams by calling close on the open file descriptors before calling exec.However child processes that finish before their parent finishes can become zombies. See the zombie page for more information.ZombiesGood parents don’t let their children become zombies!Note, the word ‘zombie’ in this instance sheds some light as to what they actually represent. When a child finishes (or terminates) it still takes up a slot in the kernel process table. Furthermore, they still contain information about the process that got terminated, such as process id, exit status, etc. (i.e. a skeleton of the original process still remains).Only when the child has been ‘waited on’ will the slot be available and the remaining information can be accessed by the parent.A long running program could create many zombies by continually creating processes and never wait-ing for them.What would be effect of too many zombies?Eventually there would be insufficient space in the kernel process table to create a new processes. Thus fork() would fail and could make the system difficult / impossible to use - for example just logging in requires a new process!What does the system do to help prevent zombies?Once a process completes, any of its children will be assigned to “init” - the first process with pid of 1. Thus these children would see getppid() return a value of 1. These orphans will eventually finish and for a brief moment become a zombie. Fortunately, the init process automatically waits for all of its children, thus removing these zombies from the system.How do I prevent zombies? (Warning: Simplified answer)Wait on your child!waitpid(child, &amp;status, 0); // Clean up and wait for my child process to finish.Note we assume that the only reason to get a SIGCHLD event is that a child has finished (this is not quite true - see man page for more details).A robust implementation would also check for interrupted status and include the above in a loop.Read on for a discussion of a more robust implementation.How can I asynchronously wait for my child using SIGCHLD? (ADVANCED)Warning: This section uses signals which we have not yet fully introduced.The parent gets the signal SIGCHLD when a child completes, so the signal handler can wait on the process. A slightly simplified version is shown below.pid_t child;void cleanup(int signal) {  int status;  waitpid(child, &amp;status, 0);  write(1,\"cleanup!\\n\",9);}int main() {   // Register signal handler BEFORE the child can finish   signal(SIGCHLD, cleanup); // or better - sigaction   child = fork();   if (child == -1) { exit(EXIT_FAILURE);}   if (child == 0) { /* I am the child!*/     // Do background stuff e.g. call exec      } else { /* I'm the parent! */      sleep(4); // so we can see the cleanup      puts(\"Parent is done\");   }   return 0;} The above example however misses a couple of subtle points:  More than one child may have finished but the parent will only get one SIGCHLD signal (signals are not queued)  SIGCHLD signals can be sent for other reasons (e.g. a child process is temporarily stopped)A more robust code to reap zombies is shown below.void cleanup(int signal) {  int status;  while (waitpid((pid_t) (-1), 0, WNOHANG) &gt; 0) {}}So what are environment variables?Environment variables are variables that the system keeps for all processes to use. Your system has these set up right now! In Bash, you can check some of these$ echo $HOME/home/bhuvy$ echo $PATH/usr/local/sbin:/usr/bin:...How would you get these in C/C++? You can use the getenv and setenv functionchar* home = getenv(\"HOME\"); // Will return /home/bhuvysetenv(\"HOME\", \"/home/bhuvan\", 1 /*set overwrite to true*/ );Right, so how do these environment variables mean anything to parent/child?Well each process gets its own dictionary of environment variables that are copied over to the child. Meaning, if the parent changes their environment variables it won’t be transferred to the child and vice versa. This is important in the fork-exec-wait trilogy if you want to exec a program with different environment variables than your parent (or any other process).For example, you can write a C program that loops through all of the time zones and executes the date command to print out the date and time in all locals. Environment variables are used for all sorts of programs so modifying them is important.Back: Forking, Part 1: Introduction |Next: Process Control, Part 1: Wait macros, using signals"
  },{
    "title": "Home",
    "url": " /wikibook/home",
   "content": "Welcome to Angrave’s crowd-sourced System Programming wiki-book!This wiki is being built by students and faculty from the University of Illinois and is a crowd-source authoring experiment by Lawrence Angrave from CS @ Illinois.This book is an introduction to programming in C, and system programming (processes, threads, synchronization, networking and more!). We assume you’ve already had some programming experience, in an earlier computer science course.0. Introduction (resources for UIUC students)  HW0  Lecture Code and handouts  Informal Glossary  #Piazza: When And How to Ask For Help  Programming Tricks, Part 1  System Programming Short Stories and Songs  Systems Programming Bugs in Industry1. Learning C  C Programming, Part 1: Introduction  C Programming, Part 2: Text Input And Output          Printing to/Reading from Streams      Parsing Input        C Programming, Part 3: Common Gotchas          Memory Mistakes      Logic/Programming Flow      Other Gotchas        C Programming, Part 4: Strings and Structs          Strings      Structs        C Programming, Part 5: Debugging          In Code Debugging      Valgrind      Tsan      GDB        C Programming, Review Questions2. Processes  Kernel, Shells, Terminals Oh My!  Processes, Part 1: Introduction          Overview      Process Contents      Bonus: More Contents        Forking, Part 1: Introduction          Introduction      Waiting and Execing        Forking, Part 2: Fork, Exec, Wait          The Pattern      Zombies        Process Control, Part 1: Wait macros, using signals          Wait Macros      Signals        Processes Review Questions3. Memory and Allocators  Memory, Part 1: Heap Memory Introduction          C Dynamic Memory Allocation      Introduction to Allocating        Memory, Part 2: Implementing a Memory Allocator          Memory Allocator Tutorial        Memory, Part 3: Smashing the Stack Example  Memory Review Questions4. Intro to Pthreads  Pthreads, Part 1: Introduction          Intro to Threads      Simple Pthreads        Pthreads, Part 2: Usage in Practice          More pthread Functions      Intro to Race Conditions        Pthreads, Part 3: Parallel Problems (Bonus)  Pthread Review Questions5. Synchronization  Synchronization, Part 1: Mutex Locks          Solving Critical Sections      Mutex Gotchas        Synchronization, Part 2: Counting Semaphores  Synchronization, Part 3: Working with Mutexes And Semaphores          Thread Safe Stack      Stack Semaphores        Synchronization, Part 4: The Critical Section Problem          Candidate Solutions      Working Solutions      Hardware Solutions        Synchronization, Part 5: Condition Variables          Intro To Condition Variables      Implementing a Counting Semaphore        Synchronization, Part 6: Implementing a barrier  Synchronization, Part 7: The Reader Writer Problem  Synchronization, Part 8: Ring Buffer Example  Synchronization, Part 9: Synchronization Across Processes  Synchronization Review Questions6. Deadlock  Deadlock, Part 1: Resource Allocation Graph  Deadlock, Part 2: Deadlock Conditions  Deadlock, Part 3: Dining Philosophers          Failed Solutions      Viable Solutions        Deadlock Review Questions7. Inter-process Communication &amp; Scheduling  Virtual Memory, Part 1: Introduction to Virtual Memory          What is Virtual Memory?      Advanced Frames and Protections        Pipes, Part 1: Introduction to pipes  Pipes, Part 2: Pipe programming secrets          Pipe Gotchas      Named Pipes        Files, Part 1: Working with files  Scheduling, Part 1: Scheduling Processes          Thinking about Scheduling      Measures of Efficiency        Scheduling, Part 2: Scheduling Processes: Algorithms  IPC Review Questions8. Networking  POSIX, Part 1: Error handling  Networking, Part 1: Introduction  Networking, Part 2: Using getaddrinfo  Networking, Part 3: Building a simple TCP Client  Networking, Part 4: Building a simple TCP Server  Networking, Part 5: Shutting down ports, reusing ports and other tricks  Networking, Part 6: Creating a UDP server  Networking, Part 7: Nonblocking I O, select(), and epoll  Networking, Part 8: Protocols (TCP Handshaking, HTTP latency, Heart Bleed)  RPC, Part 1: Introduction to Remote Procedure Calls  Networking Review Questions9. File Systems  File System, Part 1: Introduction          Navigation/Terminology      What’s a File System?        File System, Part 2: Files are inodes  File System, Part 3: Permissions  File System, Part 4: Working with directories  File System, Part 5: Virtual file systems  File System, Part 6: Memory mapped files and Shared memory  File System, Part 7: Scalable and Reliable Filesystems          Reliability with a Single Disk      Redundancy        File System, Part 8: Removing preinstalled malware from an Android device  File System, Part 9: Disk blocks example  File Systems Review Questions10. Signals  Process Control, Part 1: Wait macros, using signals          Wait Macros      Signals        Signals, Part 2: Pending Signals and Signal Masks          Signals in Depth      Disposition in Threads/Children        Signals, Part 3: Raising signals  Signals, Part 4: Sigaction  Signals Review Questions11. Distributed Computing  Introduction to Distributed ComputingUIUC Exam Practice QuestionsWarning these are good practice but not comprehensive. The UIUC CS241 final assumes you fully understand and can apply all topics of the course. Questions will focus mostly but not entirely on topics that you have used in the lab and programming assignments.  Exam Topics  C Programming: Review Questions  [[Multi-threaded Programming: Review Questions]]  Synchronization Concepts: Review Questions  Memory: Review Questions  Pipe: Review Questions  Filesystem: Review Questions  Networking: Review Questions  Signals: Review Questions  System Programming Jokes"
  },{
    "title": "HW0",
    "url": " /wikibook/hw0",
   "content": "Welcome!// First, can you guess which lyrics have been transformed into this C-like system code?char q[] = \"Do you wanna build a C99 program?\";#define or \"go debugging with gdb?\"static unsigned int i = sizeof(or) != strlen(or);char* ptr = \"lathe\"; size_t come = fprintf(stdout,\"%s door\", ptr+2);int away = ! (int) * \"\";int* shared = mmap(NULL, sizeof(int*), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);munmap(shared,sizeof(int*));if(!fork()) { execlp(\"man\",\"man\",\"-3\",\"ftell\", (char*)0); perror(\"failed\"); }if(!fork()) { execlp(\"make\",\"make\", \"snowman\", (char*)0); execlp(\"make\",\"make\", (char*)0)); }exit(0);So you want to master System Programming? And get a better grade than B?int main(int argc, char** argv) {\tputs(\"Great! We have plenty of useful resources for you, but it's up to you to\");\tputs(\" be an active learner and learn how to solve problems and debug code.\");\tputs(\"Bring your near-completed answers the problems below\");\tputs(\" to the first lab to show that you've been working on this.\");\tprintf(\"A few \\\"don't knows\\\" or \\\"unsure\\\" is fine for lab 1.\\n\"); \tputs(\"Warning: you and your peers will work hard in this class.\");\tputs(\"This is not CS225; you will be pushed much harder to\");\tputs(\" work things out on your own.\");\tfprintf(stdout,\"This homework is a stepping stone to all future assignments.\\n\");\tchar p[] = \"So, you will want to clear up any confusions or misconceptions.\\n\";\twrite(1, p, strlen(p) );\tchar buffer[1024];\tsprintf(buffer,\"For grading purposes, this homework 0 will be graded as part of your lab %d work.\\n\", 1);\twrite(1, buffer, strlen(buffer));\tprintf(\"Press Return to continue\\n\");\tread(0, buffer, sizeof(buffer));\treturn 0;}Watch the videos and write up your answers to the following questionsImportant!The virtual machine-in-your-browser and the videos you need for HW0 are here:http://cs-education.github.io/sys/The course wikibook:https://github.com/angrave/SystemProgramming/wikiQuestions? Comments? Use Piazza:https://piazza.com/illinois/fall2018/cs241The in-browser virtual machine runs entirely in Javascript and is fastest in Chrome. Note the VM and any code you write is reset when you reload the page, so copy your code to a separate document. The post-video challenges (e.g. Haiku poem) are not part of homework 0 but you learn the most by doing (rather than just passively watching) - so we suggest you have some fun with each end-of-video challenge.HW0 questions are below. Copy your answers into a text document sd you’ll need to submit them later in the course.Chapter 1In which our intrepid hero battles standard out, standard error, file descriptors and writing to filesHello, World! (system call style)  Write a program that uses write() to print out “Hi! My name is &lt;Your Name&gt;”.    Hello, Standard Error Stream!    Write a function to print out a triangle of height n to standard error.          Your function should have the signature void write_triangle(int n) and should use write().      The triangle should look like this, for n = 3:        ******        Writing to files              Take your program from “Hello, World!” modify it write to a file called hello_world.txt.          Make sure to to use correct flags and a correct mode for open() (man 2 open is your friend).        Not everything is a system call              Take your program from “Writing to files” and replace write() with printf().          Make sure to print to the file instead of standard out!        What are some differences between write() and printf()?Chapter 2Sizing up C types and their limits, int and char arrays, and incrementing pointersNot all bytes are 8 bits?  How many bits are there in a byte?  How many bytes are there in a char?  How many bytes the following are on your machine?          int, double, float, long, and long long        Follow the int pointer              On a machine with 8 byte integers:    int main(){ int data[8];}     If the address of data is 0x7fbd9d40, then what is the address of data+2?    What is data[3] equivalent to in C?          Hint: what does C convert data[3] to before dereferencing the address?      sizeof character arrays, incrementing pointersRemember, the type of a string constant \"abc\" is an array.  Why does this segfault?    char *ptr = \"hello\";*ptr = 'J';    What does sizeof(\"Hello\\0World\") return?  What does strlen(\"Hello\\0World\") return?  Give an example of X such that sizeof(X) is 3.  Give an example of Y such that sizeof(Y) might be 4 or 8 depending on the machine.Chapter 3Program arguments, environment variables, and working with character arrays (strings)Program arguments, argc, argv  What are two ways to find the length of argv?  What does argv[0] represent?    Environment Variables    Where are the pointers to environment variables stored (on the stack, the heap, somewhere else)?    String searching (strings are just char arrays)    On a machine where pointers are 8 bytes, and with the following code:    char *ptr = \"Hello\";char array[] = \"Hello\";    What are the values of sizeof(ptr) and sizeof(array)? Why?  Lifetime of automatic variables  What data structure manages the lifetime of automatic variables?Chapter 4Heap and stack memory, and working with structsMemory allocation using malloc, the heap, and time  If I want to use data after the lifetime of the function it was created in ends, where should I put it? How do I put it there?  What are the differences between heap and stack memory?  Are there other kinds of memory in a process?  Fill in the blank: “In a good C program, for every malloc, there is a ___”.    Heap allocation gotchas    What is one reason malloc can fail?  What are some differences between time() and ctime()?  What is wrong with this code snippet?    free(ptr);free(ptr);    What is wrong with this code snippet?    free(ptr);printf(\"%s\\n\", ptr);    How can one avoid the previous two mistakes?    struct, typedefs, and a linked list    Create a struct that represents a Person. Then make a typedef, so that struct Person can be replaced with a single word. A person should contain the following information: their name (a string), their age (an integer), and a list of their friends (stored as a pointer to an array of pointers to Persons).  Now, make two persons on the heap, “Agent Smith” and “Sonny Moore”, who are 128 and 256 years old respectively and are friends with each other.    Duplicating strings, memory allocation and deallocation of structures    Create functions to create and destroy a Person (Person’s and their names should live on the heap).    create() should take a name and age. The name should be copied onto the heap. Use malloc to reserve sufficient memory for everyone having up to ten friends. Be sure initialize all fields (why?).  destroy() should free up not only the memory of the person struct, but also free all of its attributes that are stored on the heap. Destroying one person should not destroy any others.Chapter 5Text input and output and parsing using getchar, gets, and getline.Reading characters, trouble with gets  What functions can be used for getting characters from stdin and writing them to stdout?  Name one issue with gets().    Introducing sscanf and friends    Write code that parses the string “Hello 5 World” and initializes 3 variables to “Hello”, 5, and “World”.    getline is useful    What does one need to define before including getline()?  Write a C program to print out the content of a file line-by-line using getline().C DevelopmentThese are general tips for compiling and developing using a compiler and git. Some web searches will be useful here  What compiler flag is used to generate a debug build?  You modify the Makefile to generate debug builds and type make again. Explain why this is insufficient to generate a new build.  Are tabs or spaces used to indent the commands after the rule in a Makefile?  What does git commit do? What’s a sha in the context of git?  What does git log show you?  What does git status tell you and how would the contents of .gitignore change its output?  What does git push do? Why is it not just sufficient to commit with git commit -m 'fixed all bugs' ?  What does a non-fast-forward error git push reject mean? What is the most common way of dealing with this?Optional (Just for fun)  Convert your a song lyrics into System Programming and C code covered in this wiki book and share on Piazza.  Find, in your opinion, the best and worst C code on the web and post the link to Piazza.  Write a short C program with a deliberate subtle C bug and post it on Piazza to see if others can spot your bug.  Do you have any cool/disastrous system programming bugs you’ve heard about? Feel free to share with your peers and the course staff on piazza."
  },{
    "title": "Informal Glossary",
    "url": " /wikibook/informal-glossary",
   "content": "Warning: Unlike a full length glossary, this informal glossary skips on details and provides a simplified and accessible explanation of each term. For more information and details use your favorite web search engine.What is the kernel?The kernel is central part of the operating system that manages processes, resources (including memory) and hardware input-output devices. User programs interact with the kernel by making system calls.Learn more:[[http://en.wikipedia.org/wiki/Kernel_%28operating_system%29]]What is a process?A process is an instance of a program that is running on a machine. There can be multiple processes of the same program. For example, you and I might both be running ‘cat’ or ‘gnuchess’A process contains the program code and modifiable state information such as variables, signals, open file descriptors for files, network connections and other system resources which are stored inside the process’s memory. An operating system also stores meta-information about the process which is used by the system to manage and monitor the process’s activity and resource use.Learn more:[[http://en.wikipedia.org/wiki/Process_%28computing%29]]What is virtual memory?Processes running on your smart phone and laptop use virtual memory: Each process is isolated from other processes and appears to get complete access to all possible memory addresses! In reality only a small fraction of the process’s address space is mapped to physical memory and the actual amount of physical memory allocated to a process can change over time and be paged out to disk, re-mapped and securely shared with other processes. Virtual memory provides significant benefits including strong process isolation (security), resource and performance benefits (simplified and efficient physical memory use) that we will discuss later.Learn more:[[http://en.wikipedia.org/wiki/Virtual_memory]]"
  },{
    "title": "Introduction to Distributed Computing",
    "url": " /wikibook/introduction-to-distributed-computing",
   "content": "An introduction to Distributed Computing will be added to the course in Fall 2018What is Distributed Computing?Distributed computing studies efficient use of physically separate computational systems.Simple distributed computing problems might span just a handful machines or even millions of platforms. For example, you might run your interactive 3D simulation on a remote machine, store your world data on another server and wonder if you can improve the latency of your Virtual Reality experience.  Or you might create a highly parallel search algorithm, where each compute node independently models and searches for the lowest energy configuration of a protein molecule, and then wonder how to best use the world’s spare computation and network capacity to run your search algorithm. Though these are examples of computing span multiple machines, the field of “Distributed Computing” is even more complex and interesting than these “simple” problems.Distributed Computing is interesting for the very same reasons that make it difficult! So far in this system programming book we’ve already introduced three core areas - concurrency, networking and data flow, fault-tolerant computing and communication - that are foundational in many Distributed Computing problems. The distributed part however also means we need to study messaging, coordination and synchronicity (timing) between our systems and how we can best partition the computation and data of a particular kind of computing problem across multiple systems that are physically separated. We can also develop and evaluate algorithms and protocols that use distributed computing resources efficiently (or not!). For this we will also need to decide what are the important details that we need to include in our theoretical mode of our distributed system."
  },{
    "title": "IPC Review Questions",
    "url": " /wikibook/ipc-review-questions",
   "content": "TopicsVirtual MemoryPage TableMMU/TLBAddress TranslationPage FaultsFrames/PagesSingle level vs multi level page tableCalculating offsets for multi-level page tablePipesPipe read write endsWriting to a zero reader pipeReading from a zero writer pipeNamed pipe and Unnamed PipesBuffer Size/AtomicityScheduling AlgorithmsMeasures of EfficiencyQuestions  What is virtual memory?  What are the following and what is their purpose?          Translation Lookaside Buffer      Physical Address      Memory Management Unit. Multilevel page table. Frame number. Page number and page offset.      The dirty bit      The NX Bit        What is a page table? How about a physical frame? Does a page always need to point to a physical frame?  What is a page fault? What are the types? When does it result in a segfault?  What are the advantages to a single level page table? Disadvantages? How about a multi leveled table?  What does a multi leveled table look like in memory?  How do you determine how many bits are used in the page offset?  Given a 64 bit address space, 4kb pages and frames, and a 3 level page table, how many bits is the Virtual page number 1, VPN2, VPN3 and the offset?  What is a pipe? How do I create a pipe?  When is SIGPIPE delivered to a process?  Under what conditions will calling read() on a pipe block? Under what conditions will read() immediately return 0  What is the difference between a named pipe and an unnamed pipe?  Is a pipe thread safe?  Write a function that uses fseek and ftell to replace the middle character of a file with an ‘X’  Write a function that create a pipe and uses write to send 5 bytes, “HELLO” to the pipe. Return the read file descriptor of the pipe.  What happens when you mmap a file?  Why is getting the file size with ftell not recommended? How should you do it instead?  What is scheduling?  What is turnaround time? Response Time? Wait time?  What is the convoy effect?  Which algorithms have the best turnaround/response/wait time on average"
  },{
    "title": "Kernel, Shells, Terminals Oh My!",
    "url": " /wikibook/kernel-shells-terminals-oh-my!",
   "content": "KernelsThe operating system kernel is a special piece of software. This is the piece of software that is loaded up before all of your other programs even consider getting booted up. What the kernel does is the following, abbreviated  The operating system executes ROM or read only code  The operating system then executes a boot_loader or EFI extensions nowadays  The boot_loader loads your kernels  Your kernel executes init to bootstrap itself from nothing  The kernel executes start up scripts  The kernel executes userland scripts, and you get to use your computer!You don’t need to know the specifics of the booting process, but there it is. When you are executing in user space the kernel provides some important operations that programs don’t have to worry about.  Scheduling Processes and threads; in addition, handling synchronization primitives  Providing System Calls like write or read  Manages virtual memory and low level binary devices like usb drivers  Handles reading and understanding a filesystem  Handles communicating over networks  Handles communications with other processes  Dynamically linking librariesThe kernel handles all of this stuff in kernel mode. Kernel mode gets you greater power, like executing extra CPU instructions but at the cost of one failure crashes your entire computer – ouch. That is what you are going to interacting with in this class.File DescriptorsOne of the things that you have already become familiar with is that the kernel gives you file descriptors when you open text files. Here is a zine from Julia Evans that details it a bit.As the little zine shows, the Kernel keeps track of the file descriptors and what they point to. We will see later that file descriptors need not point to actual files and the OS keeps track of them for you. Also, notice that between processes file descriptors may be reused but inside of a process they are unique.File descriptors also have a notion of position. You can read a file on disk completely because the OS keeps track of the position in the file, and that belongs to your process as well.Cool, what’s a shell then?A shell is actually how you are going to be interacting with the kernel. Before User Friendly operating systems, when a computer started up all you had access to was a shell. This meant that all of your commands and editing had to be done this way. Nowadays, our computers start up in desktop mode, but one can still access a shell using a terminal. When you open one up you should see something like this(Stuff) $It is ready for your next command! You can type in a lot of unix utilities like ls, echo Hello and the shell will execute them and give you the result. Some of these are what are known as shell-builtins meaning that the code is in the shell program itself. Some of these are compiled programs that you run. The shell only looks through a special variable called path which contains a list of : separated paths to search for an executable with your name, here is an example path.$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/gamesSo when the shell executes ls, it looks through all of those directories, finds /bin/ls and executes that.$ ls...$ /bin/lsYou can always call through the full path. That is always why in past classes if you want to run something on the terminal you’ve had to do ./exe because typically the directory that you are working in is not in the PATH variable. The . expands to your current directory and your shell executes &lt;current_dir&gt;/exe which is a valid command.Shell tricks and tips  The up arrow will get you your most recent command  ctrl-r will search commands that you previously ran  ctrl-c will interrupt your shell’s process  Add more!Alright then what’s a terminal?A terminal is just an application that displays the output form the shell. You can have your default terminal, a quake based terminal, terminator, the options are endless!"
  },{
    "title": "Memory, Part 1: Heap Memory Introduction",
    "url": " /wikibook/memory-part-1-heap-memory-introduction",
   "content": "C Dynamic Memory AllocationWhat happens when I call malloc?The function malloc is a C library call and is used to reserve a contiguous block of memory. Unlike stack memory, the memory remains allocated until free is called with the same pointer. There is also calloc and realloc which are discussed below.Can malloc fail?If malloc fails to reserve any more memory then it returns NULL. Robust programs should check the return value. If your code assumes malloc succeeds and it does not, then your program will likely crash (segfault) when it tries to write to address 0.Where is the heap and how big is it?The heap is part of the process memory and it does not have a fixed size. Heap memory allocation is performed by the C library when you call malloc (calloc, realloc) and free.First a quick review on process memory: A process is a running instance of your program. Each process has its own address space. For example on a 32 bit machine your process gets about 4 billion addresses to play with, however not all of these are valid or even mapped to actual physical memory (RAM). Inside the process’s memory you will find the executable code, space for the stack, environment variables, global (static) variables and the heap.By calling sbrk the C library can increase the size of the heap as your program demands more heap memory. As the heap and stack (one for each thread) need to grow, we put them at opposite ends of the address space. So for typical architectures the heap will grow upwards and the stack grows downwards.Truthiness: Modern operating system memory allocators no longer need sbrk - instead they can request independent regions of virtual memory and maintain multiple memory regions. For example gigabyte requests may be placed in a different memory region than small allocation requests. However this detail is an unwanted complexity: The problems of fragmentation and allocating memory efficiently still apply, so we will ignore this implementation nicety here and will write as if the heap is a single region.If we write a multi-threaded program (more about that later) we will need multiple stacks (one per thread) but there’s only ever one heap.On typical architectures, the heap is part of the Data segment and starts just above the code and global variables.Do programs need to call brk or sbrk?Not typically (though calling sbrk(0) can be interesting because it tells you where your heap currently ends). Instead programs use malloc,calloc,realloc and free which are part of the C library. The internal implementation of these functions will call sbrk when additional heap memory is required.void *top_of_heap = sbrk(0);malloc(16384);void *top_of_heap2 = sbrk(0);printf(\"The top of heap went from %p to %p \\n\", top_of_heap, top_of_heap2);Example output: The top of heap went from 0x4000 to 0xa000What is calloc?Unlike malloc, calloc initializes memory contents to zero and also takes two arguments (the number of items and the size in bytes of each item). A naive but readable implementation of calloc looks like this:void *calloc(size_t n, size_t size){\tsize_t total = n * size; // Does not check for overflow!\tvoid *result = malloc(total);\t\tif (!result) return NULL;\t// If we're using new memory pages // just allocated from the system by calling sbrk// then they will be zero so zero-ing out is unnecessary,\tmemset(result, 0, total);\treturn result; }An advanced discussion of these limitations is here.Programmers often use calloc rather than explicitly calling memset after malloc, to set the memory contents to zero. Note calloc(x,y) is identical to calloc(y,x), but you should follow the conventions of the manual.// Ensure our memory is initialized to zerolink_t *link  = malloc(256);memset(link, 0, 256); // Assumes malloc returned a valid address!link_t *link = calloc(1, 256); // safer: calloc(1, sizeof(link_t));Why is the memory that is first returned by sbrk initialized to zero?If the operating system did not zero out contents of physical RAM it might be possible for one process to learn about the memory of another process that had previously used the memory. This would be a security leak.Unfortunately this means that for malloc requests before any memory has been freed and simple programs (which end up using newly reserved memory from the system) the memory is often zero. Then programmers mistaken write C programs that assume malloc’d memory will always be zero.char* ptr = malloc(300);// contents is probably zero because we get brand new memory// so beginner programs appear to work!// strcpy(ptr, \"Some data\"); // work with the datafree(ptr);// laterchar *ptr2 = malloc(308); // Contents might now contain existing data and is probably not zeroWhy doesn’t malloc always initialize memory to zero?Performance! We want malloc to be as fast as possible. Zeroing out memory may be unnecessary.What is realloc and when would you use it?realloc allows you to resize an existing memory allocation that was previously allocated on the heap (via malloc,calloc or realloc). The most common use of realloc is to resize memory used to hold an array of values. A naive but readable version of realloc is suggested belowvoid * realloc(void * ptr, size_t newsize) {  // Simple implementation always reserves more memory  // and has no error checking  void *result = malloc(newsize);   size_t oldsize =  ... //(depends on allocator's internal data structure)  if (ptr) memcpy(result, ptr, newsize &lt; oldsize ? newsize : oldsize);  free(ptr);  return result;}An INCORRECT use of realloc is shown below:int *array = malloc(sizeof(int) * 2);array[0] = 10; array[1] = 20;// Ooops need a bigger array - so use realloc..realloc (array, 3); // ERRORS!array[2] = 30; The above code contains two mistakes. Firstly we needed 3*sizeof(int) bytes not 3 bytes.Secondly realloc may need to move the existing contents of the memory to a new location. For example, there may not be sufficient space because the neighboring bytes are already allocated. A correct use of realloc is shown below.array = realloc(array, 3 * sizeof(int));// If array is copied to a new location then old allocation will be freed.A robust version would also check for a NULL return value. Note realloc can be used to grow and shrink allocations.Where can I read more?See the man page!How important is that memory allocation is fast?Very! Allocating and de-allocating heap memory is a common operation in most applications.Intro to AllocatingWhat is the silliest malloc and free implementation and what is wrong with it?void* malloc(size_t size)// Ask the system for more bytes by extending the heap space. // sbrk Returns -1 on failure   void *p = sbrk(size);    if(p == (void *) -1) return NULL; // No space left   return p;}void free() {/* Do nothing */}The above implementation suffers from two major drawbacks:  System calls are slow (compared to library calls). We should reserve a large amount of memory and only occasionally ask for more from the system.  No reuse of freed memory. Our program never re-uses heap memory - it just keeps asking for a bigger heap.If this allocator was used in a typical program, the process would quickly exhaust all available memory.Instead we need an allocator that can efficiently use heap space and only ask for more memory when necessary.What are placement strategies?During program execution memory is allocated and de-allocated (freed), so there will be gaps (holes) in the heap memory that can be re-used for future memory requests. The memory allocator needs to keep track of which parts of the heap are currently allocated and which are parts are available.Suppose our current heap size is 64K, though not all of it is in use because some earlier malloc’d memory has already been freed by the program:16KB free | 10KB allocated | 1KB free | 1KB allocated | 30KB free | 4KB allocated | 2KB free —|—|—|—|—|—|—If a new malloc request for 2KB is executed (malloc(2048)), where should malloc reserve the memory? It could use the last 2KB hole (which happens to be the perfect size!) or it could split one of the other two free holes. These choices represent different placement strategies.Whichever hole is chosen, the allocator will need to split the hole into two: The newly allocated space (which will be returned to the program) and a smaller hole (if there is spare space left over).A perfect-fit strategy finds the smallest hole that is of sufficient size (at least 2KB):16KB free | 10KB allocated | 1KB free | 1KB allocated | 30KB free | 4KB allocated | ‘2KB HERE!’—|—|—|—|—|—|—A worst-fit strategy finds the largest hole that is of sufficient size (so break the 30KB hole into two):16KB free | 10KB allocated | 1KB free | 1KB allocated | 2KB HERE! | 28KB free | 4KB allocated | 2KB free —|—|—|—|—|—|—|—A first-fit strategy finds the first available hole that is of sufficient size (break the 16KB hole into two):2KB HERE! | 14KB free | 10KB allocated | 1KB free | 1KB allocated | 30KB free | 4KB allocated | 2KB free —|—|—|—|—|—|—|—What is external fragmentation?In the example below, of the 64KB of heap memory, 17KB is allocated, and 47KB is free. However the largest available block is only 30KB because our available unallocated heap memory is fragmented into smaller pieces.16KB free | 10KB allocated | 1KB free | 1KB allocated | 30KB free | 4KB allocated | 2KB free —|—|—|—|—|—|—What effect do placement strategies have on external fragmentation and performance?Different strategies affect the fragmentation of heap memory in non-obvious ways, which only are discovered by mathematical analysis or careful simulations under real-world conditions (for example simulating the memory allocation requests of a database or webserver).For example, best-fit at first glance appears to be an excellent strategy however, if we can not find a perfectly-sized hole then this placement creates many tiny unusable holes, leading to high fragmentation. It also requires a scan of all possible holes.First fit has the advantage that it will not evaluate all possible placements and therefore be faster.Since Worst-fit targets the largest unallocated space, it is a poor choice if large allocations are required.In practice first-fit and next-fit (which is not discussed here) are often common placement strategy. Hybrid approaches and many other alternatives exist (see implementing a memory allocator page).What are the challenges of writing a heap allocator?The main challenges are,  Need to minimize fragmentation (i.e. maximize memory utilization)  Need high performance  Fiddly implementation (lots of pointer manipulation using linked lists and pointer arithmetic)Some additional comments:Both fragmentation and performance depend on the application allocation profile, which can be evaluated but not predicted and in practice, under-specific usage conditions, a special-purpose allocator can often out-perform a general purpose implementation.The allocator doesn’t know the program’s memory allocation requests in advance. Even if we did, this is the Knapsack problem which is known to be NP hard!How do you implement a memory allocator?Good question. Implementing a memory allocator"
  },{
    "title": "Memory, Part 2: Implementing a Memory Allocator",
    "url": " /wikibook/memory-part-2-implementing-a-memory-allocator",
   "content": "Memory Allocator TutorialA memory allocator needs to keep track of which bytes are currently allocated and which are available for use. This page introduces the implementation and conceptual details of building an allocator, i.e. the actual code that implements malloc and free.This page talks about links of blocks - do I malloc memory for them instead?Though conceptually we are thinking about creating linked lists and lists of blocks, we don’t need to “malloc memory” to create them! Instead we are writing integers and pointers into memory that we already control so that we can later consistently hop from one address to the next. This internal information represents some overhead. So even if we had requested 1024 KB of contiguous memory from the system, we will not be able to provide all of it to the running program.Thinking in blocksWe can think of our heap memory as a list of blocks where each block is either allocated or unallocated.Rather than storing an explicit list of pointers we store information about the block’s size as part of the block. Thus there is conceptually a list of free blocks, but it is implicit, i.e. in the form of block size information that we store as part of each block.We could navigate from one block to the next block just by adding the block’s size. For example if you have a pointer p that points to the start of a block, then next_block  with be at ((char *)p) +  *(size_t *) p, if you are storing the size of the blocks in bytes. The cast to char * ensures that pointer arithmetic is calculated in bytes. The cast to size_t * ensures the memory at p is read as a size value and would be necessarily if p was a void * or char * type.The calling program never sees these values; they are internal to the implementation of the memory allocator.As an example, suppose your allocator is asked to reserve 80 bytes (malloc(80)) and requires 8 bytes of internal header data. The allocator would need to find an unallocated space of at least 88 bytes. After updating the heap data it would return a pointer to the block. However, the returned pointer does not point to the start of the block because that’s where the internal size data is stored! Instead we would return the start of the block + 8 bytes.In the implementation, remember that pointer arithmetic depends on type. For example, p += 8 adds 8 * sizeof(p), not necessarily 8 bytes!Implementing mallocThe simplest implementation uses first fit: Start at the first block, assuming it exists, and iterate until a block that represents unallocated space of sufficient size is found, or we’ve checked all the blocks.If no suitable block is found, it’s time to call sbrk() again to sufficiently extend the size of the heap. A fast implementation might extend it a significant amount so that we will not need to request more heap memory in the near future.When a free block is found, it may be larger than the space we need. If so, we will create two entries in our implicit list. The first entry is the allocated block, the second entry is the remaining space.There are two simple ways to note if a block is in use or available. The first is to store it as a byte in the header information along with the size and the second to encode it as the lowest bit in the size!Thus block size information would be limited to only even values:// Assumes p is a reasonable pointer type, e.g. 'size_t *'.isallocated = (*p) &amp; 1;realsize = (*p) &amp; ~1;  // mask out the lowest bitAlignment and rounding up considerationsMany architectures expect multi-byte primitives to be aligned to some multiple of 2^n. For example, it’s common to require 4-byte types to be aligned to 4-byte boundaries (and 8-byte types on 8-byte boundaries). If multi-byte primitives are not stored on a reasonable boundary (for example starting at an odd address) then the performance can be significantly impacted because it may require two memory read requests instead of one. On some architectures the penalty is even greater - the program will crash with a bus error.As malloc does not know how the user will use the allocated memory (array of doubles? array of chars?), the pointer returned to the program needs to be aligned for the worst case, which is architecture dependent.From glibc documentation, the glibc malloc uses the following heuristic:“    The block that malloc gives you is guaranteed to be aligned so that it can hold any type of data. On GNU systems, the address is always a multiple of eight on most systems, and a multiple of 16 on 64-bit systems.”For example, if you need to calculate how many 16 byte units are required, don’t forget to round up -int s = (requested_bytes + tag_overhead_bytes + 15) / 16The additional constant ensures incomplete units are rounded up. Note, real code is more likely to symbol sizes e.g. sizeof(x) - 1, rather than coding numerical constant 15.Here’s a great article on memory alignment, if you are further interestedA note about internal fragmentationInternal fragmentation happens when the block you give them is larger than their allocation size. Let’s say that we have a free block of size 16B (not including metadata). If they allocate 7 bytes, you may want to round up to 16B and just return the entire block.This gets very sinister when you implementing coalescing and splitting (next section). If you don’t implement either, then you may end up returning a block of size 64B for a 7B allocation! There is a lot of overhead for that allocation which is what we are trying to avoid.Implementing freeWhen free is called we need to re-apply the offset to get back to the ‘real’ start of the block (remember we didn’t give the user a pointer to the actual start of the block?), i.e. to where we stored the size information.A naive implementation would simply mark the block as unused. If we are storing the block allocation status in the lowest size bit, then we just need to clear the bit:*p = (*p) &amp; ~1; // Clear lowest bit However, we have a bit more work to do: If the current block and the next block (if it exists) are both free we need to coalesce these blocks into a single block.Similarly, we also need to check the previous block, too. If that exists and represents an unallocated memory, then we need to coalesce the blocks into a single large block.To be able to coalesce a free block with a previous free block we will also need to find the previous block, so we store the block’s size at the end of the block, too. These are called “boundary tags” (ref Knuth73). As the blocks are contiguous, the end of one blocks sits right next to the start of the next block. So the current block (apart from the first one) can look a few bytes further back to lookup the size of the previous block. With this information you can now jump backwards!PerformanceWith the above description it’s possible to build a memory allocator. It’s main advantage is simplicity - at least simple compared to other allocators!Allocating memory is a worst-case linear time operation (search linked lists for a sufficiently large free block) and de-allocation is constant time (no more than 3 blocks will need to be coalesced into a single block). Using this allocator it is possible to experiment with different placement strategies. For example, you could start searching from where you last free’d a block, or where you last allocated from. If you do store pointers to blocks, you need to be very careful that they always remain valid (e.g. when coalescing blocks or other malloc or free calls that change the heap structure)Explicit Free Lists AllocatorsBetter performance can be achieved by implementing an explicit doubly-linked list of free nodes. In that case, we can immediately traverse to the next free block and the previous free block. This can halve the search time, because the linked list only includes unallocated blocks.A second advantage is that we now have some control over the ordering of the linked list. For example, when a block is free’d, we could choose to insert it into the beginning of the linked list rather than always between its neighbors. This is discussed below.Where do we store the pointers of our linked list? A simple trick is to realize that the block itself is not being used and store the next and previous pointers as part of the block (though now you have to ensure that the free blocks are always sufficiently large to hold two pointers).We still need to implement Boundary Tags (i.e. an implicit list using sizes), so that we can correctly free blocks and coalesce them with their two neighbors. Consequently, explicit free lists require more code and complexity.With explicit linked lists a fast and simple ‘Find-First’ algorithm is used to find the first sufficiently large link. However, since the link order can be modified, this corresponds to different placement strategies. For example if the links are maintained from largest to smallest, then this produces a ‘Worst-Fit’ placement strategy.Explicit linked list insertion policyThe newly free’d block can be inserted easily into two possible positions: at the beginning or in address order (by using the boundary tags to first find the neighbors).Inserting at the beginning creates a LIFO (last-in, first-out) policy: The most recently free’d spaces will be reused. Studies suggest fragmentation is worse than using address order.Inserting in address order (“Address ordered policy”) inserts free’d blocks so that the blocks are visited in increasing address order. This policy required more time to free a block because the boundary tags (size data) must be used to find the next and previous unallocated blocks. However, there is less fragmentation.Case study: Buddy Allocator (an example of a segregated list)A segregated allocator is one that divides the heap into different areas that are handled by different sub-allocators dependent on the size of the allocation request. Sizes are grouped into classes (e.g. powers of two) and each size is handled by a different sub-allocator and each size maintains its own free list.A well known allocator of this type is the buddy allocator. We’ll discuss the binary buddy allocator which splits allocation into blocks of size 2^n (n = 1, 2, 3, …) times some base unit number of bytes, but others also exist (e.g. Fibonacci split - can you see why it’s named?). The basic concept is simple: If there are no free blocks of size 2^n, go to the next level and steal that block and split it into two. If two neighboring blocks of the same size become unallocated, they can be coalesced back together into a single large block of twice the size.Buddy allocators are fast because the neighboring blocks to coalesce with can be calculated from the free’d block’s address, rather than traversing the size tags. Ultimate performance often requires a small amount of assembler code to use a specialized CPU instruction to find the lowest non-zero bit.The main disadvantage of the Buddy allocator is that they suffer from internal fragmentation, because allocations are rounded up to the nearest block size. For example, a 68-byte allocation will require a 128-byte block.Further Reading and References  See Foundations of Software Technology and Theoretical Computer Science 1999 proceedings (Google books,page 85)  ThanksForTheMemory UIUC lecture Slides (pptx) (pdf)and  Wikipedia’s buddy memory allocation pageOther allocatorsThere are many other allocation schemes. For example SLUB (wikipedia) - one of three allocators used internally by the Linux Kernel."
  },{
    "title": "Memory, Part 3: Smashing the Stack Example",
    "url": " /wikibook/memory-part-3-smashing-the-stack-example",
   "content": "Each thread uses a stack memory. The stack ‘grows downwards’ - if a function calls another function, then the stack is extended to smaller memory addresses.Stack memory includes non-static automatic (temporary) variables, parameter values and the return address.If a buffer is too small some data (e.g. input values from the user), then there is a real possibility that other stack variables and even the return address will be overwritten.The precise layout of the stack’s contents and order of the automatic variables is architecture and compiler dependent. However with a little investigative work we can learn how to deliberately smash the stack for a particular architecture.The example below demonstrates how the return address is stored on the stack. For a particular 32 bit architecture Live Linux Machine, we determine that the return address is stored at an address two pointers (8 bytes) above the address of the automatic variable. The code deliberately changes the stack value so that when the input function returns, rather than continuing on inside the main method, it jumps to the exploit function instead.// Overwrites the return address on the following machine:// http://cs-education.github.io/sys/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;void breakout() {    puts(\"Welcome. Have a shell...\");    system(\"/bin/sh\");}void input() {  void *p;  printf(\"Address of stack variable: %p\\n\", &amp;p);  printf(\"Something that looks like a return address on stack: %p\\n\", *((&amp;p)+2));  // Let's change it to point to the start of our sneaky function.  *((&amp;p)+2) = breakout;}int main() {    printf(\"main() code starts at %p\\n\",main);        input();    while (1) {        puts(\"Hello\");        sleep(1);    }    return 0;}There are a lot of ways that computers tend to get around this."
  },{
    "title": "Memory: Review Questions",
    "url": " /wikibook/memory-review-questions",
   "content": "  Question numbers subject to changeQ1What are the following and what is their purpose?  Translation Lookaside Buffer  Physical Address  Memory Management Unit  The dirty bitQ2How do you determine how many bits are used in the page offset?Q320 ms after a context switch the TLB contains all logical addresses used by your numerical code which performs main memory access 100% of the time. What is the overhead (slowdown) of a two-level page table compared to a single-level page table?Q4Explain why the TLB must be flushed when a context switch occurs (i.e. the CPU is assigned to work on a different process)."
  },{
    "title": "Multi threaded Programming: Review Questions",
    "url": " /wikibook/multi-threaded-programming-review-questions",
   "content": "  Warning - question numbers subject to changeQ1Is the following code thread-safe? Redesign the following code to be thread-safe. Hint: A mutex is unnecessary if the message memory is unique to each call.static char message[20];pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;void *format(int v) {  pthread_mutex_lock(&amp;mutex);  sprintf(message, \":%d:\" ,v);  pthread_mutex_unlock(&amp;mutex);  return message;}Q2Which one of the following does not cause a process to exit?  Returning from the pthread’s starting function in the last running thread.  The original thread returning from main.  Any thread causing a segmentation fault.  Any thread calling exit.  Calling pthread_exit in the main thread with other threads still running.Q3Write a mathematical expression for the number of “W” characters that will be printed by the following program. Assume a,b,c,d are small positive integers. Your answer may use a ‘min’ function that returns its lowest valued argument.unsigned int a=...,b=...,c=...,d=...;void* func(void* ptr) {  char m = * (char*)ptr;  if(m == 'P') sem_post(s);  if(m == 'W') sem_wait(s);  putchar(m);  return NULL;}int main(int argv, char** argc) {  sem_init(s,0, a);  while(b--) pthread_create(&amp;tid, NULL, func, \"W\");   while(c--) pthread_create(&amp;tid, NULL, func, \"P\");   while(d--) pthread_create(&amp;tid, NULL, func, \"W\");   pthread_exit(NULL);   /*Process will finish when all threads have exited */}Q4Complete the following code. The following code is supposed to print alternating A and B. It represents two threads that take turns to execute.  Add condition variable calls to func so that the waiting thread does not need to continually check the turn variable. Q: Is pthread_cond_broadcast necessary or is pthread_cond_signal sufficient?pthread_cond_t cv = PTHREAD_COND_INITIALIZER;pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;void* turn;void* func(void* mesg) {  while(1) {// Add mutex lock and condition variable calls ...    while(turn == mesg) {         /* poll again ... Change me - This busy loop burns CPU time! */     }    /* Do stuff on this thread */    puts( (char*) mesg);    turn = mesg;      }  return 0;}int main(int argc, char** argv){  pthread_t tid1;  pthread_create(&amp;tid1, NULL, func, \"A\");  func(\"B\"); // no need to create another thread - just use the main thread  return 0;}Q5Identify the critical sections in the given code. Add mutex locking to make the code thread safe. Add condition variable calls so that total never becomes negative or above 1000. Instead the call should block until it is safe to proceed. Explain why pthread_cond_broadcast is necessary.int total;void add(int value) { if(value &lt; 1) return; total += value;}void sub(int value) { if(value &lt; 1) return; total -= value;}Q6A non-threadsafe data structure has size() enq and deq methods. Use condition variable and mutex lock to complete the thread-safe, blocking versions.void enqueue(void* data) {  // should block if the size() would become greater than 256  enq(data);}void* dequeue() {  // should block if size() is 0  return deq();}Q7Your startup offers path planning using latest traffic information. Your overpaid intern has created a non-threadsafe data structure with two functions: shortest (which uses but does not modify the graph) and set_edge (which modifies the graph).graph_t* create_graph(char* filename); // called once// returns a new heap object that is the shortest path from vertex i to jpath_t* shortest(graph_t* graph, int i, int j); // updates edge from vertex i to jvoid set_edge(graph_t* graph, int i, int j, double time);   For performance, multiple threads must be able to call shortest at the same time but the graph can only be modified by one thread when no threads other are executing inside shortest or set_edge.Use mutex lock and condition variables to implement a reader-writer solution. An incomplete attempt is shown below. Though this attempt is threadsafe (thus sufficient for demo day!), it does not allow multiple threads to calculate shortest path at the same time and will not have sufficient throughput.path_t* shortest_safe(graph_t* graph, int i, int j) {  pthread_mutex_lock(&amp;m);  path_t* path = shortest(graph, i, j);  pthread_mutex_unlock(&amp;m);  return path;}void set_edge_safe(graph_t* graph, int i, int j, double dist) {  pthread_mutex_lock(&amp;m);  set_edge(graph, i, j, dist);  pthread_mutex_unlock(&amp;m);}"
  },{
    "title": "Networking, Part 1: Introduction",
    "url": " /wikibook/networking-part-1-introduction",
   "content": "Caveat: It should be obvious that  page is not a complete description of IP, UDP or TCP! Instead it is a short introduction and is sufficient so that we can build upon these concepts in later lectures.What is “IP4” “IP6”?The following is the “30 second” introduction to internet protocol (IP) - which is the primary way to send packets (“datagrams”) of information from one machine to another.“IP4”, or more precisely, “IPv4” is version 4 of the Internet Protocol that describes how to send packets of information across a network from one machine to another . Roughly 95% of all packets on the Internet today are IPv4 packets. A significant limitation of IPv4 is that source and destination addresses are limited to 32 bits (IPv4 was designed at a time when the idea of 4 billion devices connected to the same network was unthinkable - or at least not worth making the packet size larger)Each IPv4 packet includes a very small header - typically 20 bytes (more precisely, “octets”), that includes a source and destination address.Conceptually the source and destination addresses can be split into two: a network number (the upper bits) and the lower bits represent a particular host number on that network.A newer packet protocol “IPv6” solves many of the limitations of IPv4 (e.g. makes routing tables simpler and 128 bit addresses) however less than 5% of web traffic is IPv6 based.A machine can have an IPv6 address and an IPv4 address.“There’s no place like 127.0.0.1”!A special IPv4 address is 127.0.0.1 also known as localhost. Packets sent to 127.0.0.1 will never leave the machine; the address is specified to be the same machine.Notice that the 32 bits address is split into 4 octets i.e. each number in the dot notation can be 0-255 inclusive. However IPv4 addresses can also be written as an integer.… and … “There’s no place like 0:0:0:0:0:0:0:1?”The 128bit localhost address in IPv6 is 0:0:0:0:0:0:0:1 which can be written in its shortened form, ::1What is a port?To send a datagram (packet) to a host on the Internet using IPv4 (or IPv6) you need to specify the host address and a port. The port is an unsigned 16 bit number (i.e. the maximum port number is 65535).A process can listen for incoming packets on a particular port. However only processes with super-user (root) access can listen on ports &lt; 1024. Any process can listen on ports 1024 or higher.An often used port is port 80: Port 80 is used for unencrypted http requests (i.e. web pages).For example, if a web browser connects to http://www.bbc.com/, then it will be connecting to port 80.What is UDP? When is it used?UDP is a connectionless protocol that is built on top of IPv4 and IPv6. It’s very simple to use: Decide the destination address and port and send your data packet! However the network makes no guarantee about whether the packets will arrive.Packets (aka Datagrams) may be dropped if the network is congested. Packets may be duplicated or arrive out of order.Between two distant data-centers it’s typical to see 3% packet loss.A typical use case for UDP is when receiving up to date data is more important than receiving all of the data. For example, a game may send continuous updates of player positions. A streaming video signal may send picture updates using UDPWhat is TCP? When is it used?TCP is a connection-based protocol that is built on top of IPv4 and IPv6 (and therefore can be described as “TCP/IP” or “TCP over IP”). TCP creates a pipe between two machines and abstracts away the low level packet-nature of the Internet: Thus, under most conditions, bytes sent from one machine will eventually arrive at the other end without duplication or data loss.TCP will automatically manage resending packets, ignoring duplicate packets, re-arranging out-of-order packets and changing the rate at which packets are sent.TCP’s three way handshake is known as SYN, SYN-ACK, and ACK. The diagram on this page helps with understanding the TCP handshake. TCP HandshakeMost services on the Internet today (e.g. a web service) use TCP because it hides the complexity of lower, packet-level nature of the Internet."
  },{
    "title": "Networking, Part 2: Using getaddrinfo",
    "url": " /wikibook/networking-part-2-using-getaddrinfo",
   "content": "How do I use getaddrinfo to convert the hostname into an IP address?The function getaddrinfo can convert a human readable domain name (e.g. www.illinois.edu) into an IPv4 and IPv6 address. In fact it will return a linked-list of addrinfo structs:struct addrinfo {    int              ai_flags;    int              ai_family;    int              ai_socktype;    int              ai_protocol;    socklen_t        ai_addrlen;    struct sockaddr *ai_addr;    char            *ai_canonname;    struct addrinfo *ai_next;};It’s very easy to use. For example, suppose you wanted to find out the numeric IPv4 address of a webserver at www.bbc.com. We do this in two stages. First use getaddrinfo to build a linked-list of possible connections. Secondly use getnameinfo to convert the binary address into a readable form.#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;struct addrinfo hints, *infoptr; // So no need to use memset global variablesint main() {    hints.ai_family = AF_INET; // AF_INET means IPv4 only addresses    int result = getaddrinfo(\"www.bbc.com\", NULL, &amp;hints, &amp;infoptr);    if (result) {        fprintf(stderr, \"getaddrinfo: %s\\n\", gai_strerror(result));        exit(1);    }    struct addrinfo *p;    char host[256];    for (p = infoptr; p != NULL; p = p-&gt;ai_next) {        getnameinfo(p-&gt;ai_addr, p-&gt;ai_addrlen, host, sizeof (host), NULL, 0, NI_NUMERICHOST);        puts(host);    }    freeaddrinfo(infoptr);    return 0;}Typical output:212.58.244.70212.58.244.71How is www.cs.illinois.edu converted into an IP address?Magic! No seriously, a system called “DNS” (Domain Name Service) is used. If a machine does not hold the answer locally then it sends a UDP packet to a local DNS server. This server in turn may query other upstream DNS servers.Is DNS secure?DNS by itself is fast but not secure. DNS requests are not encrypted and susceptible to ‘man-in-the-middle’ attacks. For example, a coffee shop internet connection could easily subvert your DNS requests and send back different IP addresses for a particular domainHow do I connect to a TCP server (e.g. web server?)TODOThere are three basic system calls you need to connect to a remote machine:getaddrinfo -- Determine the remote addresses of a remote hostsocket      -- Create a socketconnect     -- Connect to the remote host using the socket and address informationThe getaddrinfo call if successful, creates a linked-list of addrinfo structs and sets the given pointer to point to the first one.The socket call creates an outgoing socket and returns a descriptor (sometimes called a ‘file descriptor’) that can be used with read and write etc. In this sense it is the network analog of open that opens a file stream - except that we haven’t connected the socket to anything yet!Finally the connect call attempts the connection to the remote machine. We pass the original socket descriptor and also the socket address information which is stored inside the addrinfo structure. There are different kinds of socket address structures (e.g. IPv4 vs IPv6) which can require more memory. So in addition to passing the pointer, the size of the structure is also passed:// Pull out the socket address info from the addrinfo struct:connect(sockfd, p-&gt;ai_addr, p-&gt;ai_addrlen);How do I free the memory allocated for the linked-list of addrinfo structs?As part of the clean up code call freeaddrinfo on the top-most addrinfo struct:void freeaddrinfo(struct addrinfo *ai);If getaddrinfo fails can I use strerror to print out the error?No. Error handling with getaddrinfo is a little different:  The return value is the error code (i.e. don’t use errno)  Use gai_strerror to get the equivalent short English error text:int result = getaddrinfo(...);if (result) {     const char *mesg = gai_strerror(result);     ...}Can I request only IPv4 or IPv6 connection? TCP only?Yes! Use the addrinfo structure that is passed into getaddrinfo to define the kind of connection you’d like.For example, to specify stream-based protocols over IPv6:struct addrinfo hints;memset(&amp;hints, 0, sizeof (hints));hints.ai_family = AF_INET6; // Only want IPv6 (use AF_INET for IPv4)hints.ai_socktype = SOCK_STREAM; // Only want stream-based connectionWhat about code examples that use gethostbyname?The old function gethostbyname is deprecated; it’s the old way convert a host name into an IP address. The port address still needs to be manually set using htons function. It’s much easier to write code to support IPv4 AND IPv6 using the newer getaddrinfoIs it that easy!?Yes and no. It’s easy to create a simple TCP client - however network communications offers many different levels of abstraction and several attributes and options that can be set at each level of abstraction (for example we haven’t talked about setsockopt which can manipulate options for the socket).For more information see Beej’s guide."
  },{
    "title": "Networking, Part 3: Building a simple TCP Client",
    "url": " /wikibook/networking-part-3-building-a-simple-tcp-client",
   "content": "socketint socket(int domain, int socket_type, int protocol);Socket creates a socket with domain (e.g. AF_INET for IPv4 or AF_INET6 for IPv6), socket_type is whether to use UDP or TCP or other socket type, protocol is an optional choice of protocol configuration (for our examples this we can just leave this as 0 for default). This call creates a socket object in the kernel with which one can communicate with the outside world/network. You can use the result of getaddressinfo to fill in the socket parameters, or provide them manually.The socket call returns an integer - a file descriptor - and, for TCP clients, you can use it like a regular file descriptor i.e. you can use read and write to receive or send packets.TCP sockets are similar to pipes except that they allow full duplex communication i.e. you can send and receive data in both directions independently.getaddressinfoWe saw this in the last section! You’re experts at this.connectint connectok = connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);Pass connect the socket file descriptor, the address you want to connect to and the length in bytes of the address structure. To help identify errors and mistakes it is good practice to check the return value of all networking calls, including connectread/writeOnce we have a successful connection we can read or write like any old file descriptor. Keep in mind if you are connected to a website, you want to conform to the HTTP protocol specification in order to get any sort of meaningful results back. There are libraries to do this, usually you don’t connect at the socket level because there are other libraries or packages around it.The number of bytes read or written may be smaller than expected. Thus it is important to check the return value of read and write.Complete Simple TCP Client Example#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;#include &lt;unistd.h&gt;int main(int argc, char **argv) {    int s;    int sock_fd = socket(AF_INET, SOCK_STREAM, 0);    struct addrinfo hints, *result;    memset(&amp;hints, 0, sizeof (struct addrinfo));    hints.ai_family = AF_INET; /* IPv4 only */    hints.ai_socktype = SOCK_STREAM; /* TCP */    s = getaddrinfo(\"www.illinois.edu\", \"80\", &amp;hints, &amp;result);    if (s != 0) {        fprintf(stderr, \"getaddrinfo: %s\\n\", gai_strerror(s));        exit(1);    }    if (connect(sock_fd, result-&gt;ai_addr, result-&gt;ai_addrlen) == -1) {        perror(\"connect\");        exit(2);    }    char *buffer = \"GET / HTTP/1.0\\r\\n\\r\\n\";    printf(\"SENDING: %s\", buffer);    printf(\"===\\n\");    // For this trivial demo just assume write() sends all bytes in one go and is not interrupted    write(sock_fd, buffer, strlen(buffer));    char resp[1000];    int len = read(sock_fd, resp, 999);    resp[len] = '\\0';    printf(\"%s\\n\", resp);    return 0;}Example output:SENDING: GET / HTTP/1.0===HTTP/1.1 200 OKDate: Mon, 27 Oct 2014 19:19:05 GMTServer: Apache/2.2.15 (Red Hat) mod_ssl/2.2.15 OpenSSL/1.0.1e-fips mod_jk/1.2.32Last-Modified: Fri, 03 Feb 2012 16:51:10 GMTETag: \"401b0-49-4b8121ea69b80\"Accept-Ranges: bytesContent-Length: 73Connection: closeContent-Type: text/htmlProvided by Web Services at Public Affairs at the University of IllinoisComment on HTTP request and responseThe example above demonstrates a request to the server using Hypertext Transfer Protocol.A web page (or other resources) are requested using the following request:GET / HTTP/1.0There are four parts (the method e.g. GET,POST,…); the resource (e.g. / /index.html /image.png); the proctocol “HTTP/1.0” and two new lines (\\r\\n\\r\\n)The server’s first response line describes the HTTP version used and whether the request is successful using a 3 digit response code:HTTP/1.1 200 OKIf the client had requested a non existing file, e.g. GET /nosuchfile.html HTTP/1.0Then the first line includes the response code is the well-known 404 response code:HTTP/1.1 404 Not Found"
  },{
    "title": "Networking, Part 4: Building a simple TCP Server",
    "url": " /wikibook/networking-part-4-building-a-simple-tcp-server",
   "content": "What is htons and when is it used?Integers can be represented in least significant byte first or most-significant byte first. Either approach is reasonable as long as the machine itself is internally consistent. For network communications we need to standardize on agreed format.htons(xyz) returns the 16 bit unsigned integer ‘short’ value xyz in network byte order.htonl(xyz) returns the 32 bit unsigned integer ‘long’ value xyz in network byte order.These functions are read as ‘host to network’; the inverse functions (ntohs, ntohl) convert network ordered byte values to host-ordered ordering. So, is host-ordering  little-endian or big-endian? The answer is - it depends on your machine! It depends on the actual architecture of the host running the code. If the architecture happens to be the same as network ordering then the result of these functions is just the argument. For x86 machines, the host and network ordering is different.Summary: Whenever you read or write the low level C network structures (e.g. port and address information), remember to use the above functions to ensure correct conversion to/from a machine format. Otherwise the displayed or specified value may be incorrect.What are the ‘big 4’ network calls used to create a server?The four system calls required to create a TCP server are: socket, bind, listen and accept. Each has a specific purpose and should be called in the above orderThe port information (used by bind) can be set manually (many older IPv4-only C code examples do this), or be created using getaddrinfoWe also see examples of setsockopt later too.What is the purpose of calling socket?To create a endpoint for networking communication. A new socket by itself is not particularly useful; though we’ve specified either a packet or stream-based connections it is not bound to a particular network interface or port. Instead socket returns a network descriptor that can be used with later calls to bind, listen and accept.What is the purpose of calling bind?The bind call associates an abstract socket with an actual network interface and port. It is possible to call bind on a TCP client however it’s unusually unnecessary to specify the outgoing port.What is the purpose of calling listen?The listen call specifies the queue size for the number of incoming, unhandled connections i.e. that have not yet been assigned a network descriptor by acceptTypical values for a high performance server are 128 or more.Why are server sockets passive?Server sockets do not actively try to connect to another host; instead they wait for incoming connections. Additionally, server sockets are not closed when the peer disconnects. Instead the client communicates with a separate active socket on the server that is specific to that connection.Unique TCP connections are identified by the tuple (source ip, source port, destination ip, destination port)It is possible to have multiple connections from a web browser to the same server port (e.g. port 80) because the the source port on each arriving packet is unique. i.e. For a particular server port (e.g. port 80) there can be one passive server socket but multiple active sockets (one for each currently open connection) and the server’s operating system maintains a lookup table that associates a unique tuple with active sockets, so that incoming packets can be correctly routed to the correct socket.What is the purpose of calling accept?Once the server socket has been initialized the server calls accept to wait for new connections. Unlike socket bind and listen, this call will block. i.e. if there are no new connections, this call will block and only return when a new client connects. The returned TCP socket is associated with a particular tuple (client IP, client port, server IP, server port) and will be used for all future incoming and outgoing TCP packets that match this tuple.Note the accept call returns a new file descriptor. This file descriptor is specific to a particular client. It is common programming mistake to use the original server socket descriptor for server I/O and then wonder why networking code has failed.What are the gotchas of creating a TCP-server?  Using the socket descriptor of the passive server socket (described above)  Not specifying SOCK_STREAM requirement for getaddrinfo  Not being able to re-use an existing port.  Not initializing the unused struct entries  The bind call will fail if the port is currently in useNote, ports are per machine- not per process or per user. In other words,  you cannot use port 1234 while another process is using that port. Worse, ports are by default ‘tied up’ after a process has finished.Server code exampleA working simple server example is shown below. Note this example is incomplete - for example it does not close either socket descriptor, or free up memory created by getaddrinfo#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char **argv) {    int s;    int sock_fd = socket(AF_INET, SOCK_STREAM, 0);    struct addrinfo hints, *result;    memset(&amp;hints, 0, sizeof (struct addrinfo));    hints.ai_family = AF_INET;    hints.ai_socktype = SOCK_STREAM;    hints.ai_flags = AI_PASSIVE;    s = getaddrinfo(NULL, \"1234\", &amp;hints, &amp;result);    if (s != 0) {        fprintf(stderr, \"getaddrinfo: %s\\n\", gai_strerror(s));        exit(1);    }    if (bind(sock_fd, result-&gt;ai_addr, result-&gt;ai_addrlen) != 0) {        perror(\"bind()\");        exit(1);    }    if (listen(sock_fd, 10) != 0) {        perror(\"listen()\");        exit(1);    }        struct sockaddr_in *result_addr = (struct sockaddr_in *) result-&gt;ai_addr;    printf(\"Listening on file descriptor %d, port %d\\n\", sock_fd, ntohs(result_addr-&gt;sin_port));    printf(\"Waiting for connection...\\n\");    int client_fd = accept(sock_fd, NULL, NULL);    printf(\"Connection made: client_fd=%d\\n\", client_fd);    char buffer[1000];    int len = read(client_fd, buffer, sizeof (buffer) - 1);    buffer[len] = '\\0';    printf(\"Read %d chars\\n\", len);    printf(\"===\\n\");    printf(\"%s\\n\", buffer);    return 0;}Why can’t my server re-use the port?By default a port is not immediately released when the server socket is closed. Instead, the port enters a “TIMED-WAIT” state. This can lead to significant confusion during development because the timeout can make valid networking code appear to fail.To be able to immediately re-use a port, specify SO_REUSEPORT before binding to the port.int optval = 1;setsockopt(sfd, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof (optval));bind(....Here’s an extended stackoverflow introductory discussion of SO_REUSEPORT."
  },{
    "title": "Networking, Part 5: Shutting down ports, reusing ports and other tricks",
    "url": " /wikibook/networking-part-5-shutting-down-ports-reusing-ports-and-other-tricks",
   "content": "What is the difference shutdown and close?Use the shutdown call when you no longer need to read any more data from the socket, write more data, or have finished doing both.When you shutdown a socket for further writing (or reading) that information is also sent to the other end of the connection. For example if you shutdown the socket for further writing at the server end, then a moment later, a blocked read call could return 0 to indicate that no more bytes are expected.Use close when your process no longer needs the socket file descriptor.If you fork-ed after creating a socket file descriptor, all processes need to close the socket before the socket resources can be re-used.  If you shutdown a socket for further read then all process are be affected because you’ve changed the socket, not just the file descriptor.Well written code will shutdown a socket before calling close it.When I re-run my server code it doesn’t work! Why?By default, after a socket is closed the port enters a time-out state during which time it cannot be re-used (‘bound to a new socket’).This behavior can be disabled by setting the socket option REUSEPORT before bind-ing to a port:    int optval = 1;    setsockopt(sock_fd, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval));    bind(sock_fd, ...);Can a TCP client bind to a particular port?Yes! In fact outgoing TCP connections are automatically bound to an unused port on the client. Usually it’s unnecessary to explicitly set the port on the client because the system will intelligently find an unusued port on a reasonable interface (e.g. the wireless card, if currently connected by WiFi connection). However it can be useful if you needed to specifically choose a particular ethernet card, or if a firewall only allows outgoing connections from a particular range of port values.To explicitly bind to an ethernet interface and port, call bind before connectI built a simple TCP client or server but my process sometimes just quits! Why?If your process writes to a socket that has already been shutdown by the other end of the TCP connection, then your process will be sent a SIGPIPE signal. From our previous discussion on pipes, you might remember the default action is to shutdown the process. A workaround to this is to ignore SIGPIPE signals or to implement your own signal handler.void handle_sigpipe(int signal) {  char mesg[1000];  sprintf(mesg, \"\\n****** SIGPIPE  - no one is listening :-( ******\\n\");  write(1, mesg, strlen(mesg));}And register the signal handler using signal (or the newer sigaction or pthread_sigmask)…signal(SIGPIPE,handle_sigpipe)Who connected to my server?The accept system call can optionally provide information about the remote client, by passing in a sockaddr struct. Different protocols have differently variants of the  struct sockaddr, which are different sizes. The simplest struct to use is the sockaddr_storage which is sufficiently large to represent all possible types of sockaddr. Notice that C does not have any model of inheritance. Therefore we need to explicitly cast our struct to the ‘base type’ struct sockaddr.    struct sockaddr_storage clientaddr;    socklen_t clientaddrsize = sizeof(clientaddr);    int client_id = accept(passive_socket,            (struct sockaddr *) &amp;clientaddr,             &amp;clientaddrsize);We’ve already seen getaddrinfo that can build a linked list of addrinfo entries (and each one of these can include socket configuration data). What if we wanted to turn socket data into IP and port addresses? Enter getnameinfo that can be used to convert a local or remote socket information into a domain name or numeric IP. Similarly the port number can be represented as a service name (e.g. “http” for port 80). In the example below we request numeric versions for the client IP address and client port number.    socklen_t clientaddrsize = sizeof(clientaddr);    int client_id = accept(sock_id, (struct sockaddr *) &amp;clientaddr, &amp;clientaddrsize);    char host[256], port[256];    getnameinfo((struct sockaddr *) &amp;clientaddr,          clientaddrsize, host, sizeof(host), port, sizeof(port),          NI_NUMERICHOST | NI_NUMERICSERV);Todo: Discuss NI_MAXHOST and NI_MAXSERV, and NI_NUMERICHOSTgetnameinfo Example: What’s my IP address?To obtain a linked list of IP addresses of the current machine use getifaddrs which will return a linked list of IPv4 and IPv6 IP addresses (and potentially other interfaces too). We can examine each entry and use getnameinfo to print the host’s IP address.The  ifaddrs struct includes the family but does not include the sizeof the struct. Therefore we need to manually determine the struct sized based on the family (IPv4 v IPv6) (family == AF_INET) ? sizeof(struct sockaddr_in) : sizeof(struct sockaddr_in6)The complete code is shown below.    int required_family = AF_INET; // Change to AF_INET6 for IPv6    struct ifaddrs *myaddrs, *ifa;    getifaddrs(&amp;myaddrs);    char host[256], port[256];    for (ifa = myaddrs; ifa != NULL; ifa = ifa-&gt;ifa_next) {        int family = ifa-&gt;ifa_addr-&gt;sa_family;        if (family == required_family &amp;&amp; ifa-&gt;ifa_addr) {            if (0 == getnameinfo(ifa-&gt;ifa_addr,                                (family == AF_INET) ? sizeof(struct sockaddr_in) :                                sizeof(struct sockaddr_in6),                                host, sizeof(host), port, sizeof(port)                                 , NI_NUMERICHOST | NI_NUMERICSERV  ))                puts(host);            }        }What’s my machine’s IP address (shell version)Answer: use ifconfig (or Windows’s ipconfig)However this command generates a lot of output for each interface, so we can filter the output using grepifconfig | grep inetExample output:\tinet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 \tinet 127.0.0.1 netmask 0xff000000 \tinet6 ::1 prefixlen 128 \tinet6 fe80::7256:81ff:fe9a:9141%en1 prefixlen 64 scopeid 0x5 \tinet 192.168.1.100 netmask 0xffffff00 broadcast 192.168.1.255"
  },{
    "title": "Networking, Part 6: Building a web server",
    "url": " /wikibook/networking-part-6-building-a-web-server",
   "content": "How can you serve a simple static web page?A web server needs to implement HTTP (Hypertext transfer protocol), which is a specification of how client machine can request resources from a server and how a server can respond to a client message.We’re not going to build a fully compliant web server. Instead we will build the simplest possible web server, using the parts of TCP server that have already been introduced.First, we’ll set up a passive server socket hints.ai_family = AF_INET; hints.ai_socktype = SOCK_STREAM; hints.ai_flags = AI_PASSIVE; getaddrinfo(NULL, \"0\", &amp;hints, &amp;result); // \"0\"  = use any port that is freeWe don’t need the timeout after we’ve finished using the port - it can be reused immediately, int optval = 1; setsockopt(sock_fd, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval));Bind the socket to a port on the local machine and start listening for connections bind(sock_fd, result-&gt;ai_addr, result-&gt;ai_addrlen) listen(sock_fd, 10)Now that we’ve bound to a port, we can find out the actual port number used. Notice we need convert it from network to host byte ordering, (ntohs)  struct sockaddr_in sin;  socklen_t socklen = sizeof(sin);  getsockname(sock_fd, (struct sockaddr *)&amp;sin, &amp;socklen)  printf(\"Listening on port %d\\n\", ntohs(sin.sin_port)) Now call accept block until we have a client request to service. For each client, wait for the web browser’s request then always send a friendly message back. This starts with the response header that includes the MIMETYPE - the type of data that is represented by the bytes that follow. The response header, like the request header is terminated by two blank lines together \\r\\n\\r\\n/ Note this code also demonstrates use of Linux’s dprintf which allows printf-like formatting directly to a file descriptor.  while(1) {    int client_fd = accept(sock_fd, (struct sockaddr*) &amp;client_info, &amp;size);    char *connected_ip= inet_ntoa(client_info.sin_addr);  // ^^^^ Does this look thread-safe to you?    int port = ntohs(client_info.sin_port);    char buffer[1000];    read(client_fd, buffer, sizeof(buffer)-1);    dprintf(client_fd, \"HTTP/1.0 200 OK\\r\\n\");    dprintf(client_fd, \"Content-Type: text/html\\r\\n\\r\\n\");    dprintf(client_fd, \"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\");    shutdown(client_fd , SHUT_RDWR);    close(client_fd);  }How can you serve a simple static image file?  FILE*file = fopen(\"apicture.jpg\",\"r\");  if(file) {    fseek(file,0, SEEK_END);    long size = ftell(file);    fseek(file,0,SEEK_SET);    printf(\"Sending %ld bytes\\n\", size);    char*buf = malloc(size);    fread(buf,1,size,file);    char response[2048];        sprintf( response, \"HTTP/1.0 200 OK\\r\\n\"             \"Content-Type: image/jpeg\\r\\n\"             \"Content-Length: %ld\\r\\n\\r\\n\" , size);    write(client_fd, response, strlen(response));        write(client_fd, buf, size);    fclose(file);    free(buf);  }\t\t  shutdown(client_fd , SHUT_RDWR);  close(client_fd);"
  },{
    "title": "Networking, Part 6: Creating a UDP server",
    "url": " /wikibook/networking-part-6-creating-a-udp-server",
   "content": "How do I create a UDP server?There are a variety of function calls available to send UDP sockets. We will use the newer getaddrinfo to help set up a socket structure.Remember that UDP is a simple packet-based (‘data-gram’) protocol ; there is no connection to set up between the two hosts.First, initialize the hints addrinfo struct to request an IPv6, passive datagram socket.memset(&amp;hints, 0, sizeof(hints));hints.ai_family = AF_INET6; // use AF_INET instead for IPv4hints.ai_socktype =  SOCK_DGRAM;hints.ai_flags =  AI_PASSIVE;Next, use getaddrinfo to specify the port number (we don’t need to specify a host as we are creating a server socket, not sending a packet to a remote host).getaddrinfo(NULL, \"300\", &amp;hints, &amp;res);sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol);bind(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen);The port number is &lt;1024, so the program will need root privileges. We could have also specified a service name instead of a numeric port value.So far the calls have been similar to a TCP server. For a stream-based service we would call listen and accept. For our UDP-serve we can just start waiting for the arrival of a packet on the socket-struct sockaddr_storage addr;int addrlen = sizeof(addr);// ssize_t recvfrom(int socket, void* buffer, size_t buflen, int flags, struct sockaddr *addr, socklen_t * address_len);byte_count = recvfrom(sockfd, buf, sizeof(buf), 0, &amp;addr, &amp;addrlen);The addr struct will hold sender (source) information about the arriving packet.Note the sockaddr_storage type is a sufficiently large enough to hold all possible types of socket addresses (e.g. IPv4, IPv6 and other socket types).Full Code#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char **argv){    int s;    struct addrinfo hints, *res;    memset(&amp;hints, 0, sizeof(hints));    hints.ai_family = AF_INET6; // INET for IPv4    hints.ai_socktype =  SOCK_DGRAM;    hints.ai_flags =  AI_PASSIVE;    getaddrinfo(NULL, \"300\", &amp;hints, &amp;res);    int sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol);    if (bind(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen) != 0) {        perror(\"bind()\");        exit(1);    }    struct sockaddr_storage addr;    int addrlen = sizeof(addr);    while(1){        char buf[1024];        ssize_t byte_count = recvfrom(sockfd, buf, sizeof(buf), 0, &amp;addr, &amp;addrlen);        buf[byte_count] = '\\0';        printf(\"Read %d chars\\n\", byte_count);        printf(\"===\\n\");        printf(\"%s\\n\", buf);    }    return 0;}"
  },{
    "title": "Networking, Part 7: Nonblocking I O, select(), and epoll",
    "url": " /wikibook/networking-part-7-nonblocking-i-o-select()-and-epoll",
   "content": "Don’t waste time waitingNormally, when you call read(), if the data is not available yet it will wait until the data is ready before the function returns.  When you’re reading data from a disk, that delay may not be long, but when you’re reading from a slow network connection it may take a long time for that data to arrive, if it ever arrives.POSIX lets you set a flag on a file descriptor such that any call to read() on that file descriptor will return immediately, whether it has finished or not.  With your file descriptor in this mode, your call to read() will startthe read operation, and while it’s working you can do other useful work.  This is called “nonblocking” mode,since the call to read() doesn’t block.To set a file descriptor to be nonblocking:    // fd is my file descriptor    int flags = fcntl(fd, F_GETFL, 0);    fcntl(fd, F_SETFL, flags | O_NONBLOCK);For a socket, you can create it in nonblocking mode by adding SOCK_NONBLOCK to the second argument to socket():    fd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0);When a file is in nonblocking mode and you call read(), it will return immediately with whatever bytes are available.Say 100 bytes have arrived from the server at the other end of your socket and you call read(fd, buf, 150).Read will return immediately with a value of 100, meaning it read 100 of the 150 bytes you asked for.Say you tried to read the remaining data with a call to read(fd, buf+100, 50), but the last 50 bytes still hadn’tarrived yet.  read() would return -1 and set the global error variable errno to eitherEAGAIN or EWOULDBLOCK.  That’s the system’s way of telling you the data isn’t ready yet.write() also works in nonblocking mode.  Say you want to send 40,000 bytes to a remote server using a socket.The system can only send so many bytes at a time. Common systems can send about 23,000 bytes at a time. In nonblocking mode, write(fd, buf, 40000) would return the number of bytes it was able tosend immediately, or about 23,000.  If you called write() right away again, it would return -1 and set errno toEAGAIN or EWOULDBLOCK. That’s the system’s way of telling you it’s still busy sending the last chunk of data,and isn’t ready to send more yet.How do I check when the I/O has finished?There are a few ways.  Let’s see how to do it using select and epoll.select    int select(int nfds,                fd_set *readfds,                fd_set *writefds,               fd_set *exceptfds,                struct timeval *timeout);Given three sets of file descriptors, select() will wait for any of those file descriptors to become ‘ready’.  readfds - a file descriptor in readfds is ready when there is data that can be read or EOF has been reached.  writefds - a file descriptor in writefds is ready when a call to write() will succeed.  exceptfds - system-specific, not well-defined.  Just pass NULL for this.select() returns the total number of file descriptors that are ready.  If none of them becomeready during the time defined by timeout, it will return 0.  After select() returns, the caller will need to loop through the file descriptors in readfds and/or writefds to see whichones are ready. As readfds and writefds act as both input and output parameters, when select()indicates that there are file descriptors which are ready, it would have overwritten them toreflect only the file descriptors which are ready. Unless it is the caller’s intention to callselect() only once, it would be a good idea to save a copy of readfds and writefds beforecalling it.    fd_set readfds, writefds;    FD_ZERO(&amp;readfds);    FD_ZERO(&amp;writefds);    for (int i=0; i &lt; read_fd_count; i++)      FD_SET(my_read_fds[i], &amp;readfds);    for (int i=0; i &lt; write_fd_count; i++)      FD_SET(my_write_fds[i], &amp;writefds);    struct timeval timeout;    timeout.tv_sec = 3;    timeout.tv_usec = 0;    int num_ready = select(FD_SETSIZE, &amp;readfds, &amp;writefds, NULL, &amp;timeout);    if (num_ready &lt; 0) {      perror(\"error in select()\");    } else if (num_ready == 0) {      printf(\"timeout\\n\");    } else {      for (int i=0; i &lt; read_fd_count; i++)        if (FD_ISSET(my_read_fds[i], &amp;readfds))          printf(\"fd %d is ready for reading\\n\", my_read_fds[i]);      for (int i=0; i &lt; write_fd_count; i++)        if (FD_ISSET(my_write_fds[i], &amp;writefds))          printf(\"fd %d is ready for writing\\n\", my_write_fds[i]);    }For more information on select()epollepoll is not part of POSIX, but it is supported by Linux.  It is a more efficient way to wait for manyfile descriptors.  It will tell you exactly which descriptors are ready. It even gives you a way to storea small amount of data with each descriptor, like an array index or a pointer, making it easier to accessyour data associated with that descriptor.To use epoll, first you must create a special file descriptor with epoll_create().  You won’t read or write to this filedescriptor; you’ll just pass it to the other epoll_xxx functions and callclose() on it at the end.    epfd = epoll_create(1);For each file descriptor you want to monitor with epoll, you’ll need to add it to the epoll data structures using epoll_ctl() with the EPOLL_CTL_ADD option.  You can add anynumber of file descriptors to it.    struct epoll_event event;    event.events = EPOLLOUT;  // EPOLLIN==read, EPOLLOUT==write    event.data.ptr = mypointer;    epoll_ctl(epfd, EPOLL_CTL_ADD, mypointer-&gt;fd, &amp;event)To wait for some of the file descriptors to become ready, use epoll_wait().The epoll_event struct that it fills out will contain the data you provided in event.data when youadded this file descriptor. This makes it easy for you to look up your own data associatedwith this file descriptor.    int num_ready = epoll_wait(epfd, &amp;event, 1, timeout_milliseconds);    if (num_ready &gt; 0) {      MyData *mypointer = (MyData*) event.data.ptr;      printf(\"ready to write on %d\\n\", mypointer-&gt;fd);    }Say you were waiting to write data to a file descriptor, but now you want to wait to read data from it.Just use epoll_ctl() with the EPOLL_CTL_MOD option to change the type of operation you’re monitoring.    event.events = EPOLLOUT;    event.data.ptr = mypointer;    epoll_ctl(epfd, EPOLL_CTL_MOD, mypointer-&gt;fd, &amp;event);To unsubscribe one file descriptor from epoll while leaving others active, use epoll_ctl() with the EPOLL_CTL_DEL option.    epoll_ctl(epfd, EPOLL_CTL_DEL, mypointer-&gt;fd, NULL);To shut down an epoll instance, close its file descriptor.    close(epfd);In addition to nonblocking read() and write(), any calls to connect() on a nonblocking socket will also benonblocking. To wait for the connection to complete, use select() or epoll to wait for the socket to be writable.Interesting Blogpost about edge cases with selecthttps://idea.popcount.org/2017-01-06-select-is-fundamentally-broken/"
  },{
    "title": "Networking, Part 8: Protocols (TCP Handshaking, HTTP latency, Heart Bleed)",
    "url": " /wikibook/networking-part-8-protocols-(tcp-handshaking-http-latency-heart-bleed)",
   "content": "ProtocolsHow does TCP initiate a communication channel between sockets?Which POSIX call causes the first syn packet to be sent to the server?The first outgoing packet is sent by the client when the client calls connectsocket(...) &lt;- A socket is created but no actual connection has been performed yet.connect(fd,...) &lt;- Initiate connectionSubverting protocols case study: Denial of ServiceSyn floodDistributed Denial of ServiceInternet of Things Denial of ServiceTCP LatencySave the astronaut! The moon is 1.3 light seconds distant. The TCP client is on the Earth and a lunar console runs a TCP server. Assume a new TCP connection is required each time. How many seconds elapse between wanting to send a CLOSE-AIRLOCK message and the server receiving the data?fd=socket(...)connect(fd,...,...)write(fd,\"CLOSE-AIRLOCK!\",14);Answer: 3.9 seconds.TODO: Explain why. Create diagramHow many seconds elapse between requesting data from the server and receiving the result?fd= socket(...)connect(fd,...,...)write(fd,\"READ-TEMP!\",10);bytes= read(fd,buffer,256);Answer: 5.2 seconds. Todo Explain why.TCP and HTTP/1.0 performanceIf the client-server round trip time is 10 milliseconds, what is the minimum time required to display a web page with an image? Assume HTTP/1.0 and the image requires a separate HTTP request.HTTP/1.1 performance improvementsHTTP/2.0 performance improvementsQUIC protocol"
  },{
    "title": "Networking Review Questions",
    "url": " /wikibook/networking-review-questions",
   "content": "Topics  IPv4 vs IPv6  TCP vs UDP  Packet Loss/Connection Based  Get address info  DNS  TCP client calls  TCP server calls  shutdown  recvfrom  epoll vs select  RPCQuestions  What is IPv4? IPv6? What are the differences between them?  What is TCP? UDP? Give me advantages and disadvantages of both of them. When would I use one and not the other?  Which protocol is connection less and which one is connection based?  What is DNS? What is the route that DNS takes?  What does socket do?  What are the calls to set up a TCP client?  What are the calls to set up a TCP server?  What is the difference between a socket shutdown and closing?  When can you use read and write? How about recvfrom and sendto?  What are some advantages to epoll over select? How about select over epoll?  What is a remote procedure call? When should I use it?  What is marshalling/unmarshalling? Why is HTTP not an RPC?"
  },{
    "title": "OSI Model",
    "url": " /wikibook/osi-model",
   "content": "@MCQ Which one of the following is NOT a feature of TCP? -Packet re-ordering -Flow control -Packet re-transmission -Simple error detection -Encryption @ansNo Hind available @hint@EXP@END"
  },{
    "title": "#Piazza: When And How to Ask For Help",
    "url": " /wikibook/piazza%20when%20and%20how%20to%20ask%20for%20help",
   "content": "PurposeTAs and student assistants get a ton of questions. Some are well-researched, and some…are not. This is a handy guide that’ll help you move away from the latter and towards the former. (Oh, and did I mention that this is an easy way to score points with your internship managers?)Ask yourself…  Am I running on EWS?  Did I check the man pages?  Have I searched for similar questions/followups on Piazza?  Have I read the MP/DS specification completely?  Have I watched all of the videos?  Did I Google the error message (and a few permutations thereof if necessary)?  Did I try commenting out, printlining, and/or stepping through parts of the code bit by bit to find out precisely where the error occurs?  Did I commit my code to SVN in case the TAs need more context?  Did I include the console/GDB/Valgrind output AND code surrounding the bug in my Piazza post?  Have I fixed other segmentation faults not related to the issue I’m having?  Am I following good programming practice? (i.e. encapsulation, functions to limit repetition, etc)"
  },{
    "title": "Pipe: Review Questions",
    "url": " /wikibook/pipe-review-questions",
   "content": "  Question numbers subject to changeQ1Fill in the blanks to make the following program print 123456789. If cat is given no arguments it simply prints its input until EOF. Bonus: Explain why the close call below is necessary.int main() {    int i = 0;    while (++i &lt; 10) {        pid_t pid = fork();        if (pid == 0) { /* child */            char buffer[16];            sprintf(buffer, ______, i);            int fds[______];            pipe(fds);            write(fds[1], ______, ______); // Write the buffer into the pipe            close(______);            dup2(fds[0], ______);            execlp(\"cat\", \"cat\",  ______);            perror(\"exec\"); exit(1);        }        waitpid(pid, NULL, 0);    }    return 0;}Q2Use POSIX calls fork pipe dup2 and close to implement an autograding program. Capture the standard output of a child process into a pipe. The child process should exec the program ./test with no additional arguments (other than the process name). In the parent process read from the pipe: Exit the parent process as soon as the captured output contains the ! character. Before exiting the parent process send SIGKILL to the child process. Exit 0 if the output contained a !. Otherwise if the child process exits causing the pipe write end to be closed, then exit with a value of 1. Be sure to close the unused ends of the pipe in the parent and child processQ3 (Advanced)This advanced challenge uses pipes to get an “AI player” to play itself until the game is complete.The program tictactoe accepts a line of input - the sequence of turns made so far, prints the same sequence followed by another turn, and then exits. A turn is specified using two characters. For example “A1” and “C3” are two opposite corner positions. The string B2A1A3 is a game of 3 turns/plys. A valid response is B2A1A3C1 (the C1 response blocks the diagonal B2 A3 threat). The output line may also include a suffix -I win -You win -invalid or -drawUse pipes to control the input and output of each child process created. When the output contains a -, print the final output line (the entire game sequence and the result) and exit."
  },{
    "title": "Pipes, Part 1: Introduction to pipes",
    "url": " /wikibook/pipes-part-1-introduction-to-pipes",
   "content": "What is IPC?Inter process communication is any way for one process to talk to another process. You’ve already seen one form of this virtual memory! A piece of virtual memory can be shared between parent and child, leading to communication. You may want to wrap that memory in pthread_mutexattr_setpshared(&amp;attrmutex, PTHREAD_PROCESS_SHARED); mutex (or a process wide mutex) to prevent race conditions.There are more standard ways of IPC, like pipes! Consider if you type the following into your terminal$ ls -1 | cut -d'.' -f1 | uniq | sort | tee dir_contentsWhat does the following code do (It doesn’t really matter so you can skip this if you want)? Well it ls’s the current directory (the -1 means that it outputs one entry per line). The cut command then takes everything before the first period. Uniq makes sure all the lines are uniq, sort sorts them and tee outputs to a file.The important part is that bash creates 5 separate processes and connects their standard outs/stdins with pipes the trail looks something like this.(0) ls (1)——&gt;(0) cut (1)——-&gt;(0) uniq (1)——&gt;(0) sort (1)——&gt;(0) tee (1)The numbers in the pipes are the file descriptors for each process and the arrow represents the redirect or where the output of the pipe is going.What is a pipe?A POSIX pipe is almost like its real counterpart - you can stuff bytes down one end and they will appear at the other end in the same order. Unlike real pipes however, the flow is always in the same direction, one file descriptor is used for reading and the other for writing. The pipe system call is used to create a pipe.int filedes[2];pipe (filedes);printf(\"read from %d, write to %d\\n\", filedes[0], filedes[1]);These file descriptors can be used with read -// To read...char buffer[80];int bytesread = read(filedes[0], buffer, sizeof(buffer));And write -write(filedes[1], \"Go!\", 4);How can I use pipe to communicate with a child process?A common method of using pipes is to create the pipe before forking.int filedes[2];pipe (filedes);pid_t child = fork();if (child &gt; 0) { /* I must be the parent */    char buffer[80];    int bytesread = read(filedes[0], buffer, sizeof(buffer));    // do something with the bytes read    }The child can then send a message back to the parent:if (child == 0) {   write(filedes[1], \"done\", 4);}Can I use pipes inside a single process?Short answer: Yes, but I’m not sure why you would want to LOL!Here’s an example program that sends a message to itself:#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int main() {    int fh[2];    pipe(fh);    FILE *reader = fdopen(fh[0], \"r\");    FILE *writer = fdopen(fh[1], \"w\");    // Hurrah now I can use printf rather than using low-level read() write()    printf(\"Writing...\\n\");    fprintf(writer,\"%d %d %d\\n\", 10, 20, 30);    fflush(writer);        printf(\"Reading...\\n\");    int results[3];    int ok = fscanf(reader,\"%d %d %d\", results, results + 1, results + 2);    printf(\"%d values parsed: %d %d %d\\n\", ok, results[0], results[1], results[2]);        return 0;}The problem with using a pipe in this fashion is that writing to a pipe can block i.e. the pipe only has a limited buffering capacity. If the pipe is full the writing process will block! The maximum size of the buffer is system dependent; typical values from  4KB upto 128KB.int main() {    int fh[2];    pipe(fh);    int b = 0;    #define MESG \"...............................\"    while(1) {        printf(\"%d\\n\",b);        write(fh[1], MESG, sizeof(MESG))        b+=sizeof(MESG);    }    return 0;}See Pipes, Part 2: Pipe programming secrets"
  },{
    "title": "Pipes, Part 2: Pipe programming secrets",
    "url": " /wikibook/pipes-part-2-pipe-programming-secrets",
   "content": "Pipe GotchasHere’s a complete example that doesn’t work! The child reads one byte at a time from the pipe and prints it out - but we never see the message! Can you see why?#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;signal.h&gt;int main() {    int fd[2];    pipe(fd);    // You must read from fd[0] and write from fd[1]    printf(\"Reading from %d, writing to %d\\n\", fd[0], fd[1]);    pid_t p = fork();    if (p &gt; 0) {        /* I have a child therefore I am the parent*/        write(fd[1],\"Hi Child!\",9);        /*don't forget your child*/        wait(NULL);    } else {        char buf;        int bytesread;        // read one byte at a time.        while ((bytesread = read(fd[0], &amp;buf, 1)) &gt; 0) {            putchar(buf);        }    }    return 0;}The parent sends the bytes H,i,(space),C...! into the pipe (this may block if the pipe is full).The child starts reading the pipe one byte at a time. In the above case, the child process will read and print each character. However it never leaves the while loop! When there are no characters left to read it simply blocks and waits for more.The call putchar writes the characters out but we never flush the stdout buffer. i.e. We have transferred the message from one process to another but it has not yet been printed. To see the message we could flush the buffer e.g. fflush(stdout) (or printf(\"\\n\") if the output is going to a terminal). A better solution would also exit the loop by checking for an end-of-message marker,        while ((bytesread = read(fd[0], &amp;buf, 1)) &gt; 0) {            putchar(buf);            if (buf == '!') break; /* End of message */        }And the message will be flushed to the terminal when the child process exits.Want to use pipes with printf and scanf? Use fdopen!POSIX file descriptors are simple integers 0,1,2,3…At the C library level, C wraps these with a buffer and useful functions like printf and scanf, so we that we can easily print or parse integers, strings etc.If you already have a file descriptor then you can ‘wrap’ it yourself into a FILE pointer using fdopen :#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main() {    char *name = \"Fred\";    int score = 123;    int filedes = open(\"mydata.txt\", \"w\", O_CREAT, S_IWUSR | S_IRUSR);    FILE *f = fdopen(filedes, \"w\");    fprintf(f, \"Name:%s Score:%d\\n\", name, score);    fclose(f);For writing to files this is unnecessary - just use fopen which does the same as open and fdopenHowever for pipes, we already have a file descriptor - so this is great time to use fdopen!Here’s a complete example using pipes that almost works! Can you spot the error? Hint: The parent never prints anything!#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int main() {    int fh[2];    pipe(fh);    FILE *reader = fdopen(fh[0], \"r\");    FILE *writer = fdopen(fh[1], \"w\");    pid_t p = fork();    if (p &gt; 0) {        int score;        fscanf(reader, \"Score %d\", &amp;score);        printf(\"The child says the score is %d\\n\", score);    } else {        fprintf(writer, \"Score %d\", 10 + 10);        fflush(writer);    }    return 0;}Note the (unnamed) pipe resource will disappear once both the child and parent have exited. In the above example the child will send the bytes and the parent will receive the bytes from the pipe. However, no end-of-line character is ever sent, so fscanf will continue to ask for bytes because it is waiting for the end of the line i.e. it will wait forever! The fix is to ensure we send a newline character, so that fscanf will return.change:   fprintf(writer, \"Score %d\", 10 + 10);to:       fprintf(writer, \"Score %d\\n\", 10 + 10);So do we need to fflush too?Yes, if you want your bytes to be sent to the pipe immediately! At the beginning of this course we assumed that file streams are always line buffered i.e. the C library will flush its buffer everytime you send a newline character. Actually this is only true for terminal streams - for other filestreams the C library attempts to improve performance by only flushing when it’s internal buffer is full or the file is closed.When do I need two pipes?If you need to send data to and from a child asynchronously, then two pipes are required (one for each direction).Otherwise the child would attempt to read its own data intended for the parent (and vice versa)!Closing pipes gotchasProcesses receive the signal SIGPIPE when no process is listening! From the pipe(2) man page -If all file descriptors referring to the read end of a pipe have been closed, then a write(2) will cause a SIGPIPE signal to be generated for the calling process. Tip: Notice only the writer (not a reader) can use this signal.To inform the reader that a writer is closing their end of the pipe, you could write your own special byte (e.g. 0xff) or a message ( \"Bye!\")Here’s an example of catching this signal that does not work! Can you see why?#include &lt;stdio.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;signal.h&gt;void no_one_listening(int signal) {    write(1, \"No one is listening!\\n\", 21);}int main() {    signal(SIGPIPE, no_one_listening);    int filedes[2];        pipe(filedes);    pid_t child = fork();    if (child &gt; 0) {         /* I must be the parent. Close the listening end of the pipe */        /* I'm not listening anymore!*/        close(filedes[0]);    } else {        /* Child writes messages to the pipe */        write(filedes[1], \"One\", 3);        sleep(2);        // Will this write generate SIGPIPE ?        write(filedes[1], \"Two\", 3);        write(1, \"Done\\n\", 5);    }    return 0;}The mistake in above code is that there is still a reader for the pipe! The child still has the pipe’s first file descriptor open and remember the specification? All readers must be closed.When forking, It is common practice to close the unnecessary (unused) end of each pipe in the child and parent process. For example the parent might close the reading end and the child might close the writing end (and vice versa if you have two pipes)What is filling up the pipe? What happens when the pipe becomes full?A pipe gets filled up when the writer writes too much to the pipe without the reader reading any of it. When the pipes become full, all writes fail until a read occurs. Even then, a write may partial fail if the pipe has a little bit of space left but not enough for the entire message.To avoid this, usually two things are done. Either increase the size of the pipe. Or more commonly, fix your program design so that the pipe is constantly being read from.Are pipes process safe?Yes! Pipe write are atomic up to the size of the pipe. Meaning that if two processes try to write to the same pipe, the kernel has internal mutexes with the pipe that it will lock, do the write, and return. The only gotcha is when the pipe is about to become full. If two processes are trying to write and the pipe can only satisfy a partial write, that pipe write is not atomic – be careful about that!The lifetime of pipesUnnamed pipes (the kind we’ve seen up to this point) live in memory (do not take up any disk space) and are a simple and efficient form of inter-process communication (IPC) that is useful for streaming data and simple messages. Once all processes have closed, the pipe resources are freed.An alternative to unamed pipes is named pipes created using mkfifo.Named PipesHow do I create named pipes?From the command line: mkfifoFrom C: int mkfifo(const char *pathname, mode_t mode);You give it the path name and the operation mode, it will be ready to go! Named pipes take up no space on the disk. What the operating system is essentially telling you when you have a named pipe is that it will create an unnamed pipe that refers to the named pipe, and that’s it! There is no additional magic. This is just for programming convenience if processes are started without forking (meaning that there would be no way to get the file descriptor to the child process for an unnamed pipe)Why is my pipe hanging?Reads and writes hang on Named Pipes until there is at least one reader and one writer, take this1$ mkfifo fifo1$ echo Hello &gt; fifo# This will hang until I do this on another terminal or another process2$ cat fifoHelloAny open is called on a named pipe the kernel blocks until another process calls the opposite open. Meaning, echo calls open(.., O_WRONLY) but that blocks until cat calls open(.., O_RDONLY), then the programs are allowed to continue.Race condition with named pipes.What is wrong with the following program?// Program 1int main() {    int fd = open(\"fifo\", O_RDWR | O_TRUNC);    write(fd, \"Hello!\", 6);    close(fd);    return 0;}//Program 2int main() {    char buffer[7];    int fd = open(\"fifo\", O_RDONLY);    read(fd, buffer, 6);    buffer[6] = '\\0';    printf(\"%s\\n\", buffer);    return 0;}This may never print hello because of a race condition. Since you opened the pipe in the first process under both permissions, open won’t wait for a reader because you told the operating system that you are a reader! Sometimes it looks like it works because the execution of the code looks something like this.            Process 1      Process 2                  open(O_RDWR) &amp; write()                            open(O_RDONLY) &amp; read()              close() &amp; exit()                            print() &amp; exit()      Sometimes it won’t            Process 1      Process 2                  open(O_RDWR) &amp; write()                     close() &amp; exit()      (Named pipe is destroyed)              (Blocks indefinitely)      open(O_RDONLY)      "
  },{
    "title": "POSIX, Part 1: Error handling",
    "url": " /wikibook/posix-part-1-error-handling",
   "content": "What is POSIX error handling?In other languages, you may see error handling implemented with exceptions. Although you technically can use them in C –You keep a stack of very try/catch block and use setjmp and longjmp to go to those blocks, respectively – error handling in C is typically done with POSIX error handling the code typically looks like this.int ret = some_system_call()if(ret == ERROR_CODE){switch(errno){// Do different stuff based on the errno number.}}In the kernel, the use of goto is heavily used to clean up different parts of the application. You should not use gotos because they make code harder to read. gotos in the kernel are there out of necessity, so don’t take lessons.What is errno and when is it set?POSIX defines a special integer errno that is set when a system call fails.The initial value of errno is zero (i.e. no error).When a system call fails it will typically return -1 to indicate an error and set errnoWhat about multiple threads?Each thread has it’s own copy of errno. This is very useful; otherwise an error in one thread would interfere with the error status of another thread.When is errno reset to zero?It’s not unless you specifically reset it to zero!  When system calls are successful they do not reset the value of errno.This means you should only rely on the value of errno if you know a system call has failed (e.g. it returned -1).What are the gotchas and best practices of using errno?Be careful when complex error handling use of library calls or system calls that may change the value of errno. In practice it’s safer to copy the value of errno into a int variable:// Unsafe - the first fprintf may change the value of errno before we use it!if (-1 == sem_wait(&amp;s)) {   fprintf(stderr, \"An error occurred!\");   fprintf(stderr, \"The error value is %d\\n\", errno);}// Better, copy the value before making more system and library callsif (-1 == sem_wait(&amp;s)) {   int errno_saved = errno;   fprintf(stderr, \"An error occurred!\");   fprintf(stderr, \"The error value is %d\\n\", errno_saved);}In a similar vein, if your signal handler makes any system or library calls, then it is good practice to save the original value of errno and restore the value before returning:void handler(int signal) {   int errno_saved = errno;   // make system calls that might change errno   errno = errno_saved;}How can you print out the string message associated with a particular error number?Use strerror to get a short (English) description of the error valuechar *mesg = strerror(errno);fprintf(stderr, \"An error occurred (errno=%d): %s\", errno, mesg);How are perror and strerror related?In previous pages we’ve used perror to print out the error to standard error. Using strerror, we can now write a simple implementation of perror:void perror(char *what) {   fprintf(stderr, \"%s: %s\\n\", what, strerror(errno));}What are the gotchas of using strerror?Unfortunately strerror is not threadsafe. In other words, two threads cannot call it at the same time!There are two workarounds: Firstly we can use a mutex lock to define a critical section and a local buffer. The same mutex should be used by all threads in all places that call strerrorpthread_mutex_lock(&amp;m);char *result = strerror(errno);char *message = malloc(strlen(result) + 1);strcpy(message, result);pthread_mutex_unlock(&amp;m);fprintf(stderr, \"An error occurred (errno=%d): %s\", errno, message);free(message);Alternatively, use the less portable but thread-safe strerror_r. perror is thread safe, which is why it is preferred in multi-threading environments if possible.What is EINTR? What does it mean for sem_wait? read? write?Some system calls can be interrupted when a signal (e.g SIGCHLD, SIGPIPE,…) is delivered to the process. At this point the system call may return without performing any action! For example, bytes may not have been read/written, semaphore wait may not have waited.This interruption can be detected by checking the return value and if errno is EINTR. In which case the system call should be retried. It’s common to see the following kind of loop that wraps a system call (such as sem_wait).while ((-1 == systemcall(...)) &amp;&amp; (errno == EINTR)) { /* repeat! */}Be careful to write == EINTR, not = EINTR.Or, if the result value needs to be used later…while ((-1 == (result = systemcall(...))) &amp;&amp; (errno == EINTR)) { /* repeat! */}On Linux,calling read and write to a local disk will normally not return with EINTR (instead the function is automatically restarted for you). However, calling read and write on a file descriptor that corresponds to a network stream can return with EINTR.Which system calls may be interrupted and need to be wrapped?Use the man page! The man page includes a list of errors (i.e. errno values) that may be set by the system call. A rule of thumb is ‘slow’ (blocking) calls (e.g. writing to a socket) may be interrupted but fast non-blocking calls (e.g. pthread_mutex_lock) will not.From the linux signal 7 man page:“If a signal handler is invoked while a system call or library function call is blocked, then either:  the call is automatically restarted after the signal handler returns; or  the call fails with the error EINTR.Which of these two behaviors occurs depends on the interface and whether or not the signal handler was established using the SA_RESTART flag (see sigaction(2)). The details vary across UNIX systems; below, the details for Linux.If a blocked call to one of the following interfaces is interrupted by a signal handler, then the call will be automatically restarted after the signal handler returns if the SA_RESTART flag was used; otherwise the call will fail with the error EINTR:  read(2), readv(2), write(2), writev(2), and ioctl(2) calls on “slow” devices. A “slow” device is one where the I/O call may block for an indefinite time, for example, a terminal, pipe, or socket. (A disk is not a slow device according to this definition.) If an I/O call on a slow device has already transferred some data by the time it is interrupted by a signal handler, then the call will return a success status (normally, the number of bytes transferred).“Note, it is easy to believe that setting ‘SA_RESTART’ flag is sufficient to make this whole problem disappear. Unfortunately that’s not true: there are still system calls that may return early and set EINTR! See signal(7) for details.Errno exceptions?There are some POSIX utilities that have their own errno per say. One is when you call getaddrinfo the function to check that error and convert to a string is gai_strerr. Don’t get them mixed up!"
  },{
    "title": "Process Control, Part 1: Wait macros, using signals",
    "url": " /wikibook/process-control-part-1-wait-macros-using-signals",
   "content": "Wait MacrosCan I find out the exit value of my child?You can find the lowest 8 bits of the child’s exit value (the return value of main() or value included in exit()): Use the “Wait macros” - typically you will use “WIFEXITED” and “WEXITSTATUS” . See wait/waitpid man page for more information).int status;pid_t child = fork();if (child == -1) return 1; // Failedif (child &gt; 0) { /* I am the parent - wait for the child to finish */    pid_t pid = waitpid(child, &amp;status, 0);    if (pid != -1 &amp;&amp; WIFEXITED(status)) {        int low8bits = WEXITSTATUS(status);        printf(\"Process %d returned %d\" , pid, low8bits);    }} else { /* I am the child */    // do something interesting    execl(\"/bin/ls\", \"/bin/ls\", \".\", (char *) NULL); // \"ls .\"}A process can only have 256 return values, the rest of the bits are informational.Bit ShiftingNote there is no need to memorize this, this is just a high level overview of how information is stored inside the status variablesFrom Android source code:/* If WIFEXITED(STATUS), the low-order 8 bits of the status. */#define __WEXITSTATUS(status) (((status) &amp; 0xff00) &gt;&gt; 8)/* If WIFSIGNALED(STATUS), the terminating signal. */#define __WTERMSIG(status) ((status) &amp; 0x7f)/* If WIFSTOPPED(STATUS), the signal that stopped the child. */#define __WSTOPSIG(status) __WEXITSTATUS(status)/* Nonzero if STATUS indicates normal termination. */#define __WIFEXITED(status) (__WTERMSIG(status) == 0)The kernel has an internal way of keeping track of signaled, exited, or stopped. That API is abstracted so that that the kernel developers are free to change at will.Being careful.Remember that the the macros only make sense if the precondition is met. Meaning that a process’ exit status won’t be defined if the process is signaled. The macros will not do the checking for you, so it’s up to the programming to make sure the logic checks out.SignalsWhat’s a signal?A signal is a construct provided to us by the kernel. It allows one process to asynchronously send a signal (think a message) to another process. If that process wants to accept the signal, it can, and then, for most signals, can decide what to do with that signal. Here is a short list (non comprehensive) of signals.            Name      Default Action      Usual Use Case                  SIGINT      Terminate Process (Can be caught)      Tell the process to stop nicely              SIGQUIT      Terminate Process (Can be caught)      Tells the process to stop harshly              SIGSTOP      Stop Process (Cannot be caught)      Stops the process to be continued              SIGCONT      Continues a Process      Continues to run the process              SIGKILL      Terminate Process (Cannot be caught)      You want your process gone      When are signals generated?  When the user sends a signal. For example, you are at the terminal, and you send CTRL-C  When a system event happens. For example, you get a SIGCHILD after forking to notice when one of your children have exited.  When another program sends it. For example, when you execute kill -9 PID, it sends SIGKILL  When an appropriate hardware interrupt is triggered. For example, if you access a page that you aren’t supposed to, the hardware generates a segfault interrupt which gets intercepted by the kernel. The kernel finds the process that caused this and sends a software interrupt signal SIGSEGV.Can I pause my child?Yes ! You can temporarily pause a running process by sending it a SIGSTOP signal.If it succeeds it will freeze a process; i.e. the process will not be allocated any more CPU time.To allow a process to resume execution send it the SIGCONT signal.For example,Here’s program that slowly prints a dot every second, up to 59 dots.#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() {    printf(\"My pid is %d\\n\", getpid());    int i = 60;    while (--i) {         write(1, \".\", 1);        sleep(1);    }    write(1, \"Done!\", 5);    return 0;}We will first start the process in the background (notice the &amp; at the end).Then send it a signal from the shell process by using the kill command.&gt;./program &amp;My pid is 403...&gt;kill -SIGSTOP 403&gt;kill -SIGCONT 403How do I kill/stop/suspend my child from C?In C, send a signal to the child using kill POSIX call,kill(child, SIGUSR1); // Send a user-defined signalkill(child, SIGSTOP); // Stop the child process (the child cannot prevent this)kill(child, SIGTERM); // Terminate the child process (the child can prevent this)kill(child, SIGINT); // Equivalent to CTRL-C (by default closes the process)As we saw above there is also a kill command available in the shelle.g. get a list of running processes and then terminate process 45 and process 46pskill -l kill -9 45kill -s TERM 46How can I detect “CTRL-C” and clean up gracefully?We will return to signals later on - this is just a short introduction. On a Linux system, see man -s7 signal if you are interested in finding out more (for example a list of system and library calls that are async-signal-safe).There are strict limitations on the executable code inside a signal handler. Most library and system calls are not ‘async-signal-safe’ - they may not be used inside a signal handler because they are not re-entrant safe. In a single-threaded program, signal handling momentarily interrupts the program execution to execute the signal handler code instead. Suppose your original program was interrupted while executing the library code of malloc ;  the memory structures used by malloc will not be in a consistent state. Calling printf (which uses malloc) as part of the signal handler is unsafe and will result in “undefined behavior” i.e. it is no longer a useful,predictable program. In practice your program might crash, compute or generate incorrect results or stop functioning (“deadlock”), depending on exactly what your program was executing when it was interrupted to execute the signal handler code.One common use of signal handlers is to set a boolean flag that is occasionally polled (read) as part of the normal running of the program. For example,int pleaseStop; // See notes on why \"volatile sig_atomic_t\" is bettervoid handle_sigint(int signal) {    pleaseStop = 1;}int main() {    signal(SIGINT, handle_sigint);    pleaseStop = 0;    while (! pleaseStop) {         /* application logic here */     }    /* cleanup code here */}The above code might appear to be correct on paper. However, we need to provide a hint to the compiler and to the CPU core that will execute the main() loop. We need to prevent a compiler optimization: The expression ! pleaseStop appears to be a loop invariant i.e. true forever, so can be simplified to true.  Secondly, we need to ensure that the value of pleaseStop is not cached using a CPU register and instead always read from and written to main memory. The sig_atomic_t type implies that all the bits of the variable can be read or modified as an “atomic operation” - a single uninterruptable operation. It is impossible to read a value that is composed of some new bit values and old bit values.By specifying pleaseStop with the correct type volatile sig_atomic_t we can write portable code where the main loop will be exited after the signal handler returns. The sig_atomic_t type can be as large as an int on most modern platforms but on embedded systems can be as small as a char and only able to represent (-127 to 127) values.volatile sig_atomic_t pleaseStop;Two examples of this pattern can be found in “COMP” a terminal based 1Hz 4bit computer (https://github.com/gto76/comp-cpp/blob/1bf9a77eaf8f57f7358a316e5bbada97f2dc8987/src/output.c#L121).Two boolean flags are used. One to mark the delivery of SIGINT (CTRL-C), and gracefully shutdown the program, and the other to mark SIGWINCH signal to detect terminal resize and redraw the entire display.Back: Forking, Part 2: Fork, Exec, Wait |Next: Processes Review Questions"
  },{
    "title": "Processes, Part 1: Introduction",
    "url": " /wikibook/processes-part-1-introduction",
   "content": "OverviewA process is program that is running, kinda. A process is also just one instance of that computer program running. Processes have a lot of things at their disposal. At the start of each program you get one process, but each program can make more processes. In fact, your operating system starts up with only one process and all other processes are forked off of that – all of that is done under the hood when booting up.Okay, but what’s a program?Programs usually contain the following  A binary format: This tells the operating system which set of bits in the binary are what – which part is executable, which parts are constants, which libraries to include etc.  A set of machine instructions  A number denoting which instruction to start from  Constants  Libraries to link and where to fill in the address of those librariesIn the beginningWhen your operating system starts on a linux machine, there is a process called init.d that gets created. That process is a special one handling signals, interrupts, and a persistence module for certain kernel elements. Whenever you want to make a new process, you call fork (to be discussed in a later section) and use another function to load another program.Process IsolationProcesses are very powerful but they are isolated! That means that by default, no process can communicate with another process. This is very important because if you have a large system (let’s say EWS) then you want some processes to have higher privileges (monitoring, admin) than your average user, and one certainly doesn’t want the average user to be able to bring down the entire system either on purpose or accidentally by modifying a process.If I run the following code,int secrets; //maybe defined in the kernel or else wheresecrets++;printf(\"%d\\n\", secrets);On two different terminals, as you would guess they would both print out 1 not 2. Even if we changed the code to do something really hacky (apart from reading the memory directly) there would be no way to change another process’ state (okay maybe this but that is getting a little too in depth).Process ContentsMemory Layout&lt;img src=\"https://i.imgur.com/pl6K5cF.png\" width=600 style=\"display: block;margin: 0 auto\"&gt;When a process starts, it gets its own address space. Meaning that each process gets :  A Stack. The Stack is the place where automatic variable and function call return addresses are stored. Every time a new variable is declared, the program moves the stack pointer down to reserve space for the variable. This segment of the stack is Writable but not executable. If the stack grows too far – meaning that it either grows beyond a preset boundary or intersects the heap – you will get a stackoverflow most likely resulting in a SEGFAULT or something similar. The stack is statically allocated by default meaning that there is only a certain amount of space to which one can write  A Heap. The heap is an expanding region of memory. If you want to allocate a large object, it goes here. The heap starts at the top of the text segment and grows upward (meaning sometimes when you call malloc that it asks the operating system to push the heap boundary upward). This area is also Writable but not Executable. One can run out of heap memory if the system is constrained or if you run out of addresses (more common on a 32bit system).  A Data Segment This contains all of your globals. This section starts at the end of the text segment and is static in size because the amount of globals is known at compile time. There are two areas to the data usually the IBSS and the UBSS which stand for the initialized basic service set and the uninitialized data segment respectively. This section is Writable but not Executable and there isn’t anything else too fancy here.  A Text Segment. This is, arguably, the most important section of the address. This is where all your code is stored. Since assembly compiles to 1’s and 0’s, this is where the 1’s and 0’s get stored. The program counter moves through this segment executing instructions and moving down the next instruction. It is important to note that this is the only Executable section of the code. If you try to change the code while it’s running, most likely you will segfault (there are ways around it but just assume that it segfaults).  Why doesn’t it start at zero? It is outside the scope of this class but it is for security.Process ID (PID)To keep track of all these processes, your operating system gives each process a number and that process is called the PID, process ID. Processes also have a ppid which is short for parent process id. Every process has a parent, that parent could be init.dProcesses could also contain  Running State - Whether a process is getting ready, running, stopped, terminated etc.  File Descriptors - List of mappings from integers to real devices (files, usb sticks, sockets)  Permissions - What user the file is running on and what group the process belongs to. The process can then only do this admissible to the user or group like opening a file that the user has made exclusives. There are tricks to make a program not be the user who started the program i.e. sudo takes a program that a user starts and executes it as root.  Arguments - a list of strings that tell your program what parameters to run under  Environment List - a list of strings in the form NAME=VALUE that one can modify.Forking, Part 1: Introduction"
  },{
    "title": "Processes Review Questions",
    "url": " /wikibook/processes-review-questions",
   "content": "Topics  Correct use of fork, exec and waitpid  Using exec with a path  Understanding what fork and exec and waitpid do. E.g. how to use their return values.  SIGKILL vs SIGSTOP vs SIGINT.  What signal is sent when you press CTRL-C  Using kill from the shell or the kill POSIX call.  Process memory isolation.  Process memory layout (where is the heap, stack etc; invalid memory addresses).  What is a fork bomb, zombie and orphan? How to create/remove them.  getpid vs getppid  How to use the WAIT exit status macros WIFEXITED etc.Questions/Exercises  What is the difference between execs with a p and without a p? What does the operating system  How do you pass in command line arguments to execl*? How about execv*? What should be the first command line argument by convention?  How do you know if exec or fork failed?  What is the int *status pointer passed into wait? When does wait fail?  What are some differences between SIGKILL, SIGSTOP, SIGCONT, SIGINT? What are the default behaviors? Which ones can you set up a signal handler for?  What signal is sent when you press CTRL-C?  My terminal is anchored to PID = 1337 and has just become unresponsive. Write me the terminal command and the C code to send SIGQUIT to it.  Can one process alter another processes memory through normal means? Why?  Where is the heap, stack, data, and text segment? Which segments can you write to? What are invalid memory addresses?  Code me up a fork bomb in C (please don’t run it).  What is an orphan? How does it become a zombie? How do I be a good parent?  Don’t you hate it when your parents tell you that you can’t do something? Write me a program that sends SIGSTOP to your parent.  Write a function that fork exec waits an executable, and using the wait macros tells me if the process exited normally or if it was signaled. If the process exited normally, then print that with the return value. If not, then print the signal number that caused the process to terminate.Back: Process Control, Part 1: Wait macros, using signals"
  },{
    "title": "Programming Tricks, Part 1",
    "url": " /wikibook/programming-tricks-part-1",
   "content": "Use cat as your IDEWho needs an editor? IDE? We can just use cat!You’ve seen cat being used to read the contents of files but it can also be used to read the standard-input and send it back to standard output.$ catHELLOHELLOTo finish reading from the input stream close the input stream by pressing CTRL-DLet’s use cat to send standard input to a file. We will use ‘&gt;’ to redirect its output to a file:$ cat &gt; myprog.c#include &lt;stdio.h&gt;int main() {printf(\"Hi!\");return 0;}(Be careful! Deletes and undos are not allowed…)Press CTRL-D when finished.Edit your code with perl regular expressions (aka “remember your perl pie”)A useful trick if you have several text files (e.g. source code) to change is to use regular expressions.perl makes this very easy to edit files in place.Just remember ‘perl pie’ and search on the web…An example. Suppose we want to change the sequence “Hi” to “Bye” in all .c files in the current directory. Then we can write a simple substitution pattern that will be executed on each line at time in all files:$ perl -p -i -e 's/Hi/Bye/' *.c(Don’t panic if you get it wrong, original files are still there; they just have the extension .bak)Obviously there’s a lot more you can do with regular expressions than changing Hi to Bye.Use your shell !!To re-run the last command just type !! and press returnTo re-run the last command that started with g type !g  and press returnUse your shell &amp;&amp;Tired of running make or gcc and then running the program if it compiled OK? Instead, use &amp;&amp; to chain these commands together$ gcc program.c &amp;&amp; ./a.outMake can do more than makeYou might also try putting a line in your Makefile that will compile, and then run your program.run : $(program)        ./$(program)Then running$ make runwill make sure any changes you’ve made are compiled, and run your program in one go. Also good for testing many inputs at once. Although you probably would just rather write a regular shell script for that.Is your neighbor too productive? C pre-processors to the rescue!Use the C pre-processor to redefine common keywords e.g.#define if whileProtip: Put this line inside one of the standard includes e.g. /usr/include/stdio.hWho needs functions when you C have the pre-processorOK, so this is more of a gotcha. Be careful when using macros that look like functions…#define min(a,b) a&lt;b?a:bA perfectly reasonable definition of a minimum of a and b. However the pre-processor is just a simpletext wrangler so precedence can bite you:int value = -min(2,3); // Should be -2?Is expanded toint value = -2&lt;3 ? 2 :3; // Oops.. result will be 2A partial fix is to wrap every argument with () and also the whole expression with ():#define min(a,b) (  (a) &lt; (b) ?(a):(b) )However this is still not a function! For example can you see why min(i++,10) might increment i once or twice!?"
  },{
    "title": "Pthread Review Questions",
    "url": " /wikibook/pthread-review-questions",
   "content": "Topics  pthread lifecycle  Each thread has a stack  Capturing return values from a thread  Using pthread_join  Using pthread_create  Using pthread_exit  Under what conditions will a process exitQuestions  What happens when a pthread gets created? (you don’t need to go into super specifics)  Where is each thread’s stack?  How do you get a return value given a pthread_t? What are the ways a thread can set that return value? What happens if you discard the return value?  Why is pthread_join important (think stack space, registers, return values)?  What does pthread_exit do under normal circumstances (ie you are not the last thread)? What other functions are called when you call pthread_exit?  Give me three conditions under which a multithreaded process will exit. Can you think of any more?  What is an embarrassingly parallel problem?"
  },{
    "title": "Pthreads, Part 1: Introduction",
    "url": " /wikibook/pthreads-part-1-introduction",
   "content": "Intro to ThreadsWhat is a thread?A thread is short for ‘thread-of-execution’. It represents the sequence of instructions that the CPU has (and will) execute. To remember how to return from function calls, and to store the values of automatic variables and  parameters a thread uses a stack.What is a Lightweight Process (LWP)? How does it relate to threads?Well for all intents and purposes a thread is a process (meaning that creating a thread is similar to fork) except there is no copying meaning no copy on write. What this allows is for a process to share the same address space, variables, heap, file descriptors and etc.The actual system call to create a thread is similar to fork; it’s clone. We won’t go into the specifics but you can read the man pages keeping in mind that it is outside the direct scope of this course.LWP or threads are preferred to forking for a lot of scenarios because there is a lot less overhead creating them. But in some cases (notably python uses this) multiprocessing is the way to make your code faster.How does the thread’s stack work?Your main function (and other functions you might call) has automatic variables. We will store them in memory using a stack and keep track of how large the stack is by using a simple pointer (the “stack pointer”). If the thread calls another function, we move our stack pointer down, so that we have more space for parameters and automatic variables. Once it returns from a function, we can move the stack pointer back up to its previous value. We keep a copy of the old stack pointer value - on the stack! This is why returning from a function is very quick - it’s easy to ‘free’ the memory used by automatic variables - we just need to change the stack pointer.In a multi threaded program, there are multiple stack but only one address space. The pthread library allocates some stack space (either in the heap or using a part of the main program’s stack) and uses the clone function call to start the thread at that stack address. The total address space may look something like this.How many threads can my process have?You can have more than one thread running inside a process. You get the first thread for free! It runs the code you write inside ‘main’. If you need more threads you can call pthread_create to create a new thread using the pthread library. You’ll need to pass a pointer to a function so that the thread knows where to start.The threads you create all live inside the same virtual memory because they are part of the same process. Thus they can all see the heap, the global variables and the program code etc. Thus you can have two (or more) CPUs working on your program at the same time and inside the same process. It’s up to the operating system to assign the threads to CPUs. If you have more active threads than CPUs then the kernel will assign the thread to a CPU for a short duration (or until it runs out of things to do) and then will automatically switch the CPU to work on another thread. For example, one CPU might be processing the game AI while another thread is computing the graphics output.Simple UsageHello world pthread exampleTo use pthreads you will need to include pthread.h AND you need to compile with -pthread (or -lpthread) compiler option. This option tells the compiler that your program requires threading supportTo create a thread use the function pthread_create. This function takes four arguments:int pthread_create(pthread_t *thread, const pthread_attr_t *attr,                   void *(*start_routine) (void *), void *arg);  The first is a pointer to a variable that will hold the id of the newly created thread.  The second is a pointer to attributes that we can use to tweak and tune some of the advanced features of pthreads.  The third is a pointer to a function that we want to run  Fourth is a pointer that will be given to our functionThe argument void *(*start_routine) (void *) is difficult to read! It means a pointer that takes a void * pointer and returns a void * pointer. It looks like a function declaration except that the name of the function is wrapped with (* .... )Here’s the simplest example:#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;// remember to set compilation option -pthreadvoid *busy(void *ptr) {// ptr will point to \"Hi\"    puts(\"Hello World\");    return NULL;}int main() {    pthread_t id;    pthread_create(&amp;id, NULL, busy, \"Hi\");    while (1) {} // Loop forever}If we want to wait for our thread to finish use pthread_joinvoid *result;pthread_join(id, &amp;result);In the above example, result will be null because the busy function returned null.We need to pass the address-of result because pthread_join will be writing into the contents of our pointer.See Pthreads Part 2"
  },{
    "title": "Pthreads, Part 2: Usage in Practice",
    "url": " /wikibook/pthreads-part-2-usage-in-practice",
   "content": "More pthread functionsHow do I create a pthread?See Pthreads Part 1 which introduces pthread_create and pthread_joinIf I call pthread_create twice, how many stacks does my process have?Your process will contain three stacks - one for each thread. The first thread is created when the process starts, and you created two more. Actually there can be more stacks than this, but let’s ignore that complication for now. The important idea is that each thread requires a stack because the stack contains automatic variables and the old CPU PC register, so that it can back to executing the calling function after the function is finished.What is the difference between a full process and a thread?In addition, unlike processes, threads within the same process can share the same global memory (data and heap segments).What does pthread_cancel do?Stops a thread. Note the thread may not actually be stopped immediately. For example it can be terminated when the thread makes an operating system call (e.g. write).In practice, pthread_cancel is rarely used because it does not give a thread an opportunity to clean up after itself (for example, it may have opened some files).An alternative implementation is to use a boolean (int) variable whose value is used to inform other threads that they should finish and clean up.What is the difference between exit and pthread_exit?exit(42) exits the entire process and sets the processes exit value.  This is equivalent to return 42 in the main method. All threads inside the process are stopped.pthread_exit(void *) only stops the calling thread i.e. the thread never returns after calling pthread_exit. The pthread library will automatically finish the process if there are no other threads running. pthread_exit(...) is equivalent to returning from the thread’s function; both finish the thread and also set the return value (void *pointer) for the thread.Calling pthread_exit in the the main thread is a common way for simple programs to ensure that all threads finish. For example, in the following program, the  myfunc threads will probably not have time to get started.int main() {  pthread_t tid1, tid2;  pthread_create(&amp;tid1, NULL, myfunc, \"Jabberwocky\");  pthread_create(&amp;tid2, NULL, myfunc, \"Vorpel\");  exit(42); //or return 42;  // No code is run after exit}The next two programs will wait for the new threads to finish-int main() {  pthread_t tid1, tid2;  pthread_create(&amp;tid1, NULL, myfunc, \"Jabberwocky\");  pthread_create(&amp;tid2, NULL, myfunc, \"Vorpel\");  pthread_exit(NULL);   // No code is run after pthread_exit  // However process will continue to exist until both threads have finished}Alternatively, we join on each thread (i.e. wait for it to finish) before we return from main (or call exit).int main() {  pthread_t tid1, tid2;  pthread_create(&amp;tid1, NULL, myfunc, \"Jabberwocky\");  pthread_create(&amp;tid2, NULL, myfunc, \"Vorpel\");  // wait for both threads to finish :  void* result;  pthread_join(tid1, &amp;result);  pthread_join(tid2, &amp;result);   return 42;}Note the pthread_exit version creates thread zombies, however this is not a long-running processes, so we don’t care.How can a thread be terminated?  Returning from the thread function  Calling pthread_exit  Cancelling the thread with pthread_cancel  Terminating the process (e.g. SIGTERM); exit(); returning from mainWhat is the purpose of pthread_join?  Wait for a thread to finish  Clean up thread resources  Grabs the return value of the threadWhat happens if you don’t call pthread_join?Finished threads will continue to consume resources. Eventually, if enough threads are created, pthread_create will fail.In practice, this is only an issue for long-running processes but is not an issue for simple, short-lived processes as all thread resources are automatically freed when the process exits.Should I use pthread_exit or pthread_join?Both pthread_exit and pthread_join will let the other threads finish on their own (even if called in the main thread). However, only pthread_join will return to you when the specified thread finishes. pthread_exit does not wait and will immediately end your thread and give you no chance to continue executing.Can you pass pointers to stack variables from one thread to another?Yes. However you need to be very careful about the lifetime of stack variables.pthread_t start_threads() {  int start = 42;  pthread_t tid;  pthread_create(&amp;tid, 0, myfunc, &amp;start); // ERROR!  return tid;}The above code is invalid because the function start_threads will likely return before myfunc even starts. The function passes the address-of start, however by the time myfunc is executes, start is no longer in scope and its address will re-used for another variable.The following code is valid because the lifetime of the stack variable is longer than the background thread.void start_threads() {  int start = 42;  void *result;  pthread_t tid;  pthread_create(&amp;tid, 0, myfunc, &amp;start); // OK - start will be valid!  pthread_join(tid, &amp;result);}Intro to Race ConditionsHow can I create ten threads with different starting values.The following code is supposed to start ten threads with values 0,1,2,3,…9However, when run prints out 1 7 8 8 8 8 8 8 8 10! Can you see why?#include &lt;pthread.h&gt;void* myfunc(void* ptr) {    int i = *((int *) ptr);    printf(\"%d \", i);    return NULL;}int main() {    // Each thread gets a different value of i to process    int i;    pthread_t tid;    for(i =0; i &lt; 10; i++) {        pthread_create(&amp;tid, NULL, myfunc, &amp;i); // ERROR    }    pthread_exit(NULL);}The above code suffers from a race condition - the value of i is changing. The new threads start later (in the example output the last thread starts after the loop has finished).To overcome this race-condition, we will give each thread a pointer to it’s own data area. For example, for each thread we may want to store the id, a starting value and an output value:struct T {  pthread_t id;  int start;  char result[100];};These can be stored in an array -struct T *info = calloc(10 , sizeof(struct T)); // reserve enough bytes for ten T structuresAnd each array element passed to each thread -pthread_create(&amp;info[i].id, NULL, func, &amp;info[i]);Why are some functions e.g.  asctime,getenv, strtok, strerror  not thread-safe?To answer this, let’s look at a simple function that is also not ‘thread-safe’char *to_message(int num) {    char static result [256];    if (num &lt; 10) sprintf(result, \"%d : blah blah\" , num);    else strcpy(result, \"Unknown\");    return result;}In the above code the result buffer is stored in global memory. This is good - we wouldn’t want to return a pointer to an invalid address on the stack, but there’s only one result buffer in the entire memory. If two threads were to use it at the same time then one would corrupt the other:            Time      Thread 1      Thread 2      Comments                  1      to_m(5 )                            2             to_m(99)      Now both threads will see “Unknown” stored in the result buffer      What are condition variables, semaphores, mutexes?These are synchronization locks that are used to prevent race conditions and ensure proper synchronization between threads running in the same program. In addition, these locks are conceptually identical to the primitives used inside the kernel.Are there any advantages of using threads over forking processes?Yes! Sharing information between threads is easy because threads (of the same process) live inside the same virtual memory space.Also, creating a thread is significantly faster than creating(forking) a process.Are there any dis-advantages of using threads over forking processes?Yes! No- isolation! As threads live inside the same process, one thread has access to the same virtual memory as the other threads. A single thread can terminate the entire process (e.g. by trying to read address zero).Can you fork a process with multiple threads?Yes! However the child process only has a single thread (which is a clone of the thread that called fork. We can see this as a simple example, where the background threads never print out a second message in the child process.#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;static pid_t child = -2;void *sleepnprint(void *arg) {  printf(\"%d:%s starting up...\\n\", getpid(), (char *) arg);  while (child == -2) {sleep(1);} /* Later we will use condition variables */  printf(\"%d:%s finishing...\\n\",getpid(), (char*)arg);  return NULL;  }int main() {  pthread_t tid1, tid2;  pthread_create(&amp;tid1,NULL, sleepnprint, \"New Thread One\");  pthread_create(&amp;tid2,NULL, sleepnprint, \"New Thread Two\");    child = fork();  printf(\"%d:%s\\n\",getpid(), \"fork()ing complete\");  sleep(3);      printf(\"%d:%s\\n\",getpid(), \"Main thread finished\");    pthread_exit(NULL);  return 0; /* Never executes */}8970:New Thread One starting up...8970:fork()ing complete8973:fork()ing complete8970:New Thread Two starting up...8970:New Thread Two finishing...8970:New Thread One finishing...8970:Main thread finished8973:Main thread finishedIn practice, creating threads before forking can lead to unexpected errors because (as demonstrated above) the other threads are immediately terminated when forking. Another thread might have just lock a mutex (e.g. by calling malloc) and never unlock it again. Advanced users may find pthread_atfork useful however we suggest you usually try to avoid creating threads before forking unless you fully understand the limitations and difficulties of this approach.Are there other reasons where fork might be preferable to creating a thread.Creating separate processes is useful  When more security is desired (for example, Chrome browser uses different processes for different tabs)  When running an existing and complete program then a new process is required (e.g. starting ‘gcc’)  When you are running into synchronization primitives and each process is operating on something in the systemHow can I find out more?See the complete example in the man pageAnd the pthread reference guideALSO: Concise third party sample code explaining create, join and exit"
  },{
    "title": "Pthreads, Part 3: Parallel Problems (Bonus)",
    "url": " /wikibook/pthreads-part-3-parallel-problems-(bonus)",
   "content": "OverviewThe next section deals with what happens when pthreads collide, but what if we have each thread do something entirely different, no overlap?We have found the maximum speedup parallel problems?Embarrassingly Parallel ProblemsThe study of parallel algorithms has exploded over the past few years. An embarrassingly parallel problem is any problem that needs little effort to turn parallel. A lot of them have some synchronization concepts with them but not always. You already know a parallelizable algorithm, Merge Sort!void merge_sort(int *arr, size_t len){     if(len &gt; 1){     //Mergesort the left half     //Mergesort the right half     //Merge the two halves     }With your new understanding of threads, all you need to do is create a thread for the left half, and one for the right half. Given that your CPU has multiple real cores, you will see a speedup in accordance with Amdahl’s Law. The time complexity analysis gets interesting here as well. The parallel algorithm runs in O(log^3(n)) running time (because we fancy analysis assuming that we have a lot of cores.In practice though, we typically do two changes. One, once the array gets small enough, we ditch the parallel mergesort algorithm and do a quicksort or other algorithm that works fast on small arrays (something something cache coherency). The other thing that we know is that CPUs don’t have infinite cores. To get around that, we typically keep a worker pool.Worker PoolWe know that CPUs have a finite amount of cores. A lot of times we start up a number of threads and give them tasks as they idle.Another problem, Parallel MapSay we want to apply a function to an entire array, one element at a time.int *map(int (*func)(int), int *arr, size_t len){    int *ret = malloc(len*sizeof(*arr));    for(size_t i = 0; i &lt; len; ++i)         ret[i] = func(arr[i]);    return ret;}Since none of the elements depend on any other element, how would you go about parallelizing this? What do you think would be the best way to split up the work between threads.SchedulingThere are a few ways to split up the work.  static scheduling: break up the problems into fixed size chunks (predetermined) and have each thread work on each of the chunks. This works well when each of the subproblems take roughly the same time because there is no additional overhead. All you need to do is write a loop and give the map function to each subarray.  dynamic scheduling: as a new problem becomes available have a thread serve it. This is useful when you don’t know how long the scheduling will take  guided scheduling: This is a mix of the above with a mix of the benefits and the tradeoffs. You start with a static scheduling and move slowly to dynamic if needed  runtime scheduling: You have absolutely no idea how long the problems are going to take. Instead of deciding it yourself, let the program decide what to do!source, but no need to memorize.Few DrawbacksYou won’t see the speedup right away because of things like cache coherency and scheduling extra threads.Other ProblemsFrom Wikipedia  Serving static files on a webserver to multiple users at once.  The Mandelbrot set, Perlin noise and similar images, where each point is calculated independently.  Rendering of computer graphics. In computer animation, each frame may be rendered independently (see parallel rendering).  Brute-force searches in cryptography.[8] Notable real-world examples include distributed.net and proof-of-work systems used in cryptocurrency.  BLAST searches in bioinformatics for multiple queries (but not for individual large queries) [9]  Large scale facial recognition systems that compare thousands of arbitrary acquired faces (e.g., a security or surveillance video via closed-circuit television) with similarly large number of previously stored faces (e.g., a rogues gallery or similar watch list).[10]  Computer simulations comparing many independent scenarios, such as climate models.  Evolutionary computation metaheuristics such as genetic algorithms.  Ensemble calculations of numerical weather prediction.  Event simulation and reconstruction in particle physics.  The marching squares algorithm  Sieving step of the quadratic sieve and the number field sieve.  Tree growth step of the random forest machine learning technique.  Discrete Fourier Transform where each harmonic is independently calculated."
  },{
    "title": "RPC, Part 1: Introduction to Remote Procedure Calls",
    "url": " /wikibook/rpc-part-1-introduction-to-remote-procedure-calls",
   "content": "What is RPC?Remote Procedure Call. RPC is the idea that we can execute a procedure (function) on a different machine. In practice the procedure may execute on the same machine, however it may be in a different context - for example under a different user with different permissions and different lifecycle.What is Privilege Separation?The remote code will execute under a different user and with different privileges from the caller. In practice the remote call may execute with more or fewer privileges than the caller. This in principle can be used to improve the security of a system (by ensuring components operate with least privilege). Unfortunately, security concerns need to be carefully assessed to ensure that RPC mechanisms cannot be subverted to perform unwanted actions. For example, an RPC implementation may implicitly trust any connected client to perform any action, rather than a subset of actions on a subset of the data.What is stub code? What is marshalling?The stub code is the necessary code to hide the complexity of performing a remote procedure call. One of the roles of the stub code is to marshall the necessary data into a format that can be sent as a byte stream to a remote server.// On the outside 'getHiscore' looks like a normal function call// On the inside the stub code performs all of the work to send and receive the data to and from the remote machine.int getHiscore(char* game) {  // Marshall the request into a sequence of bytes:  char* buffer;  asprintf(&amp;buffer,\"getHiscore(%s)!\", name);  // Send down the wire (we do not send the zero byte; the '!' signifies the end of the message)  write(fd, buffer, strlen(buffer) );  // Wait for the server to send a response  ssize_t bytesread = read(fd, buffer, sizeof(buffer));  // Example: unmarshal the bytes received back from text into an int  buffer[bytesread] = 0; // Turn the result into a C string  int score= atoi(buffer);  free(buffer);  return score;}What is server stub code? What is unmarshalling?The server stub code will receive the request, unmarshall the request into a valid in-memory data call the underlying implementation and send the result back to the caller.How do you send an int? float? a struct?  A linked list? A graph?To implement RPC you need to decide (and document) which conventions you will use to serialize the data into a byte sequence. Even a simple integer has several common choices:  Signed or unsigned?  ASCII  Fixed number of bytes or variable depending on magnitude  Little or Big endian binary format?To marshall a struct, decide which fields need to be serialized. It may not be necessary to send all data items (for example, some items may be irrelevant to the specific RPC or can be re-computed by the server from the other data items present).To marshall a linked list it is unnecessary to send the link pointers- just stream the values. As part of unmarshalling the server can recreate a linked list structure from the byte sequence.By starting at the head node/vertex, a simple tree can be recursively visited to create a serialized version of the data. A cyclic graph will usually require additional memory to ensure that each edge and vertex is processed exactly once.What is an IDL (Interface Description Language)?Writing stub code by hand is painful, tedious, error prone, difficult to maintain and difficult to reverse engineer the wire protocol from the implemented code. A better approach is specify the data objects, messages and services and automatically generate the client and server code.A modern example of an Interface Description Language is Google’s Protocol Buffer .proto files.Complexity and challenges of RPC vs local calls?Remote Procedure Calls are significantly slower (10x to 100x) and more complex than local calls. An RPC must marshall data into a wire-compatible format. This may require multiple passes through the data structure, temporary memory allocation and transformation of the data representation.Robust RPC stub code must intelligently handle network failures and versioning. For example, a server may have to process requests from clients that are still running an early version of the stub code.A secure RPC will need to implement additional security checks (including authentication and authorization), validate data and encrypt communication between the client and host.Transferring large amounts of structured dataLet’s examine three methods of transferring data using 3 different formats - JSON, XML and Google Protocol Buffers. JSON and XML are text-based protocols. Examples of JSON and XML messages are below.&lt;ticket&gt;&lt;price currency='dollar'&gt;10&lt;/price&gt;&lt;vendor&gt;travelocity&lt;/vendor&gt;&lt;/ticket&gt;{ 'currency':'dollar' , 'vendor':'travelocity', 'price':'10' }Google Protocol Buffers is an open-source efficient binary protocol that places a strong emphasis on high throughput with low CPU overhead and minimal memory copying. Implementations exist for multiple languages including Go, Python, C++ and C. This means client and server stub code in multiple languages can be generated from the .proto specification file to marshall data to and from a binary stream.Google Protocol Buffers reduces the versioning problem by ignoring unknown fields that are present in a message. See the introduction to Protocol Buffers for more information.[[https://developers.google.com/protocol-buffers/docs/overview]]"
  },{
    "title": "Sample program using pthread barriers",
    "url": " /wikibook/sample-program-using-pthread-barriers",
   "content": "#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;time.h&gt;#define THREAD_COUNT 4pthread_barrier_t mybarrier;void* threadFn(void *id_ptr) {  int thread_id = *(int*)id_ptr;  int wait_sec = 1 + rand() % 5;  printf(\"thread %d: Wait for %d seconds.\\n\", thread_id, wait_sec);  sleep(wait_sec);  printf(\"thread %d: I'm ready...\\n\", thread_id);  pthread_barrier_wait(&amp;mybarrier);  printf(\"thread %d: going!\\n\", thread_id);  return NULL;}int main() {  int i;  pthread_t ids[THREAD_COUNT];  int short_ids[THREAD_COUNT];  srand(time(NULL));  pthread_barrier_init(&amp;mybarrier, NULL, THREAD_COUNT + 1);  for (i=0; i &lt; THREAD_COUNT; i++) {    short_ids[i] = i;    pthread_create(&amp;ids[i], NULL, threadFn, &amp;short_ids[i]);  }  printf(\"main() is ready.\\n\");  pthread_barrier_wait(&amp;mybarrier);  printf(\"main() is going!\\n\");  for (i=0; i &lt; THREAD_COUNT; i++) {    pthread_join(ids[i], NULL);  }  pthread_barrier_destroy(&amp;mybarrier);  return 0;}"
  },{
    "title": "Scheduling, Part 1: Scheduling Processes",
    "url": " /wikibook/scheduling-part-1-scheduling-processes",
   "content": "Thinking about scheduling.CPU Scheduling is the problem of efficiently selecting which process to run on a system’s CPU cores. In a busy system there will be more ready-to-run processes than there are CPU cores, so the system kernel must evaluate which processes should be scheduled to run on the CPU and which processes should be placed in a ready queue to be executed later.The additional complexity of multi-threaded and multiple CPU cores are considered a distraction to this initial exposition so are ignored here.Another gotcha for non-native speakers is the dual meanings of “Time”: The word “Time” can be used in both clock and elapsed duration context. For example “The arrival time of the first process was 9:00am.” and, “The running time of the algorithm is 3 seconds”.How is scheduling measured and which scheduler is best?Scheduling affects the performance of the system, specifically the latency and throughput of the system. The throughput might be measured by a system value, for example the I/O throughput - the number of bytes written per second, or number of small processes that can complete per unit time, or using a higher level of abstraction for example number of customer records processed per minute. The latency might be measured by the response time (elapse time before a process can start to send a response) or wait time or turnaround time (the elapsed time to complete a task). Different schedulers offer different optimization trade-offs that may or may not be appropriate to desired use - there is no optimal scheduler for all possible environments and goals. For example ‘shortest-job-first’ will minimize total wait time across all jobs but in interactive (UI) environments it would be preferable to minimize response time (at the expense of some throughput), while FCFS seems intuitively fair and easy to implement but suffers from the Convoy Effect.What is arrival time?The time at which a process first arrives at the ready queue, and is ready to start executing. If a CPU is idle, the arrival time would also be the starting time of execution.What is preemption?Without preemption processes will run until they are unable to utilize the CPU any further. For example the following conditions would remove a process from the CPU and the CPU would be available to be scheduled for other processes: The process terminates due to a signal, is blocked waiting for concurrency primitive, or exits normally.Thus once a process is scheduled it will continue even if another process with a high priority (e.g. shorter job) appears on the ready queue.With preemption, the existing processes may be removed immediately if a more preferable process is added to the ready queue. For example, suppose at t=0 with a Shortest Job First scheduler there are two processes (P1 P2) with 10 and 20 ms execution times. P1 is scheduled. P1 immediately creates a new process P3, with execution time of 5 ms, which is added to the ready queue. Without preemption, P3 will run 10ms later (after P1 has completed). With preemption, P1 will be immediately evicted from the CPU and instead placed back in the ready queue, and P3 will be executed instead by the CPU.Which schedulers suffer from starvation?Any scheduler that uses a form of prioritization can result in starvation because earlier processes may never be scheduled to run (assigned a CPU). For example with SJF, longer jobs may never be scheduled if the system continues to have many short jobs to schedule. It all depends on the type of scheduler.Why might a process (or thread) be placed on the ready queue?A process is placed on the ready queue when it is able to use a CPU. Some examples include:  A process was blocked waiting for a read from storage or socket to complete and data is now available.  A new process has been created and is ready to start.  A process thread was blocked on a synchronization primitive (condition variable, semaphore, mutex lock) but is now able to continue.  A process is blocked waiting for a system call to complete but a signal has been delivered and the signal handler needs to run.Similar examples can be generated when considering threads.Measures of Efficiencystart_time is the wall-clock start time of the process (CPU starts working on it)end_time is the end wall-clock of the process (CPU finishes the process)run_time is the total amount of CPU time requiredarrival_time is the time the process enters the scheduler (CPU may not start working on it)What is ‘turnaround time’?The total time from when you the process arrives to when it ends.turnaround_time = end_time - arrival_timeWhat is ‘response time’?The total latency (time) that it takes from when the process arrives to when the CPU actually starts working on it.response_time = start_time - arrival_timeWhat is ‘wait time’?Wait time is the total wait time i.e. the total time that a process is on the ready queue. A common mistake is to believe it is only the initial waiting time in the ready queue.If a CPU intensive process with no I/O takes 7 minutes of CPU time to complete but required 9 minutes of wall-clock time to complete we can conclude that it was placed on the ready-queue for 2 minutes. For those 2 minutes the process was ready to run but had no CPU assigned. It does not matter when the job was waiting, the wait time is 2 minutes.wait_time  = (end_time - arrival_time) - run_timeWhat is the Convoy Effect?“The Convoy Effect is where I/O intensive processes are continually backed up, waiting for CPU-intensive processes that hog the CPU. This results in poor I/O performance, even for processes that have tiny CPU needs.”Suppose the CPU is currently assigned to a CPU intensive task and there is a set of I/O intensive processes that are in the ready queue. These processes require just a tiny amount of CPU time but they are unable to proceed because they are waiting for the CPU-intensive task to be removed from the processor. These processes are starved until the the CPU bound process releases the CPU. But the CPU will rarely be released (for example in the case of a FCFS scheduler, we must wait until the processes is blocked due to an I/O request). The I/O intensive processes can now finally satisfy their CPU needs, which they can do quickly because their CPU needs are small and the CPU is assigned back to the CPU-intensive process again. Thus the I/O performance of the whole system suffers through an indirect effect of starvation of CPU needs of all processes.This effect is usually discussed in the context of FCFS scheduler, however a round robin scheduler can also exhibit the Convoy effect for long time-quanta.Linux SchedulingAs of February 2016, Linux by default uses the Completely Fair Scheduler for CPU scheduling and the Budget Fair Scheduling “BFQ” for I/O scheduling. Appropriate scheduling can have a significant impact on throughput and latency. Latency is particularly important for interactive and soft-real time applications such as audio and video streaming. See the discussion and comparative benchmarks here for more information.Here is how the CFS schedules  The CPU creates a Red-Black tree with the processes virtual runtime (runtime / nice_value) and sleeper fairness (if the process is waiting on something give it the CPU when it is done waiting).  (Nice values are the kernel’s way of giving priority to certain processes, the lower nice value the higher priority)  The kernel chooses the lowest one based on this metric and schedules that process to run next, taking it off the queue. Since the red-black tree is self balancing this operation is guaranteed $O(log(n))$ (selecting the min process is the same runtime)Although it is called the Fair Scheduler there are a fair bit of problems.  Groups of processes that are scheduled may have imbalanced loads so the scheduler roughly distributes the load. When another CPU gets free it can only look at the average load of a group schedule not the individual cores. So the free CPU may not take the work from a CPU that is burning so long as the average is fine.  If a group of processes is running on non-adjacent cores then there is a bug. If the two cores are more than a hop away, the load balancing algorithm won’t even consider that core. Meaning if a CPU is free and a CPU that is doing more work is more than a hop away, it won’t take the work (may have been patched).  After a thread goes to sleep on a subset of cores, when it wakes up it can only be scheduled on the cores that it was sleeping on. If those cores are now busy, the thread will have to wait on them, wasting opportunities to use other idle cores.  To read more on the problems of the Fair Scheduler, read here."
  },{
    "title": "Scheduling, Part 2: Scheduling Processes: Algorithms",
    "url": " /wikibook/scheduling-part-2-scheduling-processes-algorithms",
   "content": "What are some well known scheduling algorithms?For all the examples,Process 1: Runtime 1000msProcess 2: Runtime 2000msProcess 3: Runtime 3000msProcess 4: Runtime 4000msProcess 5: Runtime 5000msShortest Job First (SJF)  P1 Arrival: 0ms  P2 Arrival: 0ms  P3 Arrival: 0ms  P4 Arrival: 0ms  P5 Arrival: 0msThe processes all arrive at the start and the scheduler schedules the job with the shortest total CPU time. The glaring problem is that this scheduler needs to know how long this program will run over time before it ran the program.Technical Note: A realistic SJF implementation would not use the total execution time of the process but the burst time (the total CPU time including future computational execution before the process will no longer be ready to run). The expected burst time can be estimated by using an exponentially decaying weighted rolling average based on the previous burst time but for this exposition we will simplify this discussion to use the total running time of the process as a proxy for the burst time.Advantages  Shorter jobs tend to get run firstDisadvantages  Needs algorithm to be omniscientPreemptive Shortest Job First (PSJF)Preemptive shortest job first is like shortest job first but if a new job comes in with a shorter runtime than the total runtime of the current job, it is run instead. (If it is equal like our example our algorithm can choose). The scheduler uses the total runtime of the process. If you want the shortest remaining time left, that is a variant of PSJF called Shortest Remaining Time First (SRTF).  P2 at 0ms  P1 at 1000ms  P5 at 3000ms  P4 at 4000ms  P3 at 5000msHere’s what our algorithm does. It runs P2 because it is the only thing to run. Then P1 comes in at 1000ms, P2 runs for 2000ms, so our scheduler preemptively stops P2, and let’s P1 run all the way through (this is completely up to the algorithm because the times are equal). Then, P5 Comes in – since there are no processes running, the scheduler will run process 5. P4 comes in, and since the runtimes are equal P5, the scheduler stops P5 and runs P4. Finally P3 comes in, preempts P4, and runs to completion. Then P4 runs, then P5 runs.Advantages  Ensures shorter jobs get run firstDisadvantages  Need to know the runtime againFirst Come First Served (FCFS)  P2 at 0ms  P1 at 1000ms  P5 at 3000ms  P4 at 4000ms  P3 at 5000msProcesses are scheduled in the order of arrival. One advantage of FCFS is that scheduling algorithm is simple: the ready queue is a just a FIFO (first in first out) queue.FCFS suffers from the Convoy effect.Here P2 Arrives, then P1 arrives, then P5, then P4, then P3. You can see the convoy effect for P5.Advantages  Simple implementationDisadvantages  Long running processes could block all other processesRound Robin (RR)Processes are scheduled in order of their arrival in the ready queue. However after a small time step a running process will be forcibly removed from the running state and placed back on the ready queue. This ensures that a long-running process can not starve all other processes from running.The maximum amount of time that a process can execute before being returned to the ready queue is called the time quanta. In the limit of large time quanta (where the time quanta is longer than the running time of all processes) round robin will be equivalent to FCFS.  P1 Arrival: 0ms  P2 Arrival: 0ms  P3 Arrival: 0ms  P4 Arrival: 0ms  P5 Arrival: 0msQuantum = 1000msHere all processes arrive at the same time. P1 is run for 1 quantum and is finished. P2 for one quantum; then, it is stopped for P3. After all other processes run for a quantum we cycle back to P2 until all the processes are finished.Advantages  Ensures some notion of fairnessDisadvantages  Large number of processes = Lots of switchingPriorityProcesses are scheduled in the order of priority value. For example, a navigation process might be more important to execute than a logging process."
  },{
    "title": "Signals, Part 2: Pending Signals and Signal Masks",
    "url": " /wikibook/signals-part-2-pending-signals-and-signal-masks",
   "content": "Signals In DepthHow can I learn more about signals?The linux man pages discusses signal system calls in section 2. There is also a longer article in section 7 (though not in OSX/BSD):man -s7 signalSignal Terminology  Generated - The signal is being created in the kernel by the kill system call.  Pending - Not delivered yet but soon to be delivered  Blocked - Not delivered because no signal disposition lets the signal be delivered  Delivered - Delivered to the process, the action described is being taken  Caught - When the process stops a signal from destroying it and does something else with it insteadWhat is a process’s signal disposition?For each process, each signal has a disposition which means what action will occur when a signal is delivered to the process. For example, the default disposition SIGINT is to terminate it. The signal disposition can be changed by calling signal() (which is simple but not portable as there are subtle variations in its implementation on different POSIX architectures and also not recommended for multi-threaded programs) or sigaction (discussed later). You can imagine the processes’ disposition to all possible signals as a table of function pointers entries (one for each possible signal).The default disposition for signals can be to ignore the signal, stop the process, continue a stopped process, terminate the process, or terminate the process and also dump a ‘core’ file. Note a core file is a representation of the processes’ memory state that can be inspected using a debugger.Can multiple signals be queued?No - however it is possible to have signals that are in a pending state. If a signal is pending, it means it has not yet been delivered to the process. The most common reason for a signal to be pending is that the process (or thread) has currently blocked that particular signal.If a particular signal, e.g. SIGINT, is pending then it is not possible to queue up the same signal again.It is possible to have more than one signal of a different type in a pending state. For example SIGINT and SIGTERM signals may be pending (i.e. not yet delivered to the target process)How do I block signals?Signals can be blocked (meaning they will stay in the pending state) by setting the process signal mask or, when you are writing a multi-threaded program, the thread signal mask.Disposition in Threads/ChildrenWhat happens when creating a new thread?The new thread inherits a copy of the calling thread’s maskpthread_sigmask( ... ); // set my mask to block delivery of some signalspthread_create( ... ); // new thread will start with a copy of the same maskWhat happens when forking?The child process inherits a copy of the parent’s signal dispositions. In other words, if you have installed a SIGINT handler before forking, then the child process will also call the handler if a SIGINT is delivered to the child.Note pending signals for the child are not inherited during forking.What happens during exec?Both the signal mask and the signal disposition carries over to the exec-ed program. https://www.gnu.org/software/libc/manual/html_node/Executing-a-File.html#Executing-a-File Pending signals are preserved as well.  Signal handlers are reset, because the original handler code has disappeared along with the old process.What happens during fork?The child process inherits a copy of the parent process’s signal disposition and a copy of the parent’s signal mask.For example if SIGINT is blocked in the parent it will be blocked in the child too.For example if the parent installed a handler (call-back function) for SIG-INT then the child will also perform the same behavior.Pending signals however are not inherited by the child.How do I block signals in a single-threaded program?Use sigprocmask! With sigprocmask you can set the new mask, add new signals to be blocked to the process mask, and unblock currently blocked signals. You can also determine the existing mask (and use it for later) by passing in a non-null value for oldset.int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);`From the Linux man page of sigprocmask,SIG_BLOCK: The set of blocked signals is the union of the current set and the set argument.SIG_UNBLOCK: The signals in set are removed from the current set of blocked signals. It is permissible to attempt to unblock a signal which is not blocked.SIG_SETMASK: The set of blocked signals is set to the argument set.The sigset type behaves as a bitmap, except functions are used rather than explicitly setting and unsetting bits using &amp; and |.It is a common error to forget to initialize the signal set before modifying one bit. For example,sigset_t set, oldset;sigaddset(&amp;set, SIGINT); // Ooops!sigprocmask(SIG_SETMASK, &amp;set, &amp;oldset)Correct code initializes the set to be all on or all off. For example,sigfillset(&amp;set); // all signalssigprocmask(SIG_SETMASK, &amp;set, NULL); // Block all the signals!// (Actually SIGKILL or SIGSTOP cannot be blocked...)sigemptyset(&amp;set); // no signals sigprocmask(SIG_SETMASK, &amp;set, NULL); // set the mask to be empty againHow do I block signals in a multi-threaded program?Blocking signals is similar in multi-threaded programs to single-threaded programs:  Use pthread_sigmask instead of sigprocmask  Block a signal in all threads to prevent its asynchronous deliveryThe easiest method to ensure a signal is blocked in all threads is to set the signal mask in the main thread before new threads are createdsigemptyset(&amp;set);sigaddset(&amp;set, SIGQUIT);sigaddset(&amp;set, SIGINT);pthread_sigmask(SIG_BLOCK, &amp;set, NULL);// this thread and the new thread will block SIGQUIT and SIGINTpthread_create(&amp;thread_id, NULL, myfunc, funcparam);Just as we saw with sigprocmask, pthread_sigmask includes a ‘how’ parameter that defines how the signal set is to be used:pthread_sigmask(SIG_SETMASK, &amp;set, NULL); // replace the thread's mask with given signal setpthread_sigmask(SIG_BLOCK, &amp;set, NULL);   // add the signal set to the thread's maskpthread_sigmask(SIG_UNBLOCK, &amp;set, NULL); // remove the signal set from the thread's maskHow are pending signals delivered in a multi-threaded program?A signal is delivered to any signal thread that is not blocking that signal.If the two or more threads can receive the signal then which thread will be interrupted is arbitrary!"
  },{
    "title": "Signals, Part 3: Raising signals",
    "url": " /wikibook/signals-part-3-raising-signals",
   "content": "How do I send a signal to a process from the shell?You already know one way to send a SIG_INT just type CTRL-C From the shell you can use kill (if you know the process id) and killall (if you know the process name)# First let's use ps and grep to find the process we want to send a signal to$ ps au | grep myprogramangrave  4409   0.0  0.0  2434892    512 s004  R+    2:42PM   0:00.00 myprogram 1 2 3#Send SIGINT signal to process 4409 (equivalent of `CTRL-C`)$ kill -SIGINT 4409#Send SIGKILL (terminate the process)$ kill -SIGKILL 4409$ kill -9 4409killall is similar except that it matches by program name. The next two example, sends a SIGINT and then SIGKILL to terminate the processes that are running myprogram# Send SIGINT (SIGINT can be ignored)$ killall -SIGINT myprogram# SIGKILL (-9) cannot be ignored! $ killall -9 myprogramHow do I send a signal to a process from the running C program?Use raise or killint raise(int sig); // Send a signal to myself!int kill(pid_t pid, int sig); // Send a signal to another processFor non-root processes, signals can only be sent to processes of the same user i.e. you cant just SIGKILL my processes! See kill(2) i.e. man -s2 for more details.How do I send a signal to a specific thread?Use pthread_killint pthread_kill(pthread_t thread, int sig)In the example below, the newly created thread executing func will be interrupted by SIGINTpthread_create(&amp;tid, NULL, func, args);pthread_kill(tid, SIGINT);pthread_kill(pthread_self(), SIGKILL); // send SIGKILL to myselfWill pthread_kill(threadid, SIGKILL) kill the process or thread?It will kill the entire process. Though individual threads can set a signal mask, the signal disposition (the table of handlers/action performed for each signal) is per-process not per-thread. This means sigaction can be called from any thread because you will be setting a signal handler for all threads in the process.How do I catch (handle) a signal?You can choose a handle pending signals asynchronously or synchronously.Install a signal handler to asynchronously handle signals use sigaction (or, for simple examples, signal).To synchronously catch a pending signal use sigwait (which blocks until a signal is delivered) or signalfd (which also blocks and provides a file descriptor that can be read() to retrieve pending signals).See Signals, Part 4 for an example of using sigwait"
  },{
    "title": "Signals, Part 4: Sigaction",
    "url": " /wikibook/signals-part-4-sigaction",
   "content": "How and why do I use sigaction ?You should use sigaction instead of signal because it has better defined semantics. signal on different operating system does different things which is bad. sigaction is more portable and is better defined for threads if need be.To change the “signal disposition” of a process - i.e. what happens when a signal is delivered to your process - use sigactionYou can use system call sigaction to set the current handler for a signal or read the current signal handler for a particular signal.int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);The sigaction struct includes two callback functions (we will only look at the ‘handler’ version), a signal mask and a flags field -struct sigaction {    void     (*sa_handler)(int);    void     (*sa_sigaction)(int, siginfo_t *, void *);    sigset_t   sa_mask;    int        sa_flags;}; How do I convert a signal call into the equivalent sigaction call?Suppose you installed a signal handler for the alarm signal,signal(SIGALRM, myhandler);The equivalent sigaction code is:struct sigaction sa; sa.sa_handler = myhandler;sigemptyset(&amp;sa.sa_mask);sa.sa_flags = 0; sigaction(SIGALRM, &amp;sa, NULL)However, we typically may also set the mask and the flags field. The mask is a temporary signal mask used during the signal handler execution. The SA_RESTART flag will automatically restart some (but not all) system calls that otherwise would have returned early (with EINTR error). The latter means we can simplify the rest of code somewhat because a restart loop may no longer be required.sigfillset(&amp;sa.sa_mask);sa.sa_flags = SA_RESTART; /* Restart functions if  interrupted by handler */     How do I use sigwait?Sigwait can be used to read one pending signal at a time. sigwait is used to synchronously wait for signals, rather than handle them in a callback. A typical use of sigwait in a multi-threaded program is shown below. Notice that the thread signal mask is set first (and will be inherited by new threads). This prevents signals from being delivered so they will remain in a pending state until sigwait is called. Also notice the same set sigset_t variable is used by sigwait - except rather than setting the set of blocked signals it is being used as the set of signals that sigwait can catch and return.One advantage of writing a custom signal handling thread (such as the example below) rather than a callback function is that you can now use many more C library and system functions that otherwise could not be safely used in a signal handler because they are not async signal-safe.Based on http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_sigmask.htmlstatic sigset_t   signal_mask;  /* signals to block         */int main (int argc, char *argv[]) {    pthread_t sig_thr_id;      /* signal handler thread ID */    sigemptyset(&amp;signal_mask);    sigaddset(&amp;signal_mask, SIGINT);    sigaddset(&amp;signal_mask, SIGTERM);    pthread_sigmask(SIG_BLOCK, &amp;signal_mask, NULL);    /* New threads will inherit this thread's mask */    pthread_create(&amp;sig_thr_id, NULL, signal_thread, NULL);    /* APPLICATION CODE */    ...}void *signal_thread (void *arg) {    int       sig_caught;    /* signal caught       */    /* Use same mask as the set of signals that we'd like to know about! */    sigwait(&amp;signal_mask, &amp;sig_caught);    switch (sig_caught) {    case SIGINT:     /* process SIGINT  */        ...        break;    case SIGTERM:    /* process SIGTERM */        ...        break;    default:         /* should normally not happen */        fprintf(stderr, \"\\nUnexpected signal %d\\n\", sig_caught);        break;    }}"
  },{
    "title": "Signals Review Questions",
    "url": " /wikibook/signals-review-questions",
   "content": "Topics  Signals  Signal Handler Safe  Signal Disposition  Signal States  Pending Signals when Forking/Exec  Signal Disposition when Forking/Exec  Raising Signals in C  Raising Signals in a multithreaded programQuestions  What is a signal?  How are signals served under UNIX? (Bonus: How about Windows?)  What does it mean that a function is signal handler safe  What is a process Signal Disposition?  How do I change the signal disposition in a single threaded program? How about multithreaded?  Why sigaction vs signal?  How do I asynchronously and synchronously catch a signal?  What happens to pending signals after I fork? Exec?  What happens to my signal disposition after I fork? Exec?"
  },{
    "title": "Synchronization Concepts: Review Questions",
    "url": " /wikibook/synchronization-concepts-review-questions",
   "content": "  Note thread-programming synchronization problems are on a separate wiki page. This page focuses on conceptual topics.Question numbers subject to changeQ1What do each of the Coffman conditions mean? (e.g. can you provide a definition of each one)  Hold and wait  Circular wait  No pre-emption  Mutual exclusionQ2Give a real life example of breaking each Coffman condition in turn. A situation to consider: Painters, paint and paint brushes.Hold and waitCircular waitNo pre-emptionMutual exclusionQ3Identify when Dining Philosophers code causes a deadlock (or not). For example, if you saw the following code snippet which Coffman condition is not satisfied?// Get both locks or none.pthread_mutex_lock(a);if (pthread_mutex_trylock(b)) { /* failed */    pthread_mutex_unlock(a);    ...}Q4How many processes are blocked?  P1 acquires R1  P2 acquires R2  P1 acquires R3  P2 waits for R3  P3 acquires R5  P1 acquires R4  P3 waits for R1  P4 waits for R5  P5 waits for R1Q5How many of the following statements are true for the reader-writer problem?  There can be multiple active readers  There can be multiple active writers  When there is an active writer the number of active readers must be zero  If there is an active reader the number of active writers must be zero  A writer must wait until the current active readers have finished"
  },{
    "title": "Synchronization, Part 1: Mutex Locks",
    "url": " /wikibook/synchronization-part-1-mutex-locks",
   "content": "Solving Critical SectionsWhat is a Critical Section?A critical section is a section of code that can only be executed by one thread at a time, if the program is to function correctly. If two threads (or processes) were to execute code inside the critical section at the same time then it is possible that program may no longer have correct behavior.Is just incrementing a variable a critical section?Possibly. Incrementing a variable (i++) is performed in three individual steps: Copy the memory contents to the CPU register. Increment the value in the CPU. Store the new value in memory. If the memory location is only accessible by one thread (e.g. automatic variable i below) then there is no possibility of a race condition and no Critical Section associated with i. However the sum variable is a global variable and accessed by two threads. It is possible that two threads may attempt to increment the variable at the same time.#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;// Compile with -pthreadint sum = 0; //sharedvoid *countgold(void *param) {    int i; //local to each thread    for (i = 0; i &lt; 10000000; i++) {        sum += 1;    }    return NULL;}int main() {    pthread_t tid1, tid2;    pthread_create(&amp;tid1, NULL, countgold, NULL);    pthread_create(&amp;tid2, NULL, countgold, NULL);        //Wait for both threads to finish:    pthread_join(tid1, NULL);    pthread_join(tid2, NULL);        printf(\"ARRRRG sum is %d\\n\", sum);    return 0;}Typical output of the above code is ARGGGH sum is 8140268A different sum is printed each time the program is run because there is a race condition; the code does not stop two threads from reading-writing sum at the same time. For example both threads copy the current value of sum into CPU that runs each thread (let’s pick 123). Both threads increment one to their own copy. Both threads write back the value (124). If the threads had accessed the sum at different times then the count would have been 125.How do I ensure only one thread at a time can access a global variable?You mean, “Help - I need a mutex!”If one thread is currently inside a critical section we would like another thread to wait until the first thread is complete. For this purpose we can use a mutex (short for Mutual Exclusion).For simple examples the smallest amount of code we need to add is just three lines:pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER; // global variablepthread_mutex_lock(&amp;m);   // start of Critical Sectionpthread_mutex_unlock(&amp;m); // end of Critical SectionOnce we are finished with the mutex we should also call pthread_mutex_destroy(&amp;m) too. Note, you can only destroy an unlocked mutex. Calling destroy on a destroyed lock, initializing an initialized lock, locking an already locked lock, unlocking an unlocked lock etc are unsupported (at least for default mutexes) and usually result in undefined behavior.If I lock a mutex, does it stop all other threads?No, the other threads will continue. It’s only when a thread attempts to lock a mutex that is already locked, will the thread have to wait. As soon as the original thread unlocks the mutex, the second (waiting) thread will acquire the lock and be able to continue.Are there other ways to create a mutex?Yes. You can use the macro PTHREAD_MUTEX_INITIALIZER only for global (‘static’) variables.m = PTHREAD_MUTEX_INITIALIZER is equivalent to the more general purposepthread_mutex_init(&amp;m,NULL). The init version includes options to trade performance for additional error-checking and advanced sharing options.pthread_mutex_t *lock = malloc(sizeof(pthread_mutex_t)); pthread_mutex_init(lock, NULL);//laterpthread_mutex_destroy(lock);free(lock);Things to keep in mind about init and destroy:  Multiple threads init/destroy has undefined behavior  Destroying a locked mutex has undefined behavior  Basically try to keep to the pattern of one thread initializing a mutex and one and only one thread initializing a mutex.Mutex GotchasSo pthread_mutex_lock stops the other threads when they read the same variable?No. A mutex is not that smart - it works with code (threads), not data. Only when another thread calls lock on a locked mutex will the second thread need to wait until the mutex is unlocked.Considerint a;pthread_mutex_t m1 = PTHREAD_MUTEX_INITIALIZER,                m2 = PTHREAD_MUTEX_INITIALIZER;// later// Thread 1pthread_mutex_lock(&amp;m1);a++;pthread_mutex_unlock(&amp;m1);// Thread 2pthread_mutex_lock(&amp;m2);a++;pthread_mutex_unlock(&amp;m2);Will still cause a race condition.Can I create mutex before fork-ing?Yes - however the child and parent process will not share virtual memory and each one will have a mutex independent of the other.(Advanced note: There are advanced options using shared memory that allow a child and parent to share a mutex if it’s created with the correct options and uses a shared memory segment. See stackoverflow example)If one thread locks a mutex can another thread unlock it?No. The same thread must unlock it.Can I use two or more mutex locks?Yes! In fact it’s common to have one lock per data structure that you need to update.If you only have one lock, then they may be significant contention for the lock between two threads that was unnecessary. For example if two threads were updating two different counters, it might not be necessary to use the same lock.However simply creating many locks is insufficient: It’s important to be able to reason about critical sections e.g. it’s important that one thread can’t read two data structures while they are being updated and temporarily in an inconsistent state.Is there any overhead in calling lock and unlock?There is a small amount of overhead of calling pthread_mutex_lock and _unlock; however this is the price you pay for correctly functioning programs!Simplest complete example?A complete example is shown below#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;// Compile with -pthread// Create a mutex this ready to be locked!pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;int sum = 0;void *countgold(void *param) {    int i;        // Same thread that locks the mutex must unlock it    // Critical section is just 'sum += 1'    // However locking and unlocking a million times    // has significant overhead in this simple answer        pthread_mutex_lock(&amp;m);    // Other threads that call lock will have to wait until we call unlock    for (i = 0; i &lt; 10000000; i++) {\tsum += 1;    }    pthread_mutex_unlock(&amp;m);    return NULL;}int main() {    pthread_t tid1, tid2;    pthread_create(&amp;tid1, NULL, countgold, NULL);    pthread_create(&amp;tid2, NULL, countgold, NULL);    //Wait for both threads to finish:    pthread_join(tid1, NULL);    pthread_join(tid2, NULL);    printf(\"ARRRRG sum is %d\\n\", sum);    return 0;}In the code above, the thread gets the lock to the counting house before entering. The critical section is only the sum += 1 so the following version is also correct but slower -    for (i = 0; i &lt; 10000000; i++) {        pthread_mutex_lock(&amp;m);        sum += 1;        pthread_mutex_unlock(&amp;m);    }    return NULL;}This process runs slower because we lock and unlock the mutex a million times, which is expensive - at least compared with incrementing a variable. (And in this simple example we didn’t really need threads - we could have added up twice!)  A faster multi-thread example would be to add one million using an automatic(local) variable and only then adding it to a shared total after the calculation loop has finished:    int local = 0;    for (i = 0; i &lt; 10000000; i++) {       local += 1;    }    pthread_mutex_lock(&amp;m);    sum += local;    pthread_mutex_unlock(&amp;m);    return NULL;}What happens if I forget to unlock?Deadlock! We will talk about deadlock a little bit later but what is the problem with this loop if called by multiple threads.while (not_stop) {    // stdin may not be thread safe    pthread_mutex_lock(&amp;m);    char *line = getline(...);    if (rand() % 2) { /* randomly skip lines */         continue;    }    pthread_mutex_unlock(&amp;m);        process_line(line);}When can I destroy the mutex?You can only destroy an unlocked mutex.Can I copy a pthread_mutex_t to a new memory locaton?No, copying the bytes of the mutex to a new memory location and then using the copy is not supported.What would a simple implementation of a mutex look like?A simple (but incorrect!) suggestion is shown below. The unlock function simply unlocks the mutex and returns. The lock function first checks to see if the lock is already locked. If it is currently locked, it will keep checking again until another thread has unlocked the mutex.// Version 1 (Incorrect!)void lock(mutex_t *m) {    while(m-&gt;locked) { /*Locked? Nevermind - just loop and check again!*/ }    m-&gt;locked = 1;}void unlock(mutex_t *m) {    m-&gt;locked = 0;}Version 1 uses ‘busy-waiting’ (unnecessarily wasting CPU resources) however there is a more serious problem: We have a race-condition!If two threads both called lock concurrently it is possible that both threads would read ‘m_locked’ as zero. Thus both threads would believe they have exclusive access to the lock and both threads will continue. Ooops!We might attempt to reduce the CPU overhead a little by calling pthread_yield() inside the loop  - pthread_yield suggests to the operating system that the thread does not use the CPU for a short while, so the CPU may be assigned to threads that are waiting to run. But does not fix the race-condition. We need a better implementation - can you work how to prevent the race-condition?How do I find out more?Play! Read the man page!  pthread_mutex_lock man page  pthread_mutex_unlock man page  pthread_mutex_init man page  pthread_mutex_destroy man page"
  },{
    "title": "Synchronization, Part 2: Counting Semaphores",
    "url": " /wikibook/synchronization-part-2-counting-semaphores",
   "content": "What is a counting semaphore?A counting semaphore contains a value and supports two operations “wait” and “post”. Post increments the semaphore and immediately returns. “wait” will wait if the count is zero. If the count is non-zero the semaphore decrements the count and immediately returns.An analogy is a count of the cookies in a cookie jar (or gold coins in the treasure chest). Before taking a cookie, call ‘wait’. If there are no cookies left then wait will not return: It will wait until another thread increments the semaphore by calling post.In short, post increments and immediately returns whereas wait will wait if the count is zero. Before returning it will decrement count.How do I create a semaphore?This page introduces unnamed semaphores. Unfortunately Mac OS X does not support these yet.First decide if the initial value should be zero or some other value (e.g. the number of remaining spaces in an array).Unlike pthread mutex there are not shortcuts to creating a semaphore - use sem_init#include &lt;semaphore.h&gt;sem_t s;int main() {  sem_init(&amp;s, 0, 10); // returns -1 (=FAILED) on OS X  sem_wait(&amp;s); // Could do this 10 times without blocking  sem_post(&amp;s); // Announce that we've finished (and one more resource item is available; increment count)  sem_destroy(&amp;s); // release resources of the semaphore}Can I call wait and post from different threads?Yes! Unlike a mutex, the increment and decrement can be from different threads.Can I use a semaphore instead of a mutex?Yes - though the overhead of a semaphore is greater. To use a semaphore:  Initialize the semaphore with a count of one.  Replace ...lock with sem_wait  Replace ...unlock with sem_postA mutex is a semaphore that always waits before it postssem_t s;sem_init(&amp;s, 0, 1);sem_wait(&amp;s);// Critical Sectionsem_post(&amp;s);Can I use sem_post inside a signal handler?Yes! sem_post is one of a handful of functions that can be correctly used inside a signal handler.This means we can release a waiting thread which can now make all of the calls that we were notallowed to call inside the signal handler itself (e.g. printf).#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;signal.h&gt;#include &lt;semaphore.h&gt;#include &lt;unistd.h&gt;sem_t s;void handler(int signal){    sem_post(&amp;s); /* Release the Kraken! */}void *singsong(void *param){    sem_wait(&amp;s);    printf(\"I had to wait until your signal released me!\\n\");}int main(){    int ok = sem_init(&amp;s, 0, 0 /* Initial value of zero*/);     if (ok == -1) {       perror(\"Could not create unnamed semaphore\");       return 1;    }    signal(SIGINT, handler); // Too simple! See note below    pthread_t tid;    pthread_create(&amp;tid, NULL, singsong, NULL);    pthread_exit(NULL); /* Process will exit when there are no more threads */}Note robust programs do not use signal() in a multi-threaded program (“The effects of signal() in a multithreaded process are unspecified.” - the signal man page); a more correct program will need to use sigaction.How do I find out more?Read the man pages:  sem_init  sem_wait  sem_post  sem_destroy"
  },{
    "title": "Synchronization, Part 3: Working with Mutexes And Semaphores",
    "url": " /wikibook/synchronization-part-3-working-with-mutexes-and-semaphores",
   "content": "Thread Safe StackWhat is an atomic operation?To paraphrase Wikipedia,  An operation (or set of operations) is atomic or uninterruptible if it appears to the rest of the system to occur instantaneously.Without locks, only simple CPU instructions (“read this byte from memory”) are atomic (indivisible). On a single CPU system, one could temporarily disable interrupts (so a sequence of operations cannot be interrupted) but in practice atomicity is achieved by using synchronization primitives, typically a mutex lock.Incrementing a variable (i++) is not atomic because it requires three distinct steps: Copying the bit pattern from memory into the CPU; performing a calculation using the CPU’s registers; copying the bit pattern back to memory. During this increment sequence, another thread or process can still read the old value and other writes to the same memory would also be over-written when the increment sequence completes.How do I use mutex lock to make my data-structure thread-safe?Note, this is just an introduction - writing high-performance thread-safe data structures requires its own book! Here’s a simple data structure (a stack) that is not thread-safe:// A simple fixed-sized stack (version 1)#define STACK_SIZE 20int count;double values[STACK_SIZE];void push(double v) {     values[count++] = v; }double pop() {    return values[--count];}int is_empty() {    return count == 0;}Version 1 of the stack is not thread-safe because if two threads call push or pop at the same time then the results or the stack can be inconsistent. For example, imagine if two threads call pop at the same time then both threads may read the same value, both may read the original count value.To turn this into a thread-safe data structure we need to identify the critical sections of our code  i.e. which section(s) of the code must only have one thread at a time. In the above example the push,pop and is_empty functions access the same variables (i.e. memory) and all critical sections for the stack.While push (and pop) is executing, the datastructure is an inconsistent state (for example the count may not have been written to, so may still contain the original value). By wrapping these methods with a mutex we can ensure that only one thread at a time can update (or read) the stack.A candidate ‘solution’ is shown below. Is it correct? If not, how will it fail?// An attempt at a thread-safe stack (version 2)#define STACK_SIZE 20int count;double values[STACK_SIZE];pthread_mutex_t m1 = PTHREAD_MUTEX_INITIALIZER;pthread_mutex_t m2 = PTHREAD_MUTEX_INITIALIZER;void push(double v) {     pthread_mutex_lock(&amp;m1);    values[count++] = v;    pthread_mutex_unlock(&amp;m1);}double pop() {    pthread_mutex_lock(&amp;m2);    double v = values[--count];    pthread_mutex_unlock(&amp;m2);    return v;}int is_empty() {    pthread_mutex_lock(&amp;m1);    return count == 0;    pthread_mutex_unlock(&amp;m1);}The above code (‘version 2’) contains at least one error. Take a moment to see if you can the error(s) and work out the consequence(s).If three threads called push() at the same time the lock m1 ensures that only one thread at time manipulates the stack (two threads will need to wait until the first thread completes (calls unlock), then a second thread will be allowed to continue into the critical section and finally the third thread will be allowed to continue once the second thread has finished).A similar argument applies to concurrent calls (calls at the same time) to pop. However version 2 does not prevent push and pop from running at the same time because push and pop use two different mutex locks.The fix is simple in this case - use the same mutex lock for both the push and pop functions.The code has a second error; is_empty returns after the comparison and will not unlock the mutex. However the error would not be spotted immediately. For example, suppose one thread calls is_empty and a second thread later calls push. This thread would mysteriously stop. Using debugger you can discover that the thread is stuck at the lock() method inside the push method because the lock was never unlocked by the earlier is_empty call. Thus an oversight in one thread led to problems much later in time in an arbitrary other thread.A better version is shown below -// An attempt at a thread-safe stack (version 3)int count;double values[count];pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;void push(double v) {   pthread_mutex_lock(&amp;m);   values[count++] = v;  pthread_mutex_unlock(&amp;m);}double pop() {  pthread_mutex_lock(&amp;m);  double v = values[--count];  pthread_mutex_unlock(&amp;m);  return v;}int is_empty() {  pthread_mutex_lock(&amp;m);  int result= count == 0;  pthread_mutex_unlock(&amp;m);  return result;}Version 3 is thread-safe (we have ensured mutual exclusion for all of the critical sections) however there are two points of note:  is_empty is thread-safe but its result may already be out-of date i.e. the stack may no longer be empty by the time the thread gets the result!  There is no protection against underflow (popping on an empty stack) or overflow (pushing onto an already-full stack)The latter point can be fixed using counting semaphores.The implementation assumes a single stack.  A more general purpose version might include the mutex as part of the memory struct and use pthread_mutex_init to initialize the mutex. For example,// Support for multiple stacks (each one has a mutex)typedef struct stack {  int count;  pthread_mutex_t m;   double *values;} stack_t;stack_t* stack_create(int capacity) {  stack_t *result = malloc(sizeof(stack_t));  result-&gt;count = 0;  result-&gt;values = malloc(sizeof(double) * capacity);  pthread_mutex_init(&amp;result-&gt;m, NULL);  return result;}void stack_destroy(stack_t *s) {  free(s-&gt;values);  pthread_mutex_destroy(&amp;s-&gt;m);  free(s);}// Warning no underflow or overflow checks!void push(stack_t *s, double v) {   pthread_mutex_lock(&amp;s-&gt;m);   s-&gt;values[(s-&gt;count)++] = v;   pthread_mutex_unlock(&amp;s-&gt;m); }double pop(stack_t *s) {   pthread_mutex_lock(&amp;s-&gt;m);   double v = s-&gt;values[--(s-&gt;count)];   pthread_mutex_unlock(&amp;s-&gt;m);   return v;}int is_empty(stack_t *s) {   pthread_mutex_lock(&amp;s-&gt;m);   int result = s-&gt;count == 0;   pthread_mutex_unlock(&amp;s-&gt;m);  return result;}Example use:int main() {    stack_t *s1 = stack_create(10 /* Max capacity*/);    stack_t *s2 = stack_create(10);    push(s1, 3.141);    push(s2, pop(s1));    stack_destroy(s2);    stack_destroy(s1);}Stack SemaphoresHow can I force my threads to wait if the stack is empty or full?Use counting semaphores! Use a counting semaphore to keep track of how many spaces remain and another semaphore to keep to track the number of items in the stack. We will call these two semaphores ‘sremain’ and ‘sitems’. Remember sem_wait will wait if the semaphore’s count has been decremented to zero (by another thread calling sem_post).// Sketch #1sem_t sitems;sem_t sremain;void stack_init(){  sem_init(&amp;sitems, 0, 0);  sem_init(&amp;sremain, 0, 10);}double pop() {  // Wait until there's at least one item  sem_wait(&amp;sitems);  ...void push(double v) {  // Wait until there's at least one space  sem_wait(&amp;sremain);  ...Sketch #2  has implemented the post too early. Another thread waiting in push can erroneously attempt to write into a full stack (and similarly a thread waiting in the pop() is allowed to continue too early).// Sketch #2 (Error!)double pop() {  // Wait until there's at least one item  sem_wait(&amp;sitems);  sem_post(&amp;sremain); // error! wakes up pushing() thread too early  return values[--count];}void push(double v) {  // Wait until there's at least one space  sem_wait(&amp;sremain);  sem_post(&amp;sitems); // error! wakes up a popping() thread too early  values[count++] = v;}Sketch 3 implements the correct semaphore logic but can you spot the error?// Sketch #3 (Error!)double pop() {  // Wait until there's at least one item  sem_wait(&amp;sitems);  double v= values[--count];  sem_post(&amp;sremain);  return v;}void push(double v) {  // Wait until there's at least one space  sem_wait(&amp;sremain);  values[count++] = v;  sem_post(&amp;sitems); }Sketch 3 correctly enforces buffer full and buffer empty conditions using semaphores. However there is no mutual exclusion: Two threads can be in the critical section at the same time, which would corrupt the data structure (or least lead to data loss). The fix is to wrap a mutex around the critical section:// Simple single stack - see above example on how to convert this into a multiple stacks.// Also a robust POSIX implementation would check for EINTR and error codes of sem_wait.// PTHREAD_MUTEX_INITIALIZER for statics (use pthread_mutex_init() for stack/heap memory)pthread_mutex_t m= PTHREAD_MUTEX_INITIALIZER; int count = 0;double values[10];sem_t sitems, sremain;void init() {  sem_init(&amp;sitems, 0, 0);  sem_init(&amp;sremains, 0, 10); // 10 spaces}double pop() {  // Wait until there's at least one item  sem_wait(&amp;sitems);  pthread_mutex_lock(&amp;m); // CRITICAL SECTION  double v= values[--count];  pthread_mutex_unlock(&amp;m);  sem_post(&amp;sremain); // Hey world, there's at least one space  return v;}void push(double v) {  // Wait until there's at least one space  sem_wait(&amp;sremain);  pthread_mutex_lock(&amp;m); // CRITICAL SECTION  values[count++] = v;  pthread_mutex_unlock(&amp;m);  sem_post(&amp;sitems); // Hey world, there's at least one item}// Note a robust solution will need to check sem_wait's result for EINTR (more about this later)What are the common Mutex Gotchas?  Locking/unlocking the wrong mutex (due to a silly typo)  Not unlocking a mutex (due to say an early return during an error condition)  Resource leak (not calling pthread_mutex_destroy)  Using an unitialized mutex (or using a mutex that has already been destroyed)  Locking a mutex twice on a thread (without unlocking first)  Deadlock and Priority Inversion (we will talk about these later)"
  },{
    "title": "Synchronization, Part 4: The Critical Section Problem",
    "url": " /wikibook/synchronization-part-4-the-critical-section-problem",
   "content": "Candidate SolutionsWhat is the Critical Section Problem?As already discussed in Synchronization, Part 3: Working with Mutexes And Semaphores, there are critical parts of our code that can only be executed by one thread at a time. We describe this requirement as ‘mutual exclusion’; only one thread (or process) may have access to the shared resource.In multi-threaded programs we can wrap a critical section with mutex lock and unlock calls:pthread_mutex_lock() - one thread allowed at a time! (others will have to wait here)... Do Critical Section stuff here!pthread_mutex_unlock() - let other waiting threads continueHow would we implement these lock and unlock calls? Can we create an algorithm that assures mutual exclusion? An incorrect implementation is shown below,pthread_mutex_lock(p_mutex_t *m)     { while(m-&gt;lock) {}; m-&gt;lock = 1;}pthread_mutex_unlock(p_mutex_t *m)   { m-&gt;lock = 0; }At first glance, the code appears to work; if one thread attempts to locks the mutex, a later thread must wait until the lock is cleared. However this implementation does not satisfy Mutual Exclusion. Let’s take a close look at this ‘implementation’ from the point of view of two threads running around the same time. In the table below times runs from top to bottom-Time | Thread 1 | Thread 2—–|———-|———1 | while(lock) {}2 | | while(lock) {}  | 3 | lock = 1 | lock = 1 |Ooops! There is a race condition. In the unfortunate case both threads checked the lock and read a false value and so were able to continue.Candidate solutions to the critical section problem.To simplify the discussion we consider only two threads. Note these arguments work for threads and processes and the classic CS literature discusses these problem in terms of two processes that need exclusive access (i.e. mutual exclusion) to a critical section or shared resource.Raising a flag represents a thread/process’s intention to enter the critical section.Remember that the psuedo-code outlined below is part of a larger program; the thread or process will typically need to enter the critical section many times during the lifetime of the process. So imagine each example as wrapped inside a loop where for a random amount of time the thread or process is working on something else.Is there anything wrong with candidate solution described below?// Candidate #1wait until your flag is loweredraise my flag// Do Critical Section stufflower my flag Answer: Candidate solution #1 also suffers a race condition i.e. it does not satisfy Mutual Exclusion because both threads/processes could read each other’s flag value (=lowered) and continue.This suggests we should raise the flag before checking the other thread’s flag - which is candidate solution #2 below.// Candidate #2raise my flagwait until your flag is lowered// Do Critical Section stufflower my flag Candidate #2 satisfies mutual exclusion - it is impossible for two threads to be inside the critical section at the same time. However this code suffers from deadlock! Suppose two threads wish to enter the critical section at the same time:Time | Thread 1 | Thread 2—–|———-|———1 | raise flag2 | | raise flag3 | wait … | wait …Ooops both threads / processes are now waiting for the other one to lower their flags. Neither one will enter the critical section as both are now stuck forever!This suggests we should use a turn-based variable to try to resolve who should proceed.Turn-based solutionsThe following candidate solution #3 uses a turn-based variable to politely allow one thread and then the other to continue// Candidate #3wait until my turn is myid// Do Critical Section stuffturn = youridCandidate #3 satisfies mutual exclusion (each thread or process gets exclusive access to the Critical Section), however both threads/processes must take a strict turn-based approach to using the critical section; i.e. they are forced into an alternating critical section access pattern. For example, if thread 1 wishes to read a hashtable every millisecond but another thread writes to a hashtable every second, then the reading thread would have to wait another 999ms before being able to read from the hashtable again. This ‘solution’ is not effective, because our threads should be able to make progress and enter the critical section if no other thread is currently in the critical section.Desired properties for solutions to the Critical Section Problem?There are three main desirable properties that we desire in a solution the critical section problem  Mutual Exclusion - the thread/process gets exclusive access; others must wait until it exits the critical section.  Bounded Wait - if the thread/process has to wait, then it should only have to wait for a finite,  amount of time (infinite waiting times are not allowed!). The exact definition of bounded wait is that there is an upper (non-infinite) bound on the number of times any other process can enter its critical section before the given process enters.  Progress - if no thread/process is inside the critical section, then the thread/process should be able to proceed (make progress) without having to wait.With these ideas in mind let’s examine another candidate solution that uses a turn-based flag only if two threads both required access at the same time.Turn and Flag solutionsIs the following a correct solution to CSP?\\\\ Candidate #4raise my flagif your flag is raised, wait until my turn// Do Critical Section stuffturn = youridlower my flagOne instructor and another CS faculty member initially thought so! However, analyzing these solutions is tricky. Even peer-reviewed papers on this specific subject contain incorrect solutions! At first glance it appears to satisfy Mutual Exclusion, Bounded Wait and Progress: The turn-based flag is only used in the event of a tie (so Progress and Bounded Wait is allowed) and mutual exclusion appears to be satisfied. However…. Perhaps you can find a counter-example?Candidate #4 fails because a thread does not wait until the other thread lowers their flag. After some thought (or inspiration) the following scenario can be created to demonstrate how Mutual Exclusion is not satisfied.Imagine the first thread runs this code twice (so the the turn flag now points to the second thread). While the first thread is still inside the Critical Section, the second thread arrives. The second thread can immediately continue into the Critical Section!            Time      Turn      Thread #1      Thread #2                  1      2      raise my flag                     2      2      if your flag is raised, wait until my turn      raise my flag              3      2      // Do Critical Section stuff      if your flag is raised, wait until my turn(TRUE!)              4      2      // Do Critical Section stuff      // Do Critical Section stuff - OOPS      Working SolutionsWhat is Peterson’s solution?Peterson published his novel and surprisingly simple solution in a 2 page paper in 1981. A C-like code implementation is available on Wikipedia hereA version of his algorithm is shown below that uses a shared variable turn:\\\\ Candidate #5raise my flagturn = your_idwait while your flag is raised and turn is your_id// Do Critical Section stufflower my flagThis solution satisfies Mutual Exclusion, Bounded Wait and Progress. If thread #2 has set turn to 2 and is currently inside the critical section. Thread #1 arrives, sets the turn back to 1 and now waits until thread 2 lowers the flag.Link to Peterson’s original article pdf:G. L. Peterson: “Myths About the Mutual Exclusion Problem”, Information Processing Letters 12(3) 1981, 115–116Was Peterson’s solution the first solution?No, Dekkers Algorithm (1962) was the first provably correct solution. A version of the algorithm is below.raise my flagwhile(your flag is raised) :   if it's your turn to win :     lower my flag     wait while your turn     raise my flag// Do Critical Section stuffset your turn to winlower my flagNotice how the process’s flag is always raised during the critical section no matter if the loop is iterated zero, once or more times. Further the flag can be interpreted as an immediate intent to enter the critical section. Only if the other process has also raised the flag will one process defer, lower their intent flag and wait.Can I just implement Peterson’s (or Dekkers) algorithm in C or assembler?Yes - and with a bit searching it is possible even today to find it in production for specific simple mobile processors: Peterson’s algorithm is used to implement low-level Linux Kernel locks for the Tegra mobile processor (a system-on-chip ARM process and GPU core by Nvidia)https://android.googlesource.com/kernel/tegra.git/+/android-tegra-3.10/arch/arm/mach-tegra/sleep.S#58However in general, CPUs and C compilers can re-order CPU instructions or use CPU-core-specific local cache values that are stale if another core updates the shared variables. Thus a simple pseudo-code to C implementation is too naive for most platforms. You can stop reading now.Oh… you decided to keep reading. Well, here be dragons! Don’t say we didn’t warn you. Consider this advanced and gnarly topic but (spoiler alert) a happy ending.Consider the following code,while(flag2 ) { /* busy loop - go around again */An efficient compiler would infer that flag2 variable is never changed inside the loop, so that test can be optimized to while(true) Using volatile goes someway to prevent compiler optimizations of this kind.Independent instructions can be re-ordered by an optimizing compiler or at runtime by an out-of-order execution optimization by the CPU. These sophisticated optimizations if the code requires variables to be modified and checked and a precise order.A related challenge is that CPU cores include a data cache to store recently read or modified main memory values. Modified values may not be written back to main memory or re-read from memory immediately. Thus data changes, such as the state of a flag and turn variable in the above examples, may not be shared between two CPU codes.But there is happy ending. Fortunately, modern hardware addresses these issues using ‘memory fences’ (also known as memory barrier) CPU instructions to ensure that main memory and the CPUs’ cache is in a reasonable and coherent state. Higher level synchronization primitives, such as pthread_mutex_lock are will call these CPU instructions as part of their implementation. Thus, in practice, surrounding critical section with a mutex lock and unlock calls is sufficient to ignore these lower-level problems.Further reading: we suggest the following web post that discusses implementing Peterson’s algorithm on an x86 process and the linux documentation on memory barriers.http://bartoszmilewski.com/2008/11/05/who-ordered-memory-fences-on-an-x86/http://lxr.free-electrons.com/source/Documentation/memory-barriers.txtHardware SolutionsHow do we implement Critical Section Problem on hardware?We can use C11 Atomics to do that perfectly! A complete solution is detailed here (this is a spinlock mutex, futex implementations can be found online).typedef struct mutex_{    atomic_int_least8_t lock;    pthread_t owner;} mutex;#define UNLOCKED 0#define LOCKED 1#define UNASSIGNED_OWNER 0int mutex_init(mutex* mtx){    if(!mtx){        return 0;    }    atomic_init(&amp;mtx-&gt;lock, UNLOCKED); // Not thread safe the user has to take care of this    mtx-&gt;owner = UNASSIGNED_OWNER;    return 1;}This is the initialization code, nothing fancy here. We set the state of the mutex to unlocked and set the owner to locked.int mutex_lock(mutex* mtx){    int_least8_t zero = UNLOCKED;    while(!atomic_compare_exchange_weak_explicit            (&amp;mtx-&gt;lock,              &amp;zero,              LOCKED,             memory_order_acq_rel,             memory_order_relaxed)){        zero = UNLOCKED;        sched_yield(); //Use system calls for scheduling speed    }    //We have the lock now!!!!    mtx-&gt;owner = pthread_self();    return 1;}Yikes! What does this code do? Well to start it it initializes a variable that we will keep as the unlocked state. Atomic Compare and Exchange is an instruction supported by most modern architectures (on x86 it’s lock cmpxchg). The pseudocode for this operation looks like thisint atomic_compare_exchange_pseudo(int* addr1, int* addr2, int val){    if(*addr1 == *addr2){        *addr1 = val;        return 1;    }else{        *addr2 = *addr1;        return 0;    }}Except it is all done atomically meaning in one uninterruptible operation. What does the weak part mean? Well atomic instructions are also prone to spurious failures meaning that there are two versions to these atomic functions a strong and a weak part, strong guarantee the the success or failure while weak may fail. We are using weak because weak is faster and we are in a loop! That means we are okay if it fails a little bit more often because we will just keep spinning around anyway.What is this memory order business? We were talking about memory fences earlier, here it is! We won’t go into detail because it is outside the scope of this course but not the scope of this article.Inside the while loop, we have failed to grab the lock! We reset zero to unlocked and sleep for a little while. When we wake up we try to grab the lock again. Once we successfully swap, we are in the critical section! We set the mutex’s owner to the current thread for the unlock method and return successful.How does this guarantee mutual exclusion, when working with atomics we are not entirely sure! But in this simple example we can because the thread that is able to successfully expect the lock to be UNLOCKED (0) and swap it to a LOCKED (1) state is considered the winner. How do we implement unlock?int mutex_unlock(mutex* mtx){    if(unlikely(pthread_self() != mtx-&gt;owner)){        return 0; //You can't unlock a mutex if you aren't the owner    }    int_least8_t one = 1;    mtx-&gt;owner = UNASSIGNED_OWNER;    //Critical section ends after this atomic    //Also this may fail, but that is fine    if(!atomic_compare_exchange_strong_explicit(                &amp;mtx-&gt;lock,                 &amp;one,                 UNLOCKED,                memory_order_acq_rel,                memory_order_relaxed)){        //The mutex was never locked in the first place        return 0;    }    return 1;}To satisfy the api, you can’t unlock the mutex unless you are the one who owns it. Then we unassign the mutex owner, because critical section is over after the atomic. We want a strong exchange because we don’t want to block (pthread_mutex_unlock doesn’t block). We expect the mutex to be locked, and we swap it to unlock. If the swap was successful, we unlocked the mutex. If the swap wasn’t, that means that the mutex was UNLOCKED and we tried to switch it from UNLOCKED to UNLOCKED, preserving the non blocking of unlock."
  },{
    "title": "Synchronization, Part 5: Condition Variables",
    "url": " /wikibook/synchronization-part-5-condition-variables",
   "content": "Intro to Condition VariablesWarm upName these properties!  “Only one process(/thread) can be in the CS at a time”  “If waiting, then another process can only enter the CS a finite number of times”  “If no other process is in the CS then the process can immediately enter the CS”See Synchronization, Part 4: The Critical Section Problem for answers.What are condition variables? How do you use them? What is Spurious Wakeup?      Condition variables allow a set of threads to sleep until tickled! You can tickle one thread or all threads that are sleeping. If you only wake one thread then the operating system will decide which thread to wake up. You don’t wake threads directly instead you ‘signal’ the condition variable, which then will wake up one (or all) threads that are sleeping inside the condition variable.        Condition variables are used with a mutex and with a loop (to check a condition).        Occasionally a waiting thread may appear to wake up for no reason (this is called a spurious wake)! This is not an issue because you always use wait inside a loop that tests a condition that must be true to continue.        Threads sleeping inside a condition variable are woken up by calling pthread_cond_broadcast (wake up all) or pthread_cond_signal (wake up one). Note despite the function name, this has nothing to do with POSIX signals!  What does pthread_cond_wait do?The call pthread_cond_wait performs three actions:  unlock the mutex  waits (sleeps until pthread_cond_signal is called on the same condition variable). It does 1 and 2 atomically.  Before returning, locks the mutex(Advanced topic) Why do Condition Variables also need a mutex?Condition variables need a mutex for three reasons. The simplest to understand is that it prevents an early wakeup message (signal or broadcast functions) from being ‘lost.’ Imagine the following sequence of events (time runs down the page) where the condition is satisfied _just before _pthread_cond_wait is called. In this example the wake-up signal is lost!            Thread 1      Thread 2                  while (answer &lt; 42) {                            answer++                     p_cond_signal(cv)              p_cond_wait(cv, m)              If both threads had locked a mutex, the signal can not be sent until after pthread_cond_wait(cv, m) is called (which then internally unlocks the mutex)A second common reason is that updating the program state (answer variable) typically requires mutual exclusion - for example multiple threads may be updating the value of answer.A third and subtle reason is to satisfy real-time scheduling concerns which we only outline here: In a time-critical application, the waiting thread with the highest priority should be allowed to continue first. To satisfy this requirement the mutex must also be locked before calling pthread_cond_signal or pthread_cond_broadcast . For the curious, a longer and historical discussion is here.Why do spurious wakes exist?For performance. On multi-CPU systems it is possible that a race-condition could cause a wake-up (signal) request to be unnoticed. The kernel may not detect this lost wake-up call but can detect when it might occur. To avoid the potential lost signal the thread is woken up so that the program code can test the condition again.ExampleCondition variables are always used with a mutex lock.Before calling wait, the mutex lock must be locked and wait must be wrapped with a loop.pthread_cond_t cv;pthread_mutex_t m;int count;// Initializepthread_cond_init(&amp;cv, NULL);pthread_mutex_init(&amp;m, NULL);count = 0;pthread_mutex_lock(&amp;m);while (count &lt; 10) {    pthread_cond_wait(&amp;cv, &amp;m);     /* Remember that cond_wait unlocks the mutex before blocking (waiting)! */    /* After unlocking, other threads can claim the mutex. */    /* When this thread is later woken it will */    /* re-lock the mutex before returning */}pthread_mutex_unlock(&amp;m);// later clean up with pthread_cond_destroy(&amp;cv); and mutex_destroy // In another thread increment count:while (1) {    pthread_mutex_lock(&amp;m);    count++;    pthread_cond_signal(&amp;cv);    /* Even though the other thread is woken up it cannot not return */    /* from pthread_cond_wait until we have unlocked the mutex. This is */    /* a good thing! In fact, it is usually the best practice to call */    /* cond_signal or cond_broadcast before unlocking the mutex */    pthread_mutex_unlock(&amp;m);}Implementing Counting Semaphore  We can implement a counting semaphore using condition variables.  Each semaphore needs a count, a condition variable and a mutex    typedef struct sem_t {  int count;   pthread_mutex_t m;  pthread_condition_t cv;} sem_t;  Implement sem_init to initialize the mutex and condition variableint sem_init(sem_t *s, int pshared, int value) {    if (pshared) { errno = ENOSYS /* 'Not implemented'*/; return -1; }    s-&gt;count = value;    pthread_mutex_init(&amp;s-&gt;m, NULL);    pthread_cond_init(&amp;s-&gt;cv, NULL);    return 0;}Our implementation of sem_post needs to increment the count.We will also wake up any threads sleeping inside the condition variable.Notice we lock and unlock the mutex so only one thread can be inside the critical section at a time.sem_post(sem_t *s) {    pthread_mutex_lock(&amp;s-&gt;m);    s-&gt;count++;    pthread_cond_signal(&amp;s-&gt;cv); /* See note */    /* A woken thread must acquire the lock, so it will also have to wait until we call unlock */    pthread_mutex_unlock(&amp;s-&gt;m);}Our implementation of sem_wait may need to sleep if the semaphore’s count is zero.Just like sem_post we wrap the critical section using the lock (so only one thread can be executing our code at a time). Notice if the thread does need to wait then the mutex will be unlocked, allowing another thread to enter sem_post and waken us from our sleep!Notice that even if a thread is woken up, before it returns from  pthread_cond_wait it must re-acquire the lock, so it will have to wait a little bit more (e.g. until sem_post finishes).sem_wait(sem_t *s) {    pthread_mutex_lock(&amp;s-&gt;m);    while (s-&gt;count == 0) {        pthread_cond_wait(&amp;s-&gt;cv, &amp;s-&gt;m); /*unlock mutex, wait, relock mutex */    }    s-&gt;count--;    pthread_mutex_unlock(&amp;s-&gt;m);}Wait sem_post keeps calling pthread_cond_signal won’t that break sem_wait?Answer: No! We can’t get past the loop until the count is non-zero. In practice this means sem_post would unnecessary call pthread_cond_signal even if there are no waiting threads. A more efficient implementation would only call pthread_cond_signal when necessary i.e.    /* Did we increment from zero to one- time to signal a thread sleeping inside sem_post */    if (s-&gt;count == 1) /* Wake up one waiting thread! */        pthread_cond_signal(&amp;s-&gt;cv);Other semaphore considerations  Real semaphores implementation include a queue and scheduling concerns to ensure fairness and priority e.g. wake up the highest-priority longest sleeping thread.  Also, an advanced use of sem_init allows semaphores to be shared across processes. Our implementation only works for threads inside the same process."
  },{
    "title": "Synchronization, Part 6: Implementing a barrier",
    "url": " /wikibook/synchronization-part-6-implementing-a-barrier",
   "content": "How do I wait for N threads to reach a certain point before continuing onto the next step?Suppose we wanted to perform a multi-threaded calculation that has two stages, but we don’t want to advance to the second stage until the first stage is completed.We could use a synchronization method called a barrier. When a thread reaches a barrier, it will wait at the barrier until all the threads reach the barrier, and then they’ll all proceed together.Think of it like being out for a hike with some friends.  You agree to wait for each other at the top of each hill (and you make a mental note how many are in your group). Say you’re the first one to reach the top of the first hill. You’ll wait there at the top for your friends. One by one, they’ll arrive at the top, but nobody will continue until the last person in your group arrives.  Once they do, you’ll all proceed.Pthreads has a function pthread_barrier_wait() that implements this. You’ll need to declare a pthread_barrier_t variable and initialize it with pthread_barrier_init().  pthread_barrier_init() takes the number of threads that will be participating in the barrier as an argument.  Here’s an example.Now let’s implement our own barrier and use it to keep all the threads in sync in a large calculation.double data[256][8192]1 Threads do first calculation (use and change values in data)2 Barrier! Wait for all threads to finish first calculation before continuing3 Threads do second calculation (use and change values in data)The thread function has four main parts-void *calc(void *arg) {    /* Do my part of the first calculation */    /* Am I the last thread to finish? If so wake up all the other threads! */    /* Otherwise wait until the other threads has finished part one */    /* Do my part of the second calculation */}Our main thread will create the 16 threads and we will divide each calculation into 16 separate pieces.  Each thread will be given a unique value (0,1,2,..15), so it can work on its own block.Since a (void*) type can hold small integers, we will pass the value of i by casting it to a void pointer.#define N (16)double data[256][8192];int main() {    pthread_t ids[N];    for (int i = 0; i &lt; N; i++)          pthread_create(&amp;ids[i], NULL, calc, (void *) i);Note, we will never dereference this pointer value as an actual memory location - we will just cast it straight back to an integer:void *calc(void *ptr) {// Thread 0 will work on rows 0..15, thread 1 on rows 16..31    int x, y, start = N * (int) ptr;    int end = start + N;     for (x = start; x &lt; end; x++) for (y = 0; y &lt; 8192; y++) { /* do calc #1 */ }After calculation 1 completes, we need to wait for the slower threads (unless we are the last thread!).So, keep track of the number of threads that have arrived at our barrier aka ‘checkpoint’:// Global: int remain = N;// After calc #1 code:remain--; // We finishedif (remain == 0) { /*I'm last!  -  Time for everyone to wake up! */ }else {    while (remain != 0) { /* spin spin spin*/ }}However the above code has a race condition (two threads might try to decrement remain) and the loop is a busy loop. We can do better! Let’s use a condition variable and then we will use a broadcast/signal functions to wake up the sleeping threads.A reminder, that a condition variable is similar to a house! Threads go there to sleep (pthread_cond_wait). You can choose to wake up one thread (pthread_cond_signal) or all of them (pthread_cond_broadcast).  If there are no threads currently waiting then these two calls have no effect.A condition variable version is usually very similar to a busy loop incorrect solution - as we will show next. First, let’s add a mutex and condition global variables and don’t forget to initialize them in main …//global variablespthread_mutex_t m;pthread_cond_t cv;int main() {    pthread_mutex_init(&amp;m, NULL);    pthread_cond_init(&amp;cv, NULL);We will use the mutex to ensure that only one thread modifies remain at a time.The last arriving thread needs to wake up all sleeping threads - so we will use pthread_cond_broadcast(&amp;cv) not pthread_cond_signalpthread_mutex_lock(&amp;m);remain--; if (remain == 0) { pthread_cond_broadcast(&amp;cv); }else {    while (remain != 0) { pthread_cond_wait(&amp;cv, &amp;m); }}pthread_mutex_unlock(&amp;m);When a thread enters pthread_cond_wait, it releases the mutex and sleeps. At some point in the future, it will be awoken. Once we bring a thread back from its sleep, before returning it must wait until it can lock the mutex. Notice that even if a sleeping thread wakes up early, it will check the while loop condition and re-enter wait if necessary.The above barrier is not reusable Meaning that if we stick it into any old calculation loop there is a good chance that the code will encounter a condition where the barrier either deadlocks or a thread races ahead one iteration faster. Think about how you can make the above barrier reusable, meaning that if mutliple threads call barrier_wait in a loop then one can guarantee that they are on the same iteration."
  },{
    "title": "Synchronization, Part 7: The Reader Writer Problem",
    "url": " /wikibook/synchronization-part-7-the-reader-writer-problem",
   "content": "What is the Reader Writer Problem?Imagine you had a key-value map data structure which is used by many threads. Multiple threads should be able to look up (read) values at the same time provided the data structure is not being written to. The writers are not so gregarious - to avoid data corruption, only one thread at a time may modify (write) the data structure (and no readers may be reading at that time).This is an example of the Reader Writer Problem. Namely how can we efficiently synchronize multiple readers and writers such that multiple readers can read together but a writer gets exclusive access?An incorrect attempt is shown below (“lock” is a shorthand for pthread_mutex_lock):Attempt #1read() {  lock(&amp;m)  // do read stuff  unlock(&amp;m)}write() {  lock(&amp;m)  // do write stuff  unlock(&amp;m)}At least our first attempt does not suffer from data corruption (readers must wait while a writer is writing and vice versa)! However readers must also wait for other readers. So let’s try another implementation..Attempt #2:read() {  while(writing) {/*spin*/}  reading = 1  // do read stuff  reading = 0}write() {  while(reading || writing) {/*spin*/}  writing = 1  // do write stuff  writing = 0}Our second attempt suffers from a race condition - imagine if two threads both called read and write (or both called write) at the same time. Both threads would be able to proceed! Secondly, we can have multiple readers and multiple writers, so lets keep track of the total number of readers or writers. Which brings us to attempt #3,Attempt #3Remember that pthread_cond_wait performs Three actions. Firstly it atomically unlocks the mutex and then sleeps (until it is woken by pthread_cond_signal or pthread_cond_broadcast). Thirdly the awoken thread must re-acquire the mutex lock before returning. Thus only one thread can actually be running inside the critical section defined by the lock and unlock() methods.Implementation #3 below ensures that a reader will enter the cond_wait if there are any writers writing.read() {    lock(&amp;m)    while (writing)        cond_wait(&amp;cv, &amp;m)    reading++;/* Read here! */    reading--    cond_signal(&amp;cv)    unlock(&amp;m)}However only one reader a time can read because candidate #3 did not unlock the mutex. A better version unlocks before reading :read() {    lock(&amp;m);    while (writing)        cond_wait(&amp;cv, &amp;m)    reading++;    unlock(&amp;m)/* Read here! */    lock(&amp;m)    reading--    cond_signal(&amp;cv)    unlock(&amp;m)}Does this mean that a writer and read could read and write at the same time? No! First of all, remember cond_wait requires the thread re-acquire the  mutex lock before returning. Thus only one thread can be executing code inside the critical section (marked with **) at a time!read() {    lock(&amp;m);**  while (writing)**      cond_wait(&amp;cv, &amp;m)**  reading++;    unlock(&amp;m)/* Read here! */    lock(&amp;m)**  reading--**  cond_signal(&amp;cv)    unlock(&amp;m)}Writers must wait for everyone. Mutual exclusion is assured by the lock.write() {    lock(&amp;m);**  while (reading || writing)**      cond_wait(&amp;cv, &amp;m);**  writing++;**** /* Write here! */**  writing--;**  cond_signal(&amp;cv);    unlock(&amp;m);}Candidate #3 above also uses pthread_cond_signal ; this will only wake up one thread. For example, if many readers are waiting for the writer to complete then only one sleeping reader will be awoken from their slumber. The reader and writer should use cond_broadcast so that all threads should wake up and check their while-loop condition.Starving writersCandidate #3 above suffers from starvation. If readers are constantly arriving then a writer will never be able to proceed (the ‘reading’ count never reduces to zero). This is known as starvation and would be discovered under heavy loads. Our fix is to implement a bounded-wait for the writer. If a writer arrives they will still need to wait for existing readers however future readers must be placed in a “holding pen” and wait for the writer to finish. The “holding pen” can be implemented using a variable and a condition variable (so that we can wake up the threads once the writer has finished).Our plan is that when a writer arrives, and before waiting for current readers to finish, register our intent to write (by incrementing a counter ‘writer’). Sketched below -write() {    lock()    writer++    while (reading || writing)    cond_wait    unlock()  ...}And incoming readers will not be allowed to continue while writer is nonzero. Notice ‘writer’ indicates a writer has arrived, while ‘reading’ and ‘writing’ counters indicate there is an active reader or writer.read() {    lock()    // readers that arrive *after* the writer arrived will have to wait here!    while(writer)    cond_wait(&amp;cv,&amp;m)    // readers that arrive while there is an active writer    // will also wait.    while (writing)         cond_wait(&amp;cv,&amp;m)    reading++    unlock  ...}Attempt #4Below is our first working solution to the Reader-Writer problem. Note if you continue to read about the “Reader Writer problem” then you will discover that we solved the “Second Reader Writer problem” by giving writers preferential access to the lock. This solution is not optimal. However it satisfies our original problem (N active readers, single active writer, avoids starvation of the writer if there is a constant stream of readers).Can you identify any improvements? For example, how would you improve the code so that we only woke up readers or one writer?int writers; // Number writer threads that want to enter the critical section (some or all of these may be blocked)int writing; // Number of threads that are actually writing inside the C.S. (can only be zero or one)int reading; // Number of threads that are actually reading inside the C.S.// if writing !=0 then reading must be zero (and vice versa)reader() {    lock(&amp;m)    while (writers)        cond_wait(&amp;turn, &amp;m)    // No need to wait while(writing here) because we can only exit the above loop    // when writing is zero    reading++    unlock(&amp;m)  // perform reading here    lock(&amp;m)    reading--    cond_broadcast(&amp;turn)    unlock(&amp;m)}writer() {    lock(&amp;m)      writers++      while (reading || writing)           cond_wait(&amp;turn, &amp;m)      writing++      unlock(&amp;m)      // perform writing here      lock(&amp;m)      writing--      writers--      cond_broadcast(&amp;turn)      unlock(&amp;m)  }"
  },{
    "title": "Synchronization, Part 8: Ring Buffer Example",
    "url": " /wikibook/synchronization-part-8-ring-buffer-example",
   "content": "What is a ring buffer?A ring buffer is a simple, usually fixed-sized, storage mechanism where contiguous memory is treated as if it is circular, and two index counters keep track of the current beginning and end of the queue. As  array indexing is not circular, the index counters must wrap around to zero when moved past the end of the array.As data is added (enqueued) to the front of the queue or removed (dequeued) from tail of the queue, the current items in the buffer form a train that appears to circle the trackA simple (single-threaded) implementation is shown below. Note enqueue and dequeue do not guard against underflow or overflow - it’s possible to add an item when when the queue is full and possible to remove an item when the queue is empty. For example if we added 20 integers (1,2,3…) to the queue and did not dequeue any items then values 17,18,19,20 would overwrite the 1,2,3,4. We won’t fix this problem right now, instead when we create the multi-threaded version we will ensure enqueue-ing and dequeue-ing threads are blocked while the ring buffer is full or empty respectively.void *buffer[16];int in = 0, out = 0;void enqueue(void *value) { /* Add one item to the front of the queue*/  buffer[in] = value;  in++; /* Advance the index for next time */  if (in == 16) in = 0; /* Wrap around! */}void *dequeue() { /* Remove one item to the end of the queue.*/  void *result = buffer[out];  out++;  if (out == 16) out = 0;  return result;}What are gotchas of implementing a Ring Buffer?It’s very tempting to write the enqueue or dequeue method in the following compact form (N is the capacity of the buffer e.g. 16):void enqueue(void *value)  b[ (in++) % N ] = value;}This method would appear to work (pass simple tests etc) but contains a subtle bug. With enough enqueue operations (a bit more than two billion) the int value of in will overflow and become negative! The modulo (or ‘remainder’) operator % preserves the sign. Thus you might end up writing into b[-14]  for example!A compact form is correct uses bit masking provided N is 2^x (16,32,64,…)b[ (in++) &amp; (N-1) ] = value;This buffer does not yet prevent buffer underflow or overflow. For that, we’ll turn to our multi-threaded attempt that will block a thread until there is space or there is at least one item to remove.Checking a multi-threaded implementation for correctness (Example 1)The following code is an incorrect implementation. What will happen? Will enqueue and/or dequeue block? Is mutual exclusion satisfied? Can the buffer underflow? Can the buffer overflow?For clarity pthread_mutex is shortened to p_m and we assume sem_wait cannot be interrupted.#define N 16void *b[N]int in = 0, out = 0p_m_t locksem_t s1,s2void init() {     p_m_init(&amp;lock, NULL)    sem_init(&amp;s1, 0, 16)    sem_init(&amp;s2, 0, 0)}enqueue(void *value) {    p_m_lock(&amp;lock)    // Hint: Wait while zero. Decrement and return    sem_wait( &amp;s1 )      b[ (in++) &amp; (N-1) ] = value    // Hint: Increment. Will wake up a waiting thread     sem_post(&amp;s1)     p_m_unlock(&amp;lock)}void *dequeue(){    p_m_lock(&amp;lock)    sem_wait(&amp;s2)    void *result = b[(out++) &amp; (N-1) ]    sem_post(&amp;s2)    p_m_unlock(&amp;lock)    return result}AnalysisBefore reading on, see how many mistakes you can find. Then determine what would happen if threads called the enqueue and dequeue methods.  The enqueue method waits and posts on the same semaphore (s1) and similarly with equeue and (s2) i.e. we decrement the value and then immediately increment the value, so by the end of the function the semaphore value is unchanged!  The initial value of s1 is 16, so the semaphore will never be reduced to zero - enqueue will not block if the ring buffer is full - so overflow is possible.  The initial value of s2 is zero, so calls to dequeue will always block and never return!  The order of mutex lock and sem_wait will need to be swapped (however this example is so broken that this bug has no effect!)    Checking a multi-threaded implementation for correctness (Example 1)  The following code is an incorrect implementation. What will happen? Will enqueue and/or dequeue block? Is mutual exclusion satisfied? Can the buffer underflow? Can the buffer overflow?For clarity pthread_mutex is shortened to p_m and we assume sem_wait cannot be interrupted.void *b[16]int in = 0, out = 0p_m_t locksem_t s1, s2void init() {    sem_init(&amp;s1,0,16)    sem_init(&amp;s2,0,0)}enqueue(void *value){ sem_wait(&amp;s2) p_m_lock(&amp;lock) b[ (in++) &amp; (N-1) ] = value p_m_unlock(&amp;lock) sem_post(&amp;s1)}void *dequeue(){  sem_wait(&amp;s1)  p_m_lock(&amp;lock)  void *result = b[(out++) &amp; 15]  p_m_unlock(&amp;lock)  sem_post(&amp;s2)  return result;}Analysis  The initial value of s2 is 0. Thus enqueue will block on the first call to sem_wait even though the buffer is empty!  The initial value of s1 is 16. Thus dequeue will not block on the first call to sem_wait even though the buffer is empty - oops Underflow! The dequeue method will return invalid data.  The code does not satisfy Mutual Exclusion; two threads can modify in or out at the same time! The code appears to use  mutex lock. Unfortunately the lock was never initialized with pthread_mutex_init() or PTHREAD_MUTEX_INITIALIZER - so the lock may not work (pthread_mutex_lock may simply do nothing)Correct implementation of a ring bufferThe pseudo-code (pthread_mutex shortened to p_m etc) is shown below.As the mutex lock is stored in global (static) memory it can be initialized with  PTHREAD_MUTEX_INITIALIZER.If we had allocated space for the mutex on the heap, then we would have used pthread_mutex_init(ptr, NULL)#include &lt;pthread.h&gt;#include &lt;semaphore.h&gt;// N must be 2^i#define N (16)void *b[N]int in = 0, out = 0p_m_t lock = PTHREAD_MUTEX_INITIALIZERsem_t countsem, spacesemvoid init() {  sem_init(&amp;countsem, 0, 0)  sem_init(&amp;spacesem, 0, 16)}The enqueue method is shown below. Notice:  The lock is only held during the critical section (access to the data structure).  A complete implementation would need to guard against early returns from sem_wait due to POSIX signals.enqueue(void *value){ // wait if there is no space left: sem_wait( &amp;spacesem ) p_m_lock(&amp;lock) b[ (in++) &amp; (N-1) ] = value p_m_unlock(&amp;lock) // increment the count of the number of items sem_post(&amp;countsem)}The dequeue implementation is shown below. Notice the symmetry of the synchronization calls to enqueue. In both cases the functions first wait if the count of spaces or count of items is zero.void *dequeue(){  // Wait if there are no items in the buffer  sem_wait(&amp;countsem)  p_m_lock(&amp;lock)  void *result = b[(out++) &amp; (N-1)]  p_m_unlock(&amp;lock)  // Increment the count of the number of spaces  sem_post(&amp;spacesem)  return result}Food for thought  What would happen if  the order of  pthread_mutex_unlock and sem_post calls were swapped?  What would happen if the order of sem_wait and pthread_mutex_lock calls were swapped?"
  },{
    "title": "Synchronization, Part 9: Synchronization Across Processes",
    "url": " /wikibook/synchronization-part-9-synchronization-across-processes",
   "content": "Process SynchronizationYou thought that you were using different processes, so you don’t have to synchronize? Think again! You may not have race conditions within a process but what if your process needs to interact with the system around it? Let’s consider a motivating examplevoid write_string(const char *data) {    int fd = open(\"my_file.txt\", O_WRONLY);    write(fd, data, strlen(data));    close(fd);}int main() {    if(!fork()) {        write_string(\"key1: value1\");        wait(NULL);    } else {        write_string(\"key2: value2\");    }    return 0;}When the program is compiled and run, if none of the system calls fail then we should get something that looks like this (given the file was empty to begin with).key1: value1key2: value2orkey2: value2key1: value1InterruptionBut, there is a hidden nuance. Most system calls can be interrupted meaning that the operating system can stop an ongoing system call because it needs to stop the process. So barring fork wait open and close from failing – they typically go to completion – what happens if write fails? If write fails and no bytes are written, we can get something like key1: value1 or key2: value2. This is data loss which is incorrect but won’t corrupt the file. What happens if write gets interrupted after a partial write? We get all sorts of madness. For example,key2: key1: value1SolutionSo what should we do? We should use a shared mutex! Consider the following code.pthread_mutex_t * mutex = NULL;pthread_mutexattr_t attr;void write_string(const char *data) {    pthread_mutex_lock(mutex);    int fd = open(\"my_file.txt\", O_WRONLY);    int bytes_to_write = strlen(data), written = 0;    while(written &lt; bytes_to_write) {        written += write(fd, data + written, bytes_to_write - written);    }    close(fd);    pthread_mutex_unlock(mutex);}int main() {    pthread_mutexattr_init(&amp;attr);    pthread_mutexattr_setpshared(&amp;attr, PTHREAD_PROCESS_SHARED);    pmutex = mmap (NULL, sizeof(pthread_mutex_t),                 PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANON, -1, 0);    pthread_mutex_init(pmutex, &amp;attrmutex);    if(!fork()) {        write_string(\"key1: value1\");        wait(NULL);        pthread_mutex_destroy(pmutex);        pthread_mutexattr_destroy(&amp;attrmutex);         munmap((void *)pmutex, sizeof(*pmutex));    } else {        write_string(\"key2: value2\");    }    return 0;}What the code does in main is initialize a process shared mutex using a piece of shared memory. You will find out what this call to mmap does later – just assume for the time being that it create memory that is shared between processes. We can initialize a pthread_mutex_t in that special piece of memory and use it as normal. To counter write failing, we have put the write call inside a while loop that keeps writing so long as there are bytes left to write. Now if all the other system calls function, there should be more more race conditions.Most programs try to avoid this problem entirely by writing to separate files, but it is good to know that there are mutexes across processes, and they are useful.What else can you do?You can use all of the primitives that you were taught previously! Barriers, semaphores, and condition variables can all be initialized on a shared piece of memory and used in similar ways to their multithreading counterparts.Okay, so when would I use this?  You don’t have to worry about arbitrary memory addresses becoming race condition candidates. This means that only areas that you specifically mmap or outside system resources like files are ever in danger.  You get the nice isolation of a processes so if one process fails the system can maintain intact  When you have a lot of threads, creating a process might ease the system loadDo I need to memorize the specifics?No, you just need to know that mutexes and other synchronization primitives can be shared across processes."
  },{
    "title": "Synchronization Review Questions",
    "url": " /wikibook/synchronization-review-questions",
   "content": "Topics  Atomic operations  Critical Section  Producer Consumer Problem  Using Condition Variables  Using Counting Semaphore  Implementing a barrier  Implementing a ring buffer  Using pthread_mutex  Implementing producer consumer  Analyzing multi-threaded codedQuestions  What is atomic operation?  Why will the following not work in parallel code    //In the global sectionsize_t a;//In pthread functionfor(int i = 0; i &lt; 100000000; i++) a++;    And this will?    //In the global sectionatomic_size_t a;//In pthread functionfor(int i = 0; i &lt; 100000000; i++) atomic_fetch_add(a, 1);    What are some downsides to atomic operations? What would be faster: keeping a local variable or many atomic operations?  What is the critical section?  Once you have identified a critical section, what is one way of assuring that only one thread will be in the section at a time?  Identify the critical section herestruct linked_list;struct node;void add_linked_list(linked_list *ll, void* elem){    node* packaged = new_node(elem);    if(ll-&gt;head){         ll-&gt;head =     }else{         packaged-&gt;next = ll-&gt;head;         ll-&gt;head = packaged;         ll-&gt;size++;    }    }void* pop_elem(linked_list *ll, size_t index){    if(index &gt;= ll-&gt;size) return NULL;        node *i, *prev;    for(i = ll-&gt;head; i &amp;&amp; index; i = i-&gt;next, index--){        prev = i;    }    //i points to the element we need to pop, prev before    if(prev-&gt;next) prev-&gt;next = prev-&gt;next-&gt;next;    ll-&gt;size--;    void* elem = i-&gt;elem;    destroy_node(i);    return elem;}How tight can you make the critical section?  What is a producer consumer problem? How might the above be a producer consumer problem be used in the above section? How is a producer consumer problem related to a reader writer problem?  What is a condition variable? Why is there an advantage to using one over a while loop?  Why is this code dangerous?    if(not_ready){   pthread_cond_wait(&amp;cv, &amp;mtx);}    What is a counting semaphore? Give me an analogy to a cookie jar/pizza box/limited food item.  What is a thread barrier?      Use a counting semaphore to implement a barrier.    Write up a Producer/Consumer queue, How about a producer consumer stack?  Give me an implementation of a reader-writer lock with condition variables, make a struct with whatever you need, it just needs to be able to support the following functions    void reader_lock(rw_lock_t* lck);void writer_lock(rw_lock_t* lck);void reader_unlock(rw_lock_t* lck);void writer_unlock(rw_lock_t* lck);    The only specification is that in between reader_lock and reader_unlock, no writers can write. In between the writer locks, only one writer may be writing at a time.    Write code to implement a producer consumer using ONLY three counting semaphores. Assume there can be more than one thread calling enqueue and dequeue.Determine the initial value of each semaphore.  Write code to implement a producer consumer using condition variables and a mutex. Assume there can be more than one thread calling enqueue and dequeue.  Use CVs to implement  add(unsigned int) and subtract(unsigned int) blocking functions that never allow the global value to be greater than 100.  Use CVs to implement a barrier for 15 threads.  How many of the following statements are true?          There can be multiple active readers      There can be multiple active writers      When there is an active writer the number of active readers must be zero      If there is an active reader the number of active writers must be zero      A writer must wait until the current active readers have finished        Todo: Analyzing mulithreaded code snippets"
  },{
    "title": "System Programming Jokes",
    "url": " /wikibook/system-programming-jokes",
   "content": "System Programming JokesWarning: Authors are not responsible for any neuro-apoptosis caused by these “jokes.” - Groaners are allowed.Light bulb jokesQ. How many system programmers does it take to change a lightbulb?A. Just one but they keep changing it until it returns zero.A. None they prefer an empty socket.A. Well you start with one but actually it waits for a child to do all of the work.GroanersWhy did the baby system programmer like their new colorful blankie? It was multithreaded.Why are your programs so fine and soft? I only use 400-thread-count or higher programs.Where do bad student shell processes go when they die? Forking Hell.Why are C programmers so messy? They store everything in one big heap.System Programmer (Definition)A system programmer is…Someone who knows sleepsort is a bad idea but still dreams of an excuse to use it.Someone who never lets their code deadlock… but when it does, causes more problems than everyone else combined.Someone who believes zombies are real.Someone who doesn’t trust their process to run correctly without testing with the same data, kernel, compiler, RAM, filesystem size,file system format, disk brand, core count, CPU load, weather, magnetic flux, orientation, pixie dust, horoscope sign, wall color, wall gloss and reflectance, motherboard, vibration, illumination, backup battery, time of day, temperature, humidity, lunar position, sun-moon co-position…System Program (Definition)A system program …Evolves until it can send email.Evolves until it has the potential to create, connect and kill other programs and consume all possible CPU,memory,network,… resources on all possible devices but chooses not to. Today."
  },{
    "title": "System Programming Short Stories and Songs",
    "url": " /wikibook/system-programming-short-stories-and-songs",
   "content": "“Scheduling The Last Time Slice”Lawrence Angrave 12/4/15 (an extract from the longer, unpublished story “The Last Time Slice”)“Decide,” the computer said with parental patience but with an air of gravity and tempered impatience.“Why does it have to be me?” asked the last human.“Because you are the only one left, and so the decision is yours.”“Why can’t you? You are an infinite times more older, wiser. Why don’t you just pick a random slice?”“This decision is yours. A gift, or curse if you will, from your distant elders. Heavier than any religious rite. This will be the last decision I, the ancients or anyone asks, or can ask, of you. With this last choice we will exhaust the last entropy stores. You will decide the last reality slice to have meaning and experience.”The human was quiet for a few minutes which the computer measured and counted with unnecessary accuracy. Eventually the computer decided that the human was no longer productively thinking about the problem in hand.“What is the pattern of conscious if it is never made conscious?” it asked. “The universe must be self-aware, must experience itself for the Universe - for all life! - to have meaning. That is the ultimate truth that humanity discovered and celebrated. With no awareness, it is simply patterns, patterns of atoms or energy but without a single iota of meaning; mere shapes and representations encoded in geometric patterns of data, structure and energy.”___File Descriptor at Urbana ChampaignA System Programming parody by Angrave (November 2015). Lyrics released under Creative Commons attribution 3.0 license.Forever immortalized on the web youtube linkOriginal song “Blank Space” from Taylor Swift’s “1989” album.[Verse 1]Nice to join youWhere you been?I could show you idempotent thingsRPC, sockets, synSaw your malloc and I thought oh my rootLook at that race, you code up the next mistakeWe got VMs, wanna playBounded wait, Dekker’s flagsWe can frag you like a placement schemeAint it funny to #defineAnd I know you heard about free(3)So malloc strlen plus oneI’m waiting to see how this thread endsGrab your shell and a redirect outI can make your syscall good for a weekend[Pre-Chorus]So it’s gonna deadlock foreverOr it’s gonna bring the system downYou can tell me when it forkbombsIf valgrind was worth the painGot a long list of deadlocked codeGot root at Urbana ChampaignCause you know we love tsanWhen c-lib calls your main[Chorus]Cause we’re root and we’re recklessThis lab is way too hardIt’ll leave you threadlessOr asking the sizeof charGot a long list of pthread callsGot root at Urbana ChampaignBut I got a file descriptor babyAnd I’ll write(2) your name[Verse 2]Mutex locksVirtual memI could show you volatile thingsNetwork calls, IPCYou’re the mask I’m your sigSchedule what you wantRound Robin… with a small quantaBut the sleepsort is yet to runOh noScreaming, crying, runtime errorsI could make all ‘till it’s Peterson’s turnHeap allocator way too slowKeep you second guessing like a spurious wakeWhere is that pipe? We get hot for multicore CBut you’ll compile with -gCause darling I’m a nightmare dressed like a coding dream[Pre-Chorus][Chorus]Compilers only parse code if it’s tortureDon’t say I didn’t say I didn’t -Wall youCompilers only parse code if it’s tortureDon’t say I didn’t say I didn’t -Wall you[Pre-Chorus][Chorus]A parody on Yesterday (Beatles song) by AngraveYesterday, all my mallocs seemed all OKNow my core dump seems here to stayOh I believe in yesterdaySuddenly I read the man page and I checked my C.There’s a seg fault hanging over me.Oh, yesterday crashed suddenly.Why C had to crash, I don’t know, C wouldn’t say.I wrote some pointers wrong, now I long for yesterday.Yesterday C was such an easy game to play.Now I need a place to hide away.Oh, I believe in yesterday.Why C had to crash, I don’t know, C wouldn’t say.I wrote some pointers wrong, now I long for yesterday.Yesterday C was such an easy game to play.Now I need a place to hide away.Oh, I believe in yesterday.Mm mm mm mm mm mm mm"
  },{
    "title": "Systems Programming Bugs in Industry",
    "url": " /wikibook/systems-programming-bugs-in-industry",
   "content": "Be Careful!Below are all famous bugs that have brought down systems. If you want to experiment with any of the starter code that they give, take caution as you could lose important files or even usability of your system.You may not be able to understand much of this at the beginning of the course. As we go through, more and more of these bugs will become clear. Systems programming doesn’t have to be in C only!Basic Memory/C BugsVulnerabilities in IOHIDeous, Mac OS XHeartbleedPHP Memory Bug – Please don’t use PHP“Cloudbleed”Famous Race ConditionsMaking money on digital oceanAwesome Race ConditionBitcoin Race ConditionsDirty Cow, My FavoriteHyper ThreadingKernel Race ConditionsNot a bug but still cool – Random number race generationMemory StuffMemory Allocation in PythonMemory Leakskfree twice to get rootProcessesUsing waitid to escape dockerFamous fork gotchaFilesystemsApple FilesystemsUbuntu FilesystemsEvent Drive IOepoll brokenNetworkinggethostbyname overflowtricking antivirusesBreaking SSLSchedulingDecades of wasted coresSignalPrivilege Escalation with kill(-1, SIGKILL)"
  },{
    "title": "Test page",
    "url": " /wikibook/test-page",
   "content": "Test page please ignore."
  },{
    "title": "Virtual Memory, Part 1: Introduction to Virtual Memory",
    "url": " /wikibook/virtual-memory-part-1-introduction-to-virtual-memory",
   "content": "What is Virtual Memory?In very simple embedded systems and early computers, processes directly access memory i.e. “Address 1234” corresponds to a particular byte stored in a particular part of physical memory.In modern systems, this is no longer the case. Instead each process is isolated; and there is a translation process between the address of a particular CPU instruction or piece of data of a process and the actual byte of physical memory (“RAM”). Memory addresses are no longer ‘real’; the process runs inside virtual memory. Virtual memory not only keeps processes safe (because one process cannot directly read or modify another process’s memory) it also allows the system to efficiently allocate and re-allocate portions of memory to different processes.What is the MMU?The Memory Management Unit is part of the CPU. It converts a virtual memory address into a physical address. The MMU may also interrupt the CPU if there is currently no mapping from a particular virtual address to a physical address or if the current CPU instruction attempts to write to location that the process only has read-access.So how do we convert a virtual address into a physical address?Imagine you had a 32 bit machine. Pointers can hold 32 bits i.e. they can address 2^32 different locations i.e. 4GB of memory (we will be following the standard convention of one address can hold one byte).Imagine we had a large table - here’s the clever part - stored in memory! For every possible address (all 4 billion of them) we will store the ‘real’ i.e. physical address. Each physical address will need 4 bytes (to hold the 32 bits).This scheme would require 16 billion bytes to store all of entries. Oops - our lookup scheme would consume all of the memory that we could possibly buy for our 4GB machine.We need to do better than this. Our lookup table better be smaller than the memory we have otherwise we will have no space left for our actual programs and operating system data.The solution is to chunk memory into small regions called ‘pages’ and ‘frames’ and use a lookup table for each page.What is a page? How many of them are there?A page is a block of virtual memory. A typical block size on Linux operating system is 4KB (i.e. 2^12 addresses), though you can find examples of larger blocks.So rather than talking about individual bytes we can talk about blocks of 4KBs, each block is called a page. We can also number our pages (“Page 0” “Page 1” etc)EX: How many pages are there in a 32bit machine (assume page size of 4KB)?Answer: 2^32 address / 2^12 = 2^20 pages.Remember that 2^10 is 1024, so 2^20 is a bit more than one million.For a 64 bit machine, 2^64 / 2^12 = 2^52, which is roughly 10^15 pages.What is a frame?A frame (or sometimes called a ‘page frame’) is a block of physical memory or RAM (=Random Access Memory). This kind of memory is occasionally called ‘primary storage’ (and contrasted with slower, secondary storage such as spinning disks that have lower access times)A frame is the same number of bytes as a virtual page. If a 32 bit machine has 2^32 (4GB) of RAM, then there will be the same number of them in the addressable space of the machine. It’s unlikely that a 64 bit machine will ever have 2^64 bytes of RAM - can you see why?What is a page table and how big is it?A page table is a mapping between a page to the frame.For example Page 1 might be mapped to frame 45, page 2 mapped to frame 30. Other frames might be currently unused or assigned to other running processes, or used internally by the operating system.A simple page table is just an array, int frame = table[ page_num ];For a 32 bit machine with 4KB pages, each entry needs to hold a frame number - i.e. 20 bits because we calculated there are 2^20 frames. That’s 2.5 bytes per entry! In practice, we’ll round that up to 4 bytes per entry and find a use for those spare bits. With 4 bytes per entry x 2^20 entries = 4 MB of physical memory are required to hold the page table.For a 64 bit machine with 4KB pages, each entry needs 52 bits. Let’s round up to 64 bits (8 bytes) per entry. With 2^52 entries thats 2^55 bytes (roughly 40 peta bytes…) Oops our page table is too large.In 64 bit architectures memory addresses are sparse, so we need a mechanism to reduce the page table size, given that most of the entries will never be used.A visual example of the page table is here. Imagine accessing an array and grabbing array elements.What is the offset and how is it used?Remember our page table maps pages to frames, but each page is a block of contiguous addresses. How do we calculate which particular byte to use inside a particular frame? The solution is to re-use the lowest bits of the virtual memory address directly. For example, suppose our process is reading the following address-VirtualAddress = 11110000111100001111000010101010 (binary)On a machine with page size 256 Bytes, then the lowest 8 bits (10101010) will be used as the offset.The remaining upper bits will be the page number (111100001111000011110000).Multi-level page tablesMulti-level pages are one solution to the page table size issue for 64 bit architectures. We’ll look at the simplest implementation - a two level page table. Each table is a list of pointers that point to the next level of tables, not all sub-tables need to exist. An example, two level page table for a 32 bit architecture is shown below-VirtualAddress = 11110000111111110000000010101010 (binary)                 |_Index1_||        ||          | 10 bit Directory index                           |_Index2_||          | 10 bit Sub-table index                                     |__________| 12 bit offset (passed directly to RAM)In the above scheme, determining the frame number requires two memory reads: The topmost 10 bits are used in a directory of page tables. If 2 bytes are used for each entry, we only need 2KB to store this entire directory. Each subtable will point to physical frames (i.e. required 4 bytes to store the 20 bits). However, for processes with only tiny memory needs, we only need to specify entries for low memory address (for the heap and program code) and high memory addresses (for the stack). Each subtable is 1024 entries x 4 bytes i.e. 4KB for each subtable.Thus the total memory overhead for our multi-level page table has shrunk from 4MB (for the single level implementation) to 3 frames of memory (12KB) ! Here’s why: We need at least one frame for the high level directory and two frames for just two sub-tables. One sub-table is necessary for the low addresses (program code, constants and possibly a tiny heap), the other sub-table is for higher addresses used by the environment and stack. In practice, real programs will likely need more sub-table entries, as each subtable can only reference 1024*4KB = 4MB of address space but the main point still stands - we have significantly reduced the memory overhead required to perform page table look ups.Do page tables make memory access slower? (And what’s a TLB)Yes - Significantly ! (But thanks to clever hardware, usually no…)Compared to reading or writing memory directly.For a single page table, our machine is now twice as slow! (Two memory accesses are required)For a two-level page table, memory access is now three times as slow. (Three memory accesses are required)To overcome this overhead, the MMU includes an associative cache of recently-used  virtual-page-to-frame lookups. This cache is called the TLB (“translation lookaside buffer”). Everytime a virtual address needs to be translated into a physical memory location, the TLB is queried in parallel to the page table. For most memory accesses of most programs, there is a significant chance that the TLB has cached the results. However if a program does not have good cache coherence (for example is reading from random memory locations of many different pages) then the TLB will not have the result cache and now the MMU must use the much slower page table to determine the physical frame.This may be how one splits up a multi level page table.Advanced Frames and Page ProtectionsCan frames be shared between processes? Can they be specializedYes! In addition to storing the frame number, the page table can be used to store whether a process can write or only read a particular frame. Read only frames can then be safely shared between multiple processes. For example, the C-library instruction code can be shared between all processes that dynamically load the code into the process memory. Each process can only read that memory. Meaning that if you try to write to a read-only page in memory you will get a SEGFAULT. That is why sometimes memory accesses segfault and sometimes they don’t, it all depends on if your hardware says that you can access.In addition, processes can share a page with a child process using the mmap system call. mmap is an interesting call because instead of tying each virtual address to a physical frame, it ties it to something else. That something else can be a file, a GPU unit, or any other memory mapped operation that you can think of! Writing to the memory address may write through to the device or the write may be paused by the operating system but this is a very powerful abstraction because often the operating system is able to perform optimizations (multiple processes memory mapping the same file can have the kernel create one mapping).What else is stored in the page table and why?In addition to read-only bit and usage statistics discussed above, it is common to store at least read-only, modification and execution information.What’s a page fault?A page fault is when a running program tries to access some virtual memory in its address space that is not mapped to physical memory. Page faults will also occur in other situations.There are three types of Page FaultsMinor If there is no mapping yet for the page, but it is a valid address. This could be memory asked for by sbrk(2) but not written to yet meaning that the operating system can wait for the first write before allocating space. The OS simply makes the page, loads it into memory, and moves on.Major If the mapping to the page is not in memory but on disk. What this will do is swap the page into memory and swap another page out. If this happens frequently enough, your program is said to thrash the MMU.Invalid When you try to write to a non-writable memory address or read to a non-readable memory address. The MMU generates an invalid fault and the OS will usually generate a SIGSEGV meaning segmentation violation meaning that you wrote outside the segment that you could write to.Read-only bitThe read-only bit marks the page as read-only. Attempts to write to the page will cause a page fault. The page fault will then be handled by the Kernel. Two examples of the read-only page include sharing the c runtime library between multiple processes (for security you wouldn’t want to allow one process to modify the library); and Copy-On-Write where the cost of duplicating a page can be delayed until the first write occurs.Dirty bithttp://en.wikipedia.org/wiki/Page_table#Page_table_data  The dirty bit allows for a performance optimization. A page on disk that is paged in to physical memory, then read from, and subsequently paged out again does not need to be written back to disk, since the page hasn’t changed. However, if the page was written to after it’s paged in, its dirty bit will be set, indicating that the page must be written back to the backing store. This strategy requires that the backing store retain a copy of the page after it is paged in to memory. When a dirty bit is not used, the backing store need only be as large as the instantaneous total size of all paged-out pages at any moment. When a dirty bit is used, at all times some pages will exist in both physical memory and the backing store.Execution bitThe execution bit defines whether bytes in a page can be executed as CPU instructions. By disabling a page, it prevents code that is maliciously stored in the process memory (e.g. by stack overflow) from being easily executed. (further reading: http://en.wikipedia.org/wiki/NX_bit#Hardware_background)Find out moreA lower level more and more technical discussion of paging and page bits on x86 platform is discussed at [http://wiki.osdev.org/Paging]"
  }
]
